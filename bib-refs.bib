%----------------------ExGOER literature----------------------%
@InCollection{lilligreen:2019:AWI,
	author =       {Gergana Lilligreen and Alexander Wiebel},
	title =        {Augmented Reality in Vorlesung und Übung: Lehre und Interaktion neu gedacht},
	booktitle =      {Hochschulen in Zeiten der Digitalisierung: Lehre, Forschung und Organisation},
	year =         {2019},
	publisher={Springer Vieweg},
	editor =    {Thomas Barton and Christian Müller and Christian Seel},
	OPTkey =       {},
	OPTvolume =    {},
	OPTnumber =    {},
	pages =     {221-238},
	OPTmonth =     {},
	OPTnote =      {},
	OPTannote =    {},
	doi = {10.1007/978-3-658-26618-9_14}
}


@InProceedings{lilligreen:2019:EuroVR,
	author =       {Gergana Lilligreen and Sascha Keuchel and Alexander Wiebel},
	title =        {Augmented Reality in Higher Education: An Active Learning Approach for a Course in
	Audiovisual Production},
	OPTcrossref =  {},
	OPTkey =       {},
	booktitle = {Proceedings of the 16th Annual EuroVR Conference},
	year =         {2019},
	OPTeditor =    {},
	OPTvolume =    {},
	OPTnumber =    {},
	OPTseries =    {},
	pages =     {23-36},
	OPTmonth =     {},
	OPTaddress =   {},
	OPTorganization = {},
	OPTpublisher = {},
	OPTnote =      {},
	OPTnote =      {},
	OPTannote =    {},  
	doi = {10.32040/2242-122X.2019.T357}
}

@inproceedings{pueschel:2013:MRCG,
	author = {Fabian Püschel and Dino \v{C}ubela and  Klaus Böhm and Pascal Neis},
	title = {What’s the deal with {CG}? {The} usage of mixed reality applications as a mean to facilitate meaningful experiences in teaching and learning Computer Graphics},
	booktitle = {IEEE German Education Conference 2023},
	year = {2023},
	doi = {10.1109/GECon58119.2023.10295085}
}
@book{kolb:1984:experiential,
	AUTHOR = {D.A. Kolb},
	TITLE = {Experiential learning: experience as the source of learning and development},
	YEAR = {1984},
	ADDRESS = {Englewood Cliffs, NJ},
	PUBLISHER = {Prentice Hall}
	},
	KEYWORDS = {Lernen / Development | Kybernetik / Systemtheorie /dynamische Systeme | Lernen |
	Erfahrung | Konstruktvismus | Wissen | Kolb, David A. | Piaget, Jean | Dewey, John | Adaptation |
	Theorienkonstruktion | knowledge construction | }
}
@InCollection{wiley:2014:oer,
	author={Wiley, David
	and Bliss, T. J.
	and McEwen, Mary},
	editor={Spector, J. Michael
	and Merrill, M. David
	and Elen, Jan
	and Bishop, M. J.},
	title={Open Educational Resources: A Review of the Literature},
	bookTitle={Handbook of Research on Educational Communications and Technology},
	year={2014},
	publisher={Springer New York},
	address={New York, NY},
	pages={781--789},
	abstract={This chapter begins by reviewing the many definitions of the term open educational resources and concludes by discussing challenges and opportunities for the approach. Open educational resources (OER) are educational materials either licensed under an open copyright license or in the public domain. Neither the term ``open educational resources'' nor the term ``open'' itself has an agreed upon definition in the literature. Research regarding open educational resources focuses on methods of producing OER, methods of sharing OER, and the benefits of OER. Significant issues relating to OER remain unresolved, including business model and discovery problems.},
	isbn={978-1-4614-3185-5},
	doi={10.1007/978-1-4614-3185-5_63},
}

@inproceedings{figueiredo:2003:cgems,
	author = {Figueiredo, Frederico C. and Eber, Dena E. and Jorge, Joaquim A.},
	title = {{CGEMS}: Computer Graphics Educational Materials Server},
	year = {2003},
	isbn = {9781450374590},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	doi = {10.1145/965106.965131},
	abstract = {Computer graphics has evolved considerably over the past few decades. As computer science, digital arts, and other areas of study that use computer graphics continue to evolve and gain new substance, educators have come to master new content and achieve deeper understandings of computers and imagery. As the core field becomes more mature, educators in all computer graphics disciplines have a greater need for high-quality curricular resources. Offering excellent educational materials is an important service to the community of educators. Such support will empower both young and seasoned educators alike to benefit from and contribute to the work of others. In this way, we can achieve a higher standard of teaching worldwide.The purpose of our work is to provide tools to foster such a community of computer graphics educators. We will present a system that will act as the means for their work to be appraised, assessed and made available to others through an online server for refereed educational content in computer graphics.In this paper we describe the basis for and highlight some of the starting requirements of CGEMS, the online Computer Graphics Educational Materials Server. This is organized around a web-based groupware application that supports the submission, review, acquisition, and archiving of curricular resources.},
	booktitle = {ACM SIGGRAPH 2003 Educators Program},
	pages = {1–7},
	numpages = {7},
	location = {San Diego, California},
	series = {SIGGRAPH '03}
}

@article{figueiredo:2004:cgems2,
	title = {Refereed digital publication of computer graphics educational materials},
	journal = {Computers \& Graphics},
	volume = {28},
	number = {1},
	pages = {119-124},
	year = {2004},
	issn = {0097-8493},
	doi = {10.1016/j.cag.2003.10.013},
	author = {Frederico C. Figueiredo and Dena E. Eber and Joaquim A. Jorge},
	keywords = {Administration, Education, Multimedia document processing, Electronic publishing, Online information services, Computer uses in education, Digital libraries},
	abstract = {Computer Graphics (CG) as a discipline has undergone drastic modifications over the past decades. Indeed the phenomenal progress in both the technical and digital art domains requires educators to master new content and achieve deeper understandings of computers and imagery if they are to keep up with the pace of change. Moreover, as the core field matures, educators in all areas experience a greater need for high-quality curricular resources. Thus, offering excellent educational materials online is an important service to the community. Such support will empower both young and seasoned educators alike to benefit from and contribute to the work of others. The purpose of the work described here is to provide tools to foster such a community of CG educators. We present a system that will allow for original work to be appraised, assessed and made available to others through an online source for refereed educational content in CG. The present paper highlights some of the user requirements and describes the current status of CGEMS, the online CG Educational Materials Source. This is organized around a web-based groupware application that supports the all phases of submission, reviewing, acquisition, and archiving of curricular resources.}
}
@inproceedings{ridge:2019:ecosystem,
	author = {Ridge, Garett D. and Terzopoulos, Demetri},
	title = {An Online Collaborative Ecosystem for Educational Computer Graphics},
	year = {2019},
	isbn = {9781450367981},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	doi = {10.1145/3329714.3338133},
	abstract = {We introduce a coding framework that supplements introductory computer graphics courses, with the goal of teaching graphics fundamentals more effectively and lowering the excessive barrier of entry to 3D graphics programming. In particular, our framework provides tiny-graphics.js, a new WebGL-based software library for implementing projects, including an improved organization system for graphics code that has greatly benefited our students. To mitigate the difficulty of creating 3D graphics-enabled websites and online games, we furthermore introduce the “Encyclopedia of Code”—a World Wide Web framework that encourages visitors to learn 3D computer graphics, build educational graphical demos and articles, host them online, and organize them by topic. Our own contributed examples include various interactive tutorials and educational games. Some of our modules expose students to new graphics techniques, while others explore new modes of online learning, collaboration, and computing. In comparison to earlier online graphics coding platforms and mainstream graphics educational materials, the resources that we have developed offer a significantly unique set of features for both inside and outside our classrooms.},
	booktitle = {Proceedings of the 24th International Conference on 3D Web Technology},
	pages = {1–10},
	numpages = {10},
	keywords = {tiny-graphics.js, Encyclopedia of Code., Computer Graphics education, JavaScript Library, WebGL},
	location = {LA, CA, USA},
	series = {Web3D '19}
}
@inproceedings{angel:2017:interactive,
	author = {Angel, Ed and Haines, Eric},
	title = {An Interactive Introduction to WEBGL and Three.JS},
	year = {2017},
	isbn = {9781450350143},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	doi = {10.1145/3084873.3084875},
	abstract = {We will use WebGL 1.0. WebGL 2.0 is now being supported by most browsers but requires a better GPU so may not run on older computers or on most cell phones and tablets. See http://webglstats.com/. We will note some of the new features supported by WebGL 2.0 at the end of the course. three.js is starting to support WebGL 2.0.},
	booktitle = {ACM SIGGRAPH 2017 Courses},
	articleno = {17},
	numpages = {95},
	location = {Los Angeles, California},
	series = {SIGGRAPH '17}
}
@article{vanDam:1999:exploratories,
	author = {van Dam, Andries},
	title = {Education: The Unfinished Revolution},
	year = {1999},
	issue_date = {Dec. 1999},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {31},
	number = {4es},
	issn = {0360-0300},
	doi = {10.1145/345966.346038},
	journal = {ACM Comput. Surv.},
	month = {dec},
	pages = {36–es},
	numpages = {17}
}

@inproceedings{Suselo:2019:problems-cg-teaching,
	author = {Suselo, Thomas and Wünsche, Burkhard and Luxton-Reilly, Andrew},
	year = {2019},
	month = {01},
	pages = {96-105},
	title = {Technologies and Tools to Support Teaching and Learning Computer Graphics: A Literature Review},
	doi = {10.1145/3286960.3286972},
	journal = {Australian Computing Education Conference},
	publisher = {Association for Computing Machinery}
}

@inproceedings{Lui:2022:problems-cg-teaching,
	author = {Liu, Ken and Wünsche, Burkhard and Luxton-Reilly, Andrew},
	year = {2022},
	month = {07},
	pages = {304-310},
	title = {Relationship Between Spatial Skills and Performance in Introductory Computer Graphics},
	doi = {10.1145/3502718.3524756},
	publisher = {Association for Computing Machinery},
	journal = {Innovation and Technology in Computer Science Education Conference}
}

@inproceedings{Balreira:2017:topics-cg-teaching,
	author = {Balreira, Dennis and Walter, Marcelo and Fellner, Dieter},
	booktitle = {EG 2017 - Education Papers},
	year = {2017},
	month = {04},
	pages = {},
	title = {What we are teaching in Introduction to Computer Graphics},
	publisher = {The Eurographics Association},
	ISSN = {1017-4656},
	DOI = {10.2312/eged.20171019}
}

@article{Qiao:2019:disadvantage-of-ar,
	author = {Qiao, Xiuquan and Pei, Ren and Dustdar, Schahram and Liu, Ling and Ma, Huadong and Junliang, Chen},
	year = {2019},
	month = {02},
	pages = {1-16},
	title = {{Web AR}: A Promising Future for Mobile Augmented Reality - State of the Art, Challenges, and Insights},
	volume = {107},
	journal = {Proceedings of the IEEE},
	doi = {10.1109/JPROC.2019.2895105}
}

@article{Spalter:2006:cg-tool,
	author = {Spalter, Anne and Tenneson, Dana},
	year = {2006},
	month = {01},
	pages = {41},
	title = {The graphics teaching tool},
	isbn = {1-59593-364-6},
	doi = {10.1145/1179295.1179337},
	publisher = {Association for Computing Machinery}
}
@article{Suselo:2018:cg-tool,
	author = {Suselo, Thomas and Wünsche, Burkhard and Luxton-Reilly, Andrew},
	year = {2018},
	month = {03},
	pages = {},
	title = {Mobile Augmented Reality as a Teaching Medium in an Introductory Computer Graphics Course},
	doi = {10.1109/LaTICE.2018.000-3},
	publisher = {IEEE},
	journal = {Learning and Teaching in Computing and Engineering Conference}
}

@inproceedings{Eisemann:2023:cg-tool,
	booktitle = {Eurographics 2023 - Education Papers},
	editor = {Magana, Alejandra and Zara, Jiri},
	title = {{Game-based Transformations: A Playful Approach to Learning Transformations in Computer Graphics}},
	author = {Eisemann, Martin},
	year = {2023},
	publisher = {The Eurographics Association},
	ISSN = {1017-4656},
	ISBN = {978-3-03868-210-3},
	DOI = {10.2312/eged.20231018}
}
@inproceedings{Verschoore-de-la-Houssaije:2022:cg-tool,
	booktitle = {Eurographics 2022 - Education Papers},
	editor = {Bourdin, Jean-Jacques and Paquette, Eric},
	title = {{Virtual Ray Tracer}},
	author = {Verschoore de la Houssaije, Willard A. and Wezel, Chris S. van and Frey, Steffen and Kosinka, Jiri},
	year = {2022},
	publisher = {The Eurographics Association},
	ISSN = {1017-4656},
	ISBN = {978-3-03868-170-0},
	DOI = {10.2312/eged.20221045}
}

@inproceedings{Sueyasu:2010:cg-tool,
	author = {Sueyasu, Shogo and Nagano, Tatsuro and Nishino, Hiroaki and Kagawa, Tsuneo and Utsumiya, Kouichi},
	year = {2010},
	month = {12},
	pages = {115 - 122},
	booktitle={2010 International Conference on P2P, Parallel, Grid, Cloud and Internet Computing}, 
	title = {An Interactive {CG} Learning System Through 3D Authoring and Programming},
	doi = {10.1109/3PGCIC.2010.23}
}
@InProceedings{Lobb:2016:cg-tool,
	author = {Lobb, Richard and Harlow, Jenny},
	title = {Coderunner: A Tool for Assessing Computer Programming Skills},
	year = {2016},
	issue_date = {March 2016},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {7},
	number = {1},
	issn = {2153-2184},
	doi = {10.1145/2810041},
	booktitle = {ACM SIGGRAPH 2006 Educators Program},
	abstract = {How should we assess programming skills? Asking students to write code in a traditional hand-written exam can produce results like those in Figure 1. It is nearly impossible to meaningfully grade such code. With sufficient effort one can get some idea of whether the general idea is correct, but to assess programming skill we need much more than this. For example, there will almost certainly be errors in the code; how do we know whether the student would be able to correct those errors or not?},
	journal = {ACM Inroads},
	month = {feb},
	pages = {47–51},
	numpages = {5}
}

@article{Kadam:2013:cg-tool,
	author = {Kadam, K. and Sahasrabudhe, Sameer and Iyer, Sridhar and Kamat, V.},
	year = {2013},
	month = {01},
	doi={10.58459/icce.2013.1014},
	pages = {483-486},
	title = {Integration of Blender 3D in basic computer graphics course},
	journal = {Proceedings of the 21st International Conference on Computers in Education, ICCE 2013}
}

@article{Elyan:2012:cg-tool,
	author = {Elyan, Eyad},
	year = {2012},
	month = {04},
	pages = {1-8},
	title = {Enhanced interactivity and engagement: Learning by doing to simplify mathematical concepts in computer graphics and animation},
	journal = {IEEE Global Engineering Education Conference, EDUCON},
	doi = {10.1109/EDUCON.2012.6201073}
}

@online{Statista-F.Harms:2023:Media-usage-ger,
	author = {F. Harms},
	title = {Statistics on media use by young people},
	year = 2023,
	url = {https://de.statista.com/themen/2662/mediennutzung-von-jugendlichen/},
	urldate = {2023-08-31}
}
@online{Statista-Market-Insights:2023:Videogames-worldwide,
	title = {Video games - Worldwide},
	author = {{Statista}},
	year = 2023,
	url = {{https://de.statista.com/outlook/dmo/digitale-medien/videospiele/weltweit}},
	notes = {accessed 2024-01-19}
}

@inproceedings {anderson:2017:NewCGEMS,
	booktitle = {EG 2017 - Education Papers},
	editor = {Jean-Jacques Bourdin and Amit Shesh},
	title = {{The New CGEMS - Preparing the Computer Graphics Educational Materials Source to Meet the Needs of Educators}},
	author = {Anderson, Eike Falk and Duchowski, Andrew and Liarokapis, Fotis and Redford, Adam},
	year = {2017},
	publisher = {The Eurographics Association},
	ISSN = {1017-4656},
	DOI = {10.2312/eged.20171028}
}
@article{tlili:2021:towards,
	title={Towards utilising emerging technologies to address the challenges of using Open Educational Resources: a vision of the future},
	author={Tlili, Ahmed and Zhang, Jingjing and Papamitsiou, Zacharoula and Manske, Sven and Huang, Ronghuai and Kinshuk and Hoppe, H Ulrich},
	journal={Educational Technology Research and Development},
	volume={69},
	pages={515--532},
	year={2021},
	publisher={Springer},
	DOI = {10.1007/s11423-021-09993-4}
}
@book{atkins:2007:review,
	title={A review of the open educational resources (OER) movement: Achievements, challenges, and new opportunities},
	author={Atkins, Daniel Ewell and Brown, John Seely and Hammond, Allen L},
	volume={164},
	year={2007},
	publisher={Creative common Mountain View}
}
@misc{declaration:2012:paris,
	title={Paris {OER} Declaration, 2012 {World} Open Educational Resources ({OER}) Congress},
	author={Declaration, Paris},
	year={2012},
	publisher={UNESCO, Paris}
}
@article{vanDam:1999:education,
	title={Education: the unfinished revolution},
	author={van Dam, Andries},
	journal={ACM Computing Surveys (CSUR)},
	volume={31},
	number={4es},
	pages={36--es},
	year={1999},
	publisher={ACM New York, NY, USA},
	DOI={10.1145/345966.346038}
}
@article{wu:2013:current,
	title = {Current status, opportunities and challenges of augmented reality in education},
	journal = {Computers \& Education},
	volume = {62},
	pages = {41-49},
	year = {2013},
	issn = {0360-1315},
	doi = {10.1016/j.compedu.2012.10.024},
	author = {Hsin-Kai Wu and Silvia Wen-Yu Lee and Hsin-Yi Chang and Jyh-Chong Liang},
	keywords = {Virtual reality, Architectures for educational technology system},
	abstract = {Although augmented reality (AR) has gained much research attention in recent years, the term AR was given different meanings by varying researchers. In this article, we first provide an overview of definitions, taxonomies, and technologies of AR. We argue that viewing AR as a concept rather than a type of technology would be more productive for educators, researchers, and designers. Then we identify certain features and affordances of AR systems and applications. Yet, these compelling features may not be unique to AR applications and can be found in other technological systems or learning environments (e.g., ubiquitous and mobile learning environments). The instructional approach adopted by an AR system and the alignment among technology design, instructional approach, and learning experiences may be more important. Thus, we classify three categories of instructional approaches that emphasize the “roles,” “tasks,” and “locations,” and discuss what and how different categories of AR approaches may help students learn. While AR offers new learning opportunities, it also creates new challenges for educators. We outline technological, pedagogical, learning issues related to the implementation of AR in education. For example, students in AR environments may be cognitively overloaded by the large amount of information they encounter, the multiple technological devices they are required to use, and the complex tasks they have to complete. This article provides possible solutions for some of the challenges and suggests topics and issues for future research.}
}
@misc{jim:2023:studies,
	author = {{Medienpädagogischer Forschungsverbund Südwest}},
	title = {JIM(Jugend, Information, Medien)-Studie 2023},
	year = {2023},
	url = {{https://www.mpfs.de/studien/jim-studie/2023/}},
	note = {accessed 2024-01-19},
}

@article{Singleton_Charlton_2019, title={Creating {H5P} content for active learning}, volume={2},  DOI={10.24135/pjtel.v2i1.32},  number={1}, journal={Pacific Journal of Technology Enhanced Learning}, author={Singleton, Rachelle and Charlton, Amanda}, year={2019}, month={Nov.}, pages={13-14} }

@online{blender:2024:documentation,
	title        = {Blender Documentation},
	author       = {{Blender Documentation Team}},
	year         = 2024,
	url          = {https://www.blender.org/get-involved/documenters/},
	urldate      = {2024-03-07}
}

@online{maya:2024:software,
	title        = {Maya Software},
	author       = {{Autodesk Inc.}},
	year         = 2024,
	url          = {https://www.autodesk.com/maya},
	urldate      = {2024-03-07}
}

@online{unity:2024:editor,
	title        = {Real-Time 3D Development Platform \& Editor},
	author       = {{Unity Technologies}},
	year         = 2024,
	url          = {https://unity.com/products/unity-engine},
	urldate      = {2024-03-07}
}
@online{WEB:GNU:GPL:2010,
	Author = {{Free Software Foundation, Inc.}},
	Title = {GNU General Public License},
	Url = {http://www.gnu.org/licenses/gpl.html},
	Urldate = {2011-05-27},
	Year = {2010}}

@online{WEB:Miede:2011,
	Author = {Andr{\'e} Miede},
	Title = {A Classic Thesis Style by Andr{\'e} Miede},
	Url = {http://www.miede.de/index.php?page=classicthesis},
	Urldate = {2011-05-27},
	Year = {2011}}

@book{Jurgens:2000,
	Author = {Manuela J{\"u}rgens},
	Publisher = {FernUniversit{\"a}t Gesamthochschule in Hagen},
	Title = {LaTeX: eine Einf{\"u}hrung und ein bisschen mehr},
	Year = {2000}}

@book{Jurgens:1995,
	Author = {Manuela J{\"u}rgens},
	Publisher = {FernUniversit{\"a}t Gesamthochschule in Hagen},
	Title = {LaTeX: Fortgeschrittene Anwendungen},
	Year = {1995}}

@manual{Miede:2011,
	Author = {Andr{\'e} Miede},
	Title = {A Classic Thesis Style: An Homage to The Elements of Typographic Style},
	Year = {2011}}

@book{Kohm:2011,
	Author = {Markus Kohm and Jens-Uwe-Morawski},
	Title = {KOMA-Script: Die Anleitung},
	Year = {2011}}

@book{Apple:keynote:2010,
	Author = {{Apple Inc.}},
	Publisher = {{Apple Inc.}},
	Title = {Keynote '09 User Guide},
	Year = {2010}}

@book{Apple:numbers:2010,
	Author = {{Apple Inc.}},
	Publisher = {{Apple Inc.}},
	Title = {Numbers '09 User Guide},
	Year = {2010}}

@book{Apple:pages:2010,
	Author = {{Apple Inc.}},
	Publisher = {{Apple Inc.}},
	Title = {Pages '09 User Guide},
	Year = {2010}}
%----------------------TVCG literature----------------------%
@article{martin2020hit, 
year = {2020}, 
title = {{“HIIT” the ExerCube: Comparing the Effectiveness of Functional High-Intensity Interval Training in Conventional vs. Exergame-Based Training}}, 
author = {Martin-Niedecken, Anna Lisa and Mahrer, Andrea and Rogers, Katja and Bruin, Eling D. de and Schättin, Alexandra}, 
journal = {Frontiers in Computer Science}, 
doi = {10.3389/fcomp.2020.00033}, 
abstract = {{Regular physical activity is crucial for a physically and mentally healthy lifestyle. Training methods such as high-intensity interval training (HIIT) have become increasingly popular as they enable substantial training effects in little time. HIIT typically involves recurring short phases of close-to-maximal exercise intensity, interspersed with low-intensity recovery phases. Originally mainly practiced via uniformly repetitive movements, newer variations include varied functional and holistic exercises (fHIIT). While HIIT facilitates many health advantages, fHIIT is considered more beneficial since it activates more muscles, requires more coordination, strength and balance, and mimics more natural movements which transfer well to daily life. However, fHIIT is a very intense training approach; it requires strong focus and intrinsic motivation to frequently push beyond perceived physical and mental limits. This is a common barrier to exploiting the full potential of this efficient training method. Exergames may facilitate this kind of training due to their playful, immersive, motivating nature. Yet so far, few studies have investigated HIIT-exergames – no fHIIT-exergames. This is possibly because few exergames featured both (1) an effective training concept that is comparable to HIIT, and (2) an attractive and motivating game design. We believe that this lack of holistic integration of both aspects is partly why there is currently little evidence for long-term motivation and training effects in exergame-based training. Our work addresses this gap through the design of an adaptive fHIIT protocol for the ExerCube fitness game system, creating a HIIT-level functional exergame. We conducted a within-subjects study to compare objective and subjective training intensity induced by the ExerCube against a conventional fHIIT session with healthy young adults. Furthermore, we evaluated participants' subjective experience with regards to motivation, flow, and enjoyment during both conditions. Our results contribute empirical evidence that exergames can induce HIIT-level intensity. While perceived physical exertion was slightly lower in the ExerCube condition, it yielded significantly better results for flow, enjoyment, and motivation. Moreover, the ExerCube seemed to enable a dual-domain training (higher cognitive load). We discuss these results in the context of exergame design for fHIIT, and provide practical suggestions covering topics such as safety precautions and physical-cognitive load balancing.}}, 
pages = {33}, 
volume = {2}, 
keywords = {}
}

@article{ware2020wo2, 
year = {2020}, 
title = {Augmented reality assisted training}, 
author = {Ware, Jill B. and Blatter, John Henry}, 
journal = {World Intellectuell Property Organization}, 
keywords = {}
}

@article{mostajeran2019hvc, 
year = {2019}, 
title = {{Welcoming a Holographic Virtual Coach for Balance Training at Home: Two Focus Groups with Older Adults}}, 
author = {Mostajeran, Fariba and Katzakis, Nikolaos and Ariza, Oscar and Freiwald, Jann Philipp and Steinicke, Frank}, 
journal = {2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)}, 
doi = {10.1109/vr.2019.8797813}, 
abstract = {{We report on findings from two focus groups for designing an application for balance training at home with an augmented reality virtual coach. Following a User-Centered Design approach, we performed two focus groups with older adults at the early stages of development. Focus group participants were shown a prototype using a Meta 2 head mounted display. Their movements were tracked using a Kinect 2. The virtual coach gave balance training instructions and demonstrated their correct performance. Results suggest that, given the trade-offs of traditional health care, older adults are positive towards using an AR coach for their balance training.}}, 
pages = {1465--1470}, 
keywords = {}
}
@article{takahashi2019vrb, 
year = {2019}, 
title = {{VR-based Batter Training System with Motion Sensing and Performance Visualization}}, 
author = {Takahashi, Kosuke and Mikami, Dan and Isogawa, Mariko and Kusachi, Yoshinori and Saijo, Naoki}, 
journal = {2019 IEEE Conference on Virtual Reality}, 
doi = {http://dx.doi.org/10.1109/VR.2019.8798005}, 
keywords = {}
}
@article{karatsidis2018vwv, 
year = {2018}, 
title = {{Validation of wearable visual feedback for retraining foot progression angle using inertial sensors and an augmented reality headset}}, 
author = {Karatsidis, Angelos and Richards, Rosie E. and Konrath, Jason M. and Noort, Josien C. van den and Schepers, H. Martin and Bellusci, Giovanni and Harlaar, Jaap and Veltink, Peter H.}, 
journal = {Journal of NeuroEngineering and Rehabilitation}, 
doi = {10.1186/s12984-018-0419-2}, 
pmid = {30111337}, 
abstract = {{Gait retraining interventions using real-time biofeedback have been proposed to alter the loading across the knee joint in patients with knee osteoarthritis. Despite the demonstrated benefits of these conservative treatments, their clinical adoption is currently obstructed by the high complexity, spatial demands, and cost of optical motion capture systems. In this study we propose and evaluate a wearable visual feedback system for gait retraining of the foot progression angle (FPA). The primary components of the system are inertial measurement units, which track the human movement without spatial limitations, and an augmented reality headset used to project the visual feedback in the visual field. The adapted gait protocol contained five different target angles ranging from 15 degrees toe-out to 5 degrees toe-in. Eleven healthy participants walked on an instrumented treadmill, and the protocol was performed using both an established laboratory visual feedback driven by optical motion capture, and the proposed wearable system. The wearable system tracked FPA with an accuracy of 2.4 degrees RMS and ICC=0.94 across all target angles and subjects, when compared to an optical motion capture reference. In addition, the effectiveness of the biofeedback, reflected by the number of steps with FPA value ±2 degrees from the target, was found to be around 50\% in both wearable and laboratory approaches. These findings demonstrate that retraining of the FPA using wearable inertial sensing and visual feedback is feasible with effectiveness matching closely an established laboratory method. The proposed wearable setup may reduce the complexity of gait retraining applications and facilitate their transfer to routine clinical practice.}}, 
pages = {78}, 
number = {1}, 
volume = {15}, 
keywords = {}
}
@article{booth2019vue, 
year = {2019}, 
title = {{The validity and usability of an eight marker model for avatar-based biofeedback gait training}}, 
author = {Booth, A.T.C. and Krogt, M.M. van der and Buizer, A.I. and Steenbrink, F. and Harlaar, J.}, 
journal = {Clinical Biomechanics}, 
issn = {0268-0033}, 
doi = {10.1016/j.clinbiomech.2019.08.013}, 
pmid = {31499394}, 
abstract = {{Background Virtual reality presents a platform for therapeutic gaming, and incorporation of immersive biofeedback on gait may enhance outcomes in rehabilitation. Time is limited in therapeutic practice, therefore any potential gait training tool requires a short set up time, while maintaining clinical relevance and accuracy. The aim of this study was to develop, validate, and establish the usability of an avatar-based application for biofeedback-enhanced gait training with minimal set up time. Methods A simplified, eight marker model was developed using eight passive markers placed on anatomical landmarks. This allowed for visualisation of avatar-based biofeedback on pelvis kinematics, hip and knee sagittal angles in real-time. Retrospective gait analysis data from typically developing children (n = 41) and children with cerebral palsy (n = 25), were used to validate eight marker model. Gait outcomes were compared to the Human Body Model using statistical parametric mapping. Usability for use in clinical practice was tested in five clinical rehabilitation centers with the system usability score. Findings Gait outcomes of Human Body Model and eight marker model were comparable, with small differences in gait parameters. The discrepancies between models were <5°, except for knee extension where eight marker model showed significantly less knee extension, especially towards full extension. The application was considered of ‘high marginal acceptability’ (system usability score, mean 68 (SD 13)). Interpretation Gait biofeedback can be achieved, to acceptable accuracy for within-session gait training, using an eight marker model. The application may be considered usable and implemented for use in patient populations undergoing gait training.}}, 
pages = {146--152}, 
volume = {70}, 
keywords = {}
}
@article{waltemate2016tlp, 
year = {2016}, 
title = {{The impact of latency on perceptual judgments and motor performance in closed-loop interaction in virtual reality}}, 
author = {Waltemate, Thomas and Senna, Irene and Hülsmann, Felix and Rohde, Marieke and Kopp, Stefan and Ernst, Marc and Botsch, Mario}, 
journal = {Proceedings of the 22nd ACM Conference on Virtual Reality Software and Technology}, 
doi = {10.1145/2993369.2993381}, 
abstract = {{Latency between a user's movement and visual feedback is inevitable in every Virtual Reality application, as signal transmission and processing take time. Unfortunately, a high end-to-end latency impairs perception and motor performance. While it is possible to reduce feedback delay to tens of milliseconds, these delays will never completely vanish. Currently, there is a gap in literature regarding the impact of feedback delays on perception and motor performance as well as on their interplay in virtual environments employing full-body avatars. With the present study at hand, we address this gap by performing a systematic investigation of different levels of delay across a variety of perceptual and motor tasks during full-body action inside a Cave Automatic Virtual Environment. We presented participants with their virtual mirror image, which responded to their actions with feedback delays ranging from 45 to 350 ms. We measured the impact of these delays on motor performance, sense of agency, sense of body ownership and simultaneity perception by means of psychophysical procedures. Furthermore, we looked at interaction effects between these aspects to identify possible dependencies. The results show that motor performance and simultaneity perception are affected by latencies above 75 ms. Although sense of agency and body ownership only decline at a latency higher than 125 ms, and deteriorate for a latency greater than 300 ms, they do not break down completely even at the highest tested delay. Interestingly, participants perceptually infer the presence of delays more from their motor error in the task than from the actual level of delay. Whether or not participants notice a delay in a virtual environment might therefore depend on the motor task and their performance rather than on the actual delay.}}, 
pages = {27--35}, 
keywords = {}
}
@article{trajkova2018ttb, 
year = {2018}, 
title = {{Takes Tutu to Ballet: Designing Visual and Verbal Feedback for Augmented Mirrors}}, 
author = {Trajkova, Milka and Cafaro, Francesco}, 
journal = {Proceedings of the ACM on Interactive, Mobile, Wearable and Ubiquitous Technologies}, 
doi = {10.1145/3191770}, 
abstract = {{Mirrors have been a core feature in ballet studios for over five hundred years. While physical mirrors provide real-time feedback, they do not inform dancers of their errors. Thus, technologies such as motion tracking have been used to augment what a physical mirror can provide. Current augmented mirrors, however, only implement one mode of communication, usually visual, and do not provide a holistic feedback to dancers that includes all the feedback elements commonly used in ballet classes. We conducted a mixed-method study with 16 novices and 16 expert dancers in which we compared two different modes of communication (visual and verbal), two different types of feedback (value and corrective) and two levels of guidance (mirror, or no mirror). Participants' ballet technique scores were evaluated by a remote teacher on eight ballet combinations (tendue, adagio, pirouette, saute, pli, degage, frappe and battement tendue). We report quantitative and qualitative results that show how the level of guidance, mode of communication, and type of feedback, needs to be tuned in different ways for novices and experts.}}, 
pages = {1--30}, 
number = {1}, 
volume = {2}, 
keywords = {}
}
@article{naour2019s3d, 
year = {2019}, 
title = {{Superimposing 3D Virtual Self + Expert Modeling for Motor Learning: Application to the Throw in American Football}}, 
author = {Naour, Thibaut Le and Hamon, Ludovic and Bresciani, Jean-Pierre}, 
journal = {Frontiers in ICT}, 
doi = {10.3389/fict.2019.00016}, 
abstract = {{We learn and/or relearn motor skills at all ages. Feedback plays a crucial role in this learning process, and Virtual Reality (VR) constitutes a unique tool to provide feedback and improve motor learning. In particular, VR grants the possibility to edit 3D movements and display augmented feedback in real time. Here we combined VR and motion capture to provide learners with a 3D feedback superimposing in real time the reference movements of an expert (expert feedback) to the movements of the learner (self feedback). We assessed the effectiveness of this feedback for the learning of a throwing movement in American football. This feedback was used during (concurrent feedback) and/or after movement execution (delayed feedback), and it was compared with a feedback displaying only the reference movements of the expert. In contrast with more traditional studies relying on video feedback, we used the Dynamic Time Warping algorithm coupled to motion capture to measure the spatial characteristics of the movements. We also assessed the regularity with which the learner reproduced the reference movement along its path. For that, we used a new metric computing the dispersion of distance around the mean distance over time. Our results show that when the movements of the expert were superimposed on the movements of the learner during learning (i.e., self + expert), the reproduction of the reference movement improved significantly. Furthermore, providing feedback about the movements of the expert only did not give rise to any significant improvement regarding movement reproduction.}}, 
pages = {16}, 
volume = {6}, 
keywords = {}
}
@article{huelsmann2019ssp, 
year = {2019}, 
title = {{Superimposed Skilled Performance in a Virtual Mirror Improves Motor Performance and Cognitive Representation of a Full Body Motor Action}}, 
author = {Hülsmann, Felix and Frank, Cornelia and Senna, Irene and Ernst, Marc O. and Schack, Thomas and Botsch, Mario}, 
journal = {Frontiers in Robotics and AI}, 
doi = {10.3389/frobt.2019.00043}, 
pmid = {33501059}, 
abstract = {{Feedback is essential for skill acquisition as it helps identifying and correcting performance errors. Nowadays, Virtual Reality can be used as a tool to guide motor learning, and to provide innovative types of augmented feedback that exceed real world opportunities. Concurrent feedback has shown to be especially beneficial for novices. Moreover, watching skilled performances helps novices to acquire a motor skill, and this effect depends on the perspective taken by the observer. To date, however, the impact of watching one's own performance together with full body superimposition of a skilled performance, either from the front or from the side, remains to be explored. Here we used an immersive, state-of-the-art, low-latency cave automatic virtual environment (CAVE), and we asked novices to perform squat movements in front of a virtual mirror. Participants were assigned to one of three concurrent visual feedback groups: participants either watched their own avatar performing full body movements or were presented with the movement of a skilled individual superimposed on their own performance during movement execution, either from a frontal or from a side view. Motor performance and cognitive representation were measured in order to track changes in movement quality as well as motor memory across time. Consistent with our hypotheses, results showed an advantage of the groups that observed their own avatar performing the squat together with the superimposed skilled performance for some of the investigated parameters, depending on perspective. Specifically, for the deepest point of the squat, participants watching the squat from the front adapted their height, while those watching from the side adapted their backward movement. In a control experiment, we ruled out the possibility that the observed improvements were due to the mere fact of performing the squat movements—irrespective of the type of visual feedback. The present findings indicate that it can be beneficial for novices to watch themselves together with a skilled performance during execution, and that improvement depends on the perspective chosen.}}, 
pages = {43}, 
volume = {6}, 
keywords = {}
}
@article{sousa2016sar, 
year = {March 2016}, 
title = {{SleeveAR: Augmented Reality for Rehabilitation using Realtime Feedback}}, 
author = {Sousa, Maurício and Vieira, João and Medeiros, Daniel and Arsenio, Artur and Jorge, Joaquim}, 
journal = {IUI '16: Proceedings of the 21st International Conference on Intelligent User Interfaces}, 
doi = {10.1145/2856767.2856773}, 
keywords = {}
}
@article{brewster2019srt, 
year = {2019}, 
title = {{Slackliner 2.0: Real-time Training Assistance through Life-size Feedback}}, 
author = {Murlowski, Christian and Daiber, Florian and Kosmalla, Felix and Krüger, Antonio}, 
journal = {Extended Abstracts of the 2019 CHI Conference on Human Factors in Computing Systems}, 
doi = {10.1145/3290607.3313250}, 
abstract = {{In this demo, we present Slackliner 2.0, an interactive slackline training assistant which features head and skeleton tracking, and real-time feedback through life-size projection. Like in other sports, proper training leads to a faster increase of skill and lessens the risk of injuries. We chose a set of exercises from slackline literature and implemented an interactive trainer which guides the user through the exercises giving feedback if the exercises were executed correctly. Based on lessons learned from our study and prior demonstrations we present a revised version of Slackliner that uses head tracking to better guide the user's attention and movements. Additionally a new visual indicator informs the trainee about her arm posture during the performance. This has been also included in an updated post-analysis view that provides the trainee with more detailed feedback about her performance. The present demo showcases an interactive sports training system that provides in-situ feedback while following a well-guided learning procedure.}}, 
pages = {1--4}, 
keywords = {}
}
@article{oshita2018sts, 
year = {2018}, 
rating = {3}, 
title = {{Self-Training System for Tennis Shots with Motion Feature Assessment and Visualization}}, 
author = {Oshita, Masaki and Inao, Takumi and Mukai, Tomohiko and Kuriyama, Shigeru}, 
journal = {2018 International Conference on Cyberworlds (CW)}, 
doi = {10.1109/cw.2018.00025}, 
abstract = {{This paper describes a prototype self-training system for tennis forehand shots that allows trainees to practice their motion forms by themselves. Our system uses a motion capture device to record a trainee's motion, and visualizes the differences between the features of the trainee's motion and the correct motion as performed by an expert. This system enables trainees to understand the errors in their motion and how to reduce or eliminate them. In this study, we classified the motion features and corresponding visualization methods using one-dimensional spatial, rotational, and temporal features based on the key sporting poses. We also developed a statistical model for the motion features, allowing the system to assess and prioritize all features of a trainee's motion. This research focuses on the motion of a tennis forehand shot and evaluates our prototype through several user experiments.}}, 
pages = {82--89}, 
keywords = {}
}
@article{afyouni2019rbg, 
year = {2019}, 
title = {{RehaBot: Gamified Virtual Assistants Towards Adaptive TeleRehabilitation}}, 
author = {Afyouni, Imad and Einea, Anas and Murad, Abdullah}, 
journal = {Adjunct Publication of the 27th Conference on User Modeling, Adaptation and Personalization - UMAP'19 Adjunct}, 
doi = {10.1145/3314183.3324988}, 
abstract = {{This paper introduces 'RehaBot', a framework for building adaptive serious games in the context of telerehabilitation. RehaBot takes advantage of 3D motion tracking and virtual reality devices, to develop an immersive and gamified telerehabilitation environment. A personalized and adaptive gaming system is developed, which allows patients to perform exercises with the help of embedded virtual assistants, hereafter called 'rehab bots', that are dynamically displayed within scenes to guide the patient through the different sets of gestures required to complete the session. These rehab bots have the ability to learn and adapt to the best level of difficulty in real-time based on the user performance. An intelligent alerting and automatic correction technique is incorporated within our engine, so that pre-calculated gesture patterns are correlated and matched with patients' gestures. Consequently, the system estimates the perceived difficulty of gestures by the patient, and automatically adjusts the game behavior to ensure a highly engaging and adaptive gaming experience. Furthermore, multimodal instructions are conveyed to users with details on joints that are not performing as expected, and to guide them towards improving the current gesture. A pilot study has been conducted to prove the usability and effectiveness of our adaptive physiotherapy solution.}}, 
pages = {21--26}, 
keywords = {}
}
@article{clarke2020rva, 
year = {2020}, 
title = {{Reactive Video: Adaptive Video Playback Based on User Motion for Supporting Physical Activity}}, 
author = {Clarke, Christopher and Cavdir, Doga and Chiu, Patrick and Denoue, Laurent and Kimber, Don}, 
journal = {Proceedings of the 33rd Annual ACM Symposium on User Interface Software and Technology}, 
doi = {10.1145/3379337.3415591}, 
abstract = {{Videos are a convenient platform to begin, maintain, or improve a fitness program or physical activity. Traditional video systems allow users to manipulate videos through specific user interface actions such as button clicks or mouse drags, but have no model of what the user is doing and are unable to adapt in useful ways. We present adaptive video playback, which seamlessly synchronises video playback with the user's movements, building upon the principle of direct manipulation video navigation. We implement adaptive video playback in Reactive Video, a vision-based system which supports users learning or practising a physical skill. The use of pre-existing videos removes the need to create bespoke content or specially authored videos, and the system can provide real-time guidance and feedback to better support users when learning new movements. Adaptive video playback using a discrete Bayes and particle filter are evaluated on a data set collected of participants performing tai chi and radio exercises. Results show that both approaches can accurately adapt to the user's movements, however reversing playback can be problematic.}}, 
pages = {196--208}, 
keywords = {}
}
@article{sekhavat2018pba, 
year = {2018}, 
title = {{Projection-Based AR: Effective Visual Feedback in Gait Rehabilitation}}, 
author = {Sekhavat, Yoones A. and Namani, Mohammad S.}, 
journal = {IEEE Transactions on Human-Machine Systems}, 
issn = {2168-2291}, 
doi = {10.1109/thms.2018.2860579}, 
abstract = {{Effective real-time feedback is crucial to enhance motor learning in physical and cognitive rehabilitation. Although monitor-based (MB) platforms are widely used to provide visual feedback for users, the discrepancy between where the feedback is presented and where the actual movement occurs can negatively affect the use of feedback. In this paper, we propose a novel visual feedback system using projection-based augmented reality (AR) to provide a better understanding of the relationship between body perception and movement kinematics. A set of experiments were performed to assess and compare the ability of unimpaired and impaired participants to detect real-time feedback and make modifications to gait using this feedback inMB and AR platforms. The results showed a significant improvement in participants ability to better adapt the changes in projection-based AR thanMB. This improvement represents the efficacy of this system in enabling users to better synchronize their footeye coordination.}}, 
pages = {626--636}, 
number = {6}, 
volume = {48}, 
keywords = {}
}
@article{yu2020pmd, 
year = {2020}, 
title = {{Perspective Matters: Design Implications for Motion Guidance in Mixed Reality}}, 
author = {Yu, Xingyao and Angerbauer, Katrin and Mohr, Peter and Kalkofen, Denis and Sedlmair, Michael}, 
journal = {2020 IEEE International Symposium on Mixed and Augmented Reality (ISMAR)}, 
doi = {10.1109/ismar50242.2020.00085}, 
abstract = {{We investigate how Mixed Reality (MR) can be used to guide human body motions, such as in physiotherapy, dancing, or workout applications. While first MR prototypes have shown promising results, many dimensions of the design space behind such applications remain largely unexplored. To better understand this design space, we approach the topic from different angles by contributing three user studies. In particular, we take a closer look at the influence of the perspective, the characteristics of motions, and visual guidance on different user performance measures. Our results indicate that a first-person perspective performs best for all visible motions, whereas the type of visual instruction plays a minor role. From our results we compile a set of considerations that can guide future work on the design of instructions, evaluations, and the technical setup of MR motion guidance systems.}}, 
pages = {577--587}, 
volume = {00}, 
keywords = {}
}
@article{hoang2016orp, 
year = {2016}, 
title = {{Onebody: Remote Posture Guidance System using First Person View in Virtual Environment}}, 
author = {Hoang, Thuong N and Reinoso, Martin and Vetere, Frank and Tanin, Egemen}, 
journal = {Proc. of the 9th Nordic Conference on Human-Computer Interaction}, 
doi = {10.1145/2971485.2971521}, 
abstract = {{We present Onebody, a virtual reality system for remote posture guidance during sports or physical activity training, such as martial arts, yoga or dance, using first person perspective. The system uses skeletal tracking of the instructor and the students, rendered as virtual avatars. Using a virtual reality headset, the student can visualise the movement of the instructor's avatar, rendered in place of their own body. Onebody provides a first person perspective of the movement instruction, allowing the student to step into the instructor's body. We conducted a study to compare the performance of Onebody in terms of posture matching accuracy and user's preference, with existing techniques of delivering movement instructions, including pre-recorded video, video conferencing and third person view virtual reality. The result indicated that Onebody offers better posture accuracy in delivering movement instructions.}}, 
pages = {1--10}, 
keywords = {}
}
@article{han2017mtc, 
year = {2017}, 
title = {{My Tai-Chi Coaches: An Augmented-Learning Tool for Practicing Tai-Chi Chuan}}, 
author = {Han, Ping-Hsuan and Chen, Yang-Sheng and Zhong, Yilun and Wang, Han-Lei and Hung, Yi-Ping}, 
journal = {Proceedings of the 8th Augmented Human International Conference}, 
doi = {10.1145/3041164.3041194}, 
abstract = {{Tai-Chi Chuan (TCC) is a famous physical exercise and well-known for being able to effectively promote physical well-being. Many people have been interested in learning TCC at the beginning, but eventually failed in mastering it due to the lack of a constantly accompanying master on the side. In this paper, we present an augmented-learning tool, called "My Tai-Chi Coaches", for learning TCC. By wearing an optical see-through Head-Mounted Display (HMD), the users can have their own private coaches-on-demand that will guide them in practicing TCC. To solve the "attention-sticking" problem, we propose the use of "redundant coaches" and high-lighting the primary coach at every instant. When the user wants to adjust his posture to mimic the coach's movement, he can simply suspend his motion, and then the drone will fly to a proper position to capture the images of the user's posture, and display them on an augmented mirror placed near by the highlighted or gazed coach. In addition to learning TCC, the proposed augmented-learning tool can also be used for learning dancing, yoga, sporting, and for rehabilitation.}}, 
pages = {1--4}, 
keywords = {}
}
@article{meyer2018jlc, 
year = {2018}, 
title = {{Juggling 4.0: Learning Complex Motor Skills with Augmented Reality Through the Example of Juggling}}, 
author = {Meyer, Benjamin and Gruppe, Pascal and Cornelsen, Bastian and Stratmann, Tim Claudius and Gruenefeld, Uwe and Boll, Susanne}, 
journal = {The 31st Annual ACM Symposium on User Interface Software and Technology Adjunct Proceedings}, 
doi = {10.1145/3266037.3266099}, 
abstract = {{Learning new motor skills is a problem that people are constantly confronted with (e.g. to learn a new kind of sport). In our work, we investigate to which extent the learning process of a motor sequence can be optimized with the help of Augmented Reality as a technical assistant. Therefore, we propose an approach that divides the problem into three tasks: (1) the tracking of the necessary movements, (2) the creation of a model that calculates possible deviations and (3) the implementation of a visual feedback system. To evaluate our approach, we implemented the idea by using infrared depth sensors and an Augmented Reality head-mounted device (HoloLens). Our results show that the system can give an efficient assistance for the correct height of a throw with one ball. Furthermore, it provides a basis for the support of a complete juggling sequence.}}, 
pages = {54--56}, 
note = {Really movement feedback?}, 
keywords = {}
}
@article{pereira2017jat, 
year = {2017}, 
title = {{Joint angles tracking for rehabilitation at home using inertial sensors}}, 
author = {Pereira, Ana and Guimarães, Vânia and Sousa, Inês}, 
journal = {Proceedings of the 11th EAI International Conference on Pervasive Computing Technologies for Healthcare}, 
doi = {10.1145/3154862.3154888}, 
abstract = {{Joint angles are commonly measured in physical rehabilitation to evaluate joint function. Evidences showed that wearable inertial sensors can accurately quantify human motion information, however, the most advanced and accurate methodologies require the execution of complex calibration movements which are unsuitable to inexpert users and inadequate for a home context. This way, four different joint angles estimation methods requiring no calibration movement were developed in order to track the main human body joint angles in real time. IMUs mounted in bracelets were used to restrict sensor positioning on the limbs. For six different exercises, the estimated absolute and relative joint angles were evaluated against the marker-based video tracking software Kinovea ground-truth. Correlation analysis between estimated and ground-truth joint angles indicated a very strong and statistically significant correlation. The average error in estimated joint angles is below 5 degrees for all four methods employed, which may be an acceptable result for the rehabilitation at home scenario.}}, 
pages = {146--154}, 
keywords = {}
}
@article{shiro2019ipv, 
year = {2019}, 
title = {{InterPoser: Visualizing Interpolated Movements for Bouldering Training}}, 
author = {Shiro, Keisuke and Egawa, Kazme and Miyaki, Takashi and Rekimoto, Jun}, 
journal = {2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)}, 
doi = {10.1145/3290607.3312779},
keywords = {}
}
@article{booth2019iei, 
year = {2019}, 
title = {{Immediate Effects of Immersive Biofeedback on Gait in Children With Cerebral Palsy}}, 
author = {Booth, Adam T. and Buizer, Annemieke I. and Harlaar, Jaap and Steenbrink, Frans and Krogt, Marjolein M. van der}, 
journal = {Archives of Physical Medicine and Rehabilitation}, 
issn = {0003-9993}, 
doi = {10.1016/j.apmr.2018.10.013}, 
pmid = {30447196}, 
abstract = {{Objective To investigate the immediate response to avatar-based biofeedback on 3 clinically important gait parameters: step length, knee extension, and ankle power in children with cerebral palsy (CP). Design Repeated measures design. Setting Rehabilitation clinic. Participants Children with spastic paresis (N=22; 10.5±3.1y), able to walk without assistive devices. Intervention Children walked on a treadmill with a virtual reality environment. Following baseline gait analysis, they were challenged to improve aspects of gait. Children visualized themselves as an avatar, representing movement in real time. They underwent a series of 2-minute trials receiving avatar-based biofeedback on step length, knee extension, and ankle power. To investigate optimization of biofeedback visualization, additional trials in which knee extension was visualized as a simple bar with no avatar; and avatar alone with no specific biofeedback were carried out. Main Outcome Measures Gait pattern, as measured by joint angles, powers, and spatiotemporal parameters, were compared between baseline and biofeedback trials. Results Participants were able to adapt gait pattern with biofeedback, in an immediate response, reaching large increases in ankle power generation at push-off (37.7\%) and clinically important improvements in knee extension (7.4o) and step length (12.7\%). Biofeedback on one parameter had indirect influence on other aspects of gait. Conclusion Children with CP show capacity in motor function to achieve improvements in clinically important aspects of gait. Visualizing biofeedback with an avatar was subjectively preferential compared to a simplified bar presentation of knee angle. Future studies are required to investigate if observed transient effects of biofeedback can be retained with prolonged training to test whether biofeedback-based gait training may be implemented as a therapy tool.}}, 
pages = {598--605}, 
number = {4}, 
volume = {100}, 
keywords = {}
}
@article{caserman2021fbm, 
year = {2021}, 
title = {{Full-Body Motion Recognition in Immersive Virtual Reality-based Exergame}}, 
author = {Caserman, Polona and Liu, Shule and Gobel, Stefan}, 
journal = {IEEE Transactions on Games}, 
issn = {2475-1502}, 
doi = {10.1109/tg.2021.3064749}, 
abstract = {{Exergames have beneficial effects on the player's motivation to exercise. However, many current games lack accurate full-body motion recognition, resulting in players not performing the physical exercise the game requires. Therefore, we aim to develop an immersive virtual reality exergame that simultaneously recognizes and reconstructs full-body movements to motivate players to learn and practice yoga. The system analyzes the entire movement execution and identifies the player's execution errors to provide appropriate feedback so that players can then improve their movements. Such a system can be used in exergames designed for rehabilitation purposes to assist patients or to monitor their improvement. To access recognition performance, we trained and tested hidden Markov models and applied the leave-one-out cross-validation. The results show that the system achieves an F1-score of 0.79 for yoga warrior I, 0.85 for yoga warrior II, and 0.66 for extended side angle. A user study with 32 participants revealed that the game was fun and that the players enjoyed it. Moreover, performance results show that players needed fewer attempts to correctly perform a pose as the exergame progressed.}}, 
pages = {1--1}, 
number = {99}, 
volume = {PP}, 
keywords = {}
}
@article{escalona2020eva, 
year = {2020}, 
title = {{EVA: EVAluating at-home rehabilitation exercises using augmented reality and low-cost sensors}}, 
author = {Escalona, Felix and Martinez-Martin, Ester and Cruz, Edmanuel and Cazorla, Miguel and Gomez-Donoso, Francisco}, 
journal = {Virtual Reality}, 
issn = {1359-4338}, 
doi = {10.1007/s10055-019-00419-4}, 
abstract = {{Over one billion people in the world live with some form of disability. This is incessantly increasing due to aging population and chronic diseases. Among the emerging social needs, rehabilitation services are the most required. However, they are scarce and expensive what considerably limits access to them. In this paper, we propose EVA, an augmented reality platform to engage and supervise rehabilitation sessions at home using low-cost sensors. It also stores the user’s statistics and allows therapists to tailor the exercise programs according to their performance. This system has been evaluated in both qualitative and quantitative ways obtaining very promising results.}}, 
pages = {567--581}, 
number = {4}, 
volume = {24}, 
keywords = {}
}
@misc{marti2019evl, 
year = {2019}, 
title = {{Erlernen des Vorwärtszyklus beim Laufen durch erhöhtes Feedback. Ein Vergleich des kinetischen Feedbacks und dem Videofeedback der Kontrollgruppe}}, 
author = {Marti, Kym Céline Sandra}, 
note = {Master's Thesis, Universität Freiburg, Schweiz},
keywords = {}
}
@article{furukawa2018dar, 
year = {2018}, 
title = {{Design of an AR-supported System for Skill Training}}, 
author = {Furukawa, Shiho and Uchibayashi, Toshihiro and Abe, Toru and Suganuma, Takuo}, 
journal = {2018 Tohoku-Section Joint Convention}, 
doi = {10.11528/tsjc.2018.0_213}, 
pages = {213--213}, 
keywords = {}
}
@article{conner2016cef, 
year = {2016}, 
title = {{Correcting Exercise Form Using Body Tracking}}, 
author = {Conner, Caleb and Poor, Gene Michael}, 
journal = {Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems}, 
doi = {10.1145/2851581.2892519}, 
abstract = {{In the past twenty years, there have been little to no advances in technology used for free weight exercises. However, with the advances of computer vision and the availability of technology such as the XBox Kinect, having computer assisted exercises are a definite possibility for gym experiences. In this paper we examine the possibility of using a real-time correcting tool for a user's form while performing a free weight exercise. The squat exercise was chosen because it is easily track-able due to its rigid and specific set of form specifications that allow it to be easily corrected. Through our pilot study we showed that a user could learn how to correctly perform an exercise and correct their form by using the feedback provided by our software.}}, 
pages = {3028--3034}, 
note = {No AR?}, 
keywords = {}
}
@article{raffe2018cst, 
year = {2018}, 
title = {{Combining Skeletal Tracking and Virtual Reality for Game-based Fall Prevention Training for the Elderly}}, 
author = {Raffe, William L. and Garcia, Jaime A.}, 
journal = {2018 IEEE 6th Int. Conf. on Serious Games and Applications for Health (SeGAH)}, 
doi = {10.1109/segah.2018.8401371}, 
abstract = {{This paper provides a preliminary appraisal of combining commercial skeletal tracking and virtual reality technologies for the purposes of innovative gameplay interfaces in fall prevention exergames for the elderly. This work uses the previously published StepKinnection game, which used skeletal tracking with a flat screen monitor, as a primary point of comparison for the proposed combination of these interaction modalities. Here, a Microsoft Kinect is used to track the player's skeleton and represent it as an avatar in the virtual environment while the HTC Vive is used for head tracking and virtual reality visualization. Multiple avatar positioning modes are trialled and discussed via a small self-reflective study (with the authors as participants) to examine their ability to allow accurate stepping motions, maintain physical comfort, and encourage self-identification or empathy with the avatar. While this is just an initial study, it highlights promising opportunities for designing engaging step training games with this integrated interface but also highlights its limitations, especially in the context of an unsupervised exercise program of older people in independent living situations.}}, 
pages = {1--7}, 
keywords = {}
}
@article{kosmalla2017cvi, 
year = {2017}, 
title = {{ClimbVis - Investigating In-situ Visualizations for Understanding Climbing Movements by Demonstration}}, 
author = {Kosmalla, Felix and Daiber, Florian and Wiehr, Frederik and Krüger, Antonio}, 
journal = {ISS '17: Proceedings of the 2017 ACM International Conference on Interactive Surfaces and Spaces}, 
doi = {10.1145/3132272.3134119}, 
abstract = {{Rock climbing involves complex movements and therefore requires guidance when acquiring a new technique. The classic approach is mimicking the movements of a more experienced climber. However, the trainee has to remember every nuance of the climb, since the sequence of movements cannot be performed in parallel to the experienced climber. As a solution to this problem, we present a video recording and replay system for climbing. The replay component allows for different in-situ video feedback methods. We investigated the video feedback component of the system by studying two example visualization techniques, i.e. a life-sized in-place projection and a real-time third-person view of the climber, augmented by a video showing a successful ascent. The latter is presented to the user on both Google Glass and a projected display. The results indicate that a life-sized projection was perceived as easiest to follow, while most of the climbers had problems with the context switches between the augmented video and the climbing wall. These findings can aid in the design of assistance systems that teach complex movements.}}, 
pages = {270--279}, 
keywords = {}
}
@article{vidal2020blo, 
year = {2020}, 
title = {{BodyLights: Open-Ended Augmented Feedback to Support Training Towards a Correct Exercise Execution}}, 
author = {Vidal, Laia Turmo and Zhu, Hui and Riego-Delgado, Abraham}, 
journal = {Proc. of the 2020 CHI Conf. on Human Factors in Comp. Sys.}, 
doi = {10.1145/3313831.3376268}, 
abstract = {{Technologies targeting a correct execution of physical training exercises typically use pre-determined models for what they consider correct, automatizing instruction and feedback. This falls short on catering to diverse trainees and exercises. We explore an alternative design approach, in which technology provides open-ended feedback for trainers and trainees to use during training. With a personal trainer we designed the augmentation of 18 strength training exercises with BodyLights: 3D printed wearable projecting lights that augment body movement and orientation. To study them, 15 trainees at different skill levels trained three times with our personal trainer and BodyLights. Our findings show that BodyLights catered to a wide range of trainees and exercises, and supported understanding, executing and correcting diverse technique parameters. We discuss design features and methodological aspects that allowed this; and what open-ended feedback offered in comparison to current technology approaches to support training towards a correct exercise execution.}}, 
pages = {1--14}, 
keywords = {}
}
@article{wiehr2016bce, 
year = {2016}, 
title = {{betaCube – Enhancing Training for Climbing by a Self-Calibrating Camera-Projection Unit}}, 
author = {Wiehr, Frederik and Kosmalla, Felix and Daiber, Florian and Krüger, Antonio}, 
journal = {Proceedings of the 2016 CHI Conference Extended Abstracts on Human Factors in Computing Systems}, 
doi = {10.1145/2851581.2892393}, 
abstract = {{In rock climbing, discussing climbing techniques with others to master a specific route and getting practical advice from more experienced climbers is an inherent part of the culture and tradition of the sport. Spatial information, such as the position of holds, as well as learning complex body postures plays a major role in this process. A typical problem that occurs during advising is an alignment effect when trying to picture orientation-specific knowledge, e.g. explaining how to perform a certain self-climbed move to others. We propose betaCube, a self-calibrating camera-projection unit that features 3D tracking and distortion-free projection. The system enables a life-sized video replay and climbing route creation using augmented reality. We contribute an interface for automatic setup of mobile distortion-free projection, blob detection for climbing holds, as well as an automatic method for extracting planar trackables from artificial climbing walls.}}, 
pages = {1998--2004}, 
keywords = {}
}
@article{barioni2019bvr, 
year = {2019}, 
title = {{BalletVR: a Virtual Reality System for Ballet Arm Positions Training}}, 
author = {Barioni, Ricardo R. and Costa, Willams and Aleluia, Alessandra and Teichrieb, Veronica}, 
journal = {2019 21st Symposium on Virtual and Augmented Reality (SVR)}, 
doi = {10.1109/svr.2019.00018}, 
abstract = {{In a ballet studio, the teacher plays an important role in the process of learning positions and movements. However, there are occasions where the student needs to practice while the teacher is unavailable. In this situation, the student has no orientation and is likely to create bad habits during training, which may lead to worse results than before. In this work, we present the BalletVR, a Virtual Reality Kinect-based application for guiding ballet dancers through the practice of basic ballet arm positions. The results show our system's potential to be used by students as an alternative for autonomous ballet basic positions training.}}, 
pages = {10--16}, 
volume = {00}, 
keywords = {}
}
@article{debarba2018arv, 
year = {2018}, 
title = {{Augmented Reality Visualization of Joint Movements for Physical Examination and Rehabilitation}}, 
author = {Debarba, Henrique Galvan and Oliveira, Marcelo Elias de and Lädermann, Alexandre and Chagué, Sylvain and Charbonnier, Caecilia}, 
journal = {2018 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)}, 
doi = {10.1109/vr.2018.8446368}, 
abstract = {{We present a visualization tool for human motion analysis in augmented reality. Our tool builds upon our previous work on joint biomechanical modelling for kinematic analysis, based on optical motion capture and personalized anatomical reconstruction of joint structures from medical imaging. It provides healthcare professionals with the in situ visualization of joint movements, where bones are accurately rendered as a holographic overlay on the subject - like if the user has an “X-ray vision” - and in real-time as the subject performs the movement. Currently, hip and knee joints are supported.}}, 
pages = {537--538}, 
volume = {00}, 
keywords = {}
}

@InProceedings{quevedo2017asr,
author = {Quevedo, Washington X.
and Ortiz, Jessica S.
and Velasco, Paola M.
and S{\'a}nchez, Jorge S.
and {\'A}lvarez V., Marcelo
and Rivas, David
and Andaluz, V{\'i}ctor H.},
editor={De Paolis, Lucio Tommaso
and Bourdot, Patrick
and Mongelli, Antonio},
title={Assistance System for Rehabilitation and Valuation of Motor Skills},
booktitle={Augmented Reality, Virtual Reality, and Computer Graphics},
year={2017},
publisher={Springer International Publishing},
address={Cham},
doi={10.1007/978-3-319-60928-7_14},
pages={166--174},
isbn={978-3-319-60928-7}
}

@article{han2016ara, 
year = {2016}, 
title = {{AR-Arm: Augmented Visualization for Guiding Arm Movement in the First-Person Perspective}}, 
author = {Han, Ping-Hsuan and Chen, Kuan-Wen and Hsieh, Chen-Hsin and Huang, Yu-Jie and Hung, Yi-Ping}, 
journal = {Proceedings of the 7th Augmented Human International Conference 2016}, 
doi = {10.1145/2875194.2875237}, 
abstract = {{In many activities, such as martial arts, physical exercise, and physiotherapy, the users are asked to perform a sequence of body movements with highly accurate arm positions. Sometimes, the movements are too complicated for users to learn, even by imitating the action of the coach directly. This paper presents a fully immersive augmented reality (AR) system, which provides egocentric hints to guide the arm movement of the user via a video see-through head-mounted display (HMD). By using this system, the user can perform the exactitude of arm movement simply by moving his arms to follow and match the virtual arms, rendered from coach's movement of database, in the first-person view. To ensure the rendered virtual arms correctly aligned with the user's real shoulders, a calibration method is proposed to estimate the length of the user's arms and the positions of his head and shoulders in advance. In addition, we apply the system to Tai-Chi-Chuan practicing, our preliminary study has shown that the proposed egocentric hints can provide intuitive guidance for users to follow the arm movement of the coach with exactitude.}}, 
pages = {1--4}, 
keywords = {}
}
@article{ikeda2018arb, 
year = {2018}, 
title = {{AR based Self-sports Learning System using Decayed Dynamic Time Warping Algorithm}}, 
author = {Ikeda, A. and Hwang, D.H. and Koike, H.}, 
journal = {Eurographics Symposium on Virtual Environments (2018)}, 
doi = {10.2312/egve.20181330}
}
@article{cao2020esa, 
year = {bernhaupt2020esa}, 
title = {{An Exploratory Study of Augmented Reality Presence for Tutoring Machine Tasks}}, 
author = {Cao, Yuanzhi and Qian, Xun and Wang, Tianyi and Lee, Rachel and Huo, Ke and Ramani, Karthik}, 
journal = {Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems}, 
doi = {10.1145/3313831.3376688}, 
abstract = {{Machine tasks in workshops or factories are often a compound sequence of local, spatial, and body-coordinated human-machine interactions. Prior works have shown the merits of video-based and augmented reality (AR) tutoring systems for local tasks. However, due to the lack of a bodily representation of the tutor, they are not as effective for spatial and body-coordinated interactions. We propose avatars as an additional tutor representation to the existing AR instructions. In order to understand the design space of tutoring presence for machine tasks, we conduct a comparative study with 32 users. We aim to explore the strengths/limitations of the following four tutor options: video, non-avatar-AR, half-body+AR, and full-body+AR. The results show that users prefer the half-body+AR overall, especially for the spatial interactions. They have a preference for the full-body+AR for the body-coordinated interactions and the non-avatar-AR for the local interactions. We further discuss and summarize design recommendations and insights for future machine task tutoring systems.}}, 
pages = {1--13}, 
keywords = {}
}
@article{afyouni2020arb, 
year = {2020}, 
title = {{Adaptive Rehabilitation Bots in Serious Games}}, 
author = {Afyouni, Imad and Murad, Abdullah and Einea, Anas}, 
journal = {Sensors 2020}, 
doi = {10.3390/s20247037}, 
pmid = {33316916}, 
abstract = {{In recent years, we have witnessed a growing adoption of serious games in telerehabilitation by taking advantage of advanced multimedia technologies such as motion capture and virtual reality devices. Current serious game solutions for telerehabilitation suffer form lack of personalization and adaptiveness to patients’ needs and performance. This paper introduces “RehaBot”, a framework for adaptive generation of personalized serious games in the context of remote rehabilitation, using 3D motion tracking and virtual reality environments. A personalized and versatile gaming platform with embedded virtual assistants, called “Rehab bots”, is created. Utilizing these rehab bots, all workout session scenes will include a guide with various sets of motions to direct patients towards performing the prescribed exercises correctly. Furthermore, the rehab bots employ a robust technique to adjust the workout difficulty level in real-time to match the patients’ performance. This technique correlates and matches the patterns of the precalculated motions with patients’ motions to produce a highly engaging gamified workout experience. Moreover, multimodal insights are passed to the users pointing out the joints that did not perform as anticipated along with suggestions to improve the current performance. A clinical study was conducted on patients dealing with chronic neck pain to prove the usability and effectiveness of our adjunctive online physiotherapy solution. Ten participants used the serious gaming platform, while four participants performed the traditional procedure with an active program for neck pain relief, for two weeks (10 min, 10 sessions/2 weeks). Feasibility and user experience measures were collected, and the results of experiments show that patients found our game-based adaptive solution engaging and effective, and most of them could achieve high accuracy in performing the personalized prescribed therapies.}}, 
pages = {7037}, 
number = {24}, 
volume = {20}, 
keywords = {}
}
@article{ikeda2019rtp, 
year = {2019}, 
title = {{A Real-Time Projection System for Golf Training using Virtual Shadow}}, 
author = {Ikeda, Atsuki and Hwang, Dong-Hyun and Koike, Hideki}, 
journal = {2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)}, 
doi = {10.1109/VR.2019.8798196}, 
keywords = {}
}
@article{oka2021rtf, 
year = {2021}, 
title = {{A Real Time Feedback System of Strength Training With Motion Capture and Head Mounted Display}}, 
author = {Oka, Mirai and Makino, Mitsunori}, 
journal = {Proceedings Volume 11766, International Workshop on Advanced Imaging Technology (IWAIT) 2021}, 
doi = {10.1117/12.2591035}, 
keywords = {}
}

@article{trepkowski2019enf, 
year = {2019}, 
title = {{The Effect of Narrow Field of View and Information Density on Visual Search Performance in Augmented Reality}}, 
author = {Trepkowski, Christina and Eibich, David and Maiero, Jens and Marquardt, Alexander and Kruijff, Ernst and Feiner, Steven}, 
journal = {2019 IEEE Conference on Virtual Reality and 3D User Interfaces (VR)}, 
doi = {10.1109/vr.2019.8798312}, 
abstract = {{Many optical-see-through displays have a relatively narrow field of view. However, a limited field of view can constrain how information can be presented and searched through. To understand these constraints, we present a series of experiments that address the interrelationships between field of view, information density, and search performance. We do so by simulating various fields of view using two approaches: limiting the field of view presented on a Microsoft HoloLens optical-see-through head-worn display and dynamically changing the portion of a large tiled-display wall on which information is presented, for head-tracked users in both cases. Our results indicate a significant effect of information density and field of view on search performance, with potential search performance benefits of using a larger FOV between ca. 7-28\%. Furthermore, while grids guided visual search, they did not significantly affect performance.}}, 
pages = {575--584}, 
keywords = {}
}
@article{Sawan2016MRS, 
year = {2020}, 
title = {{Mixed and Augmented Reality Applications in the Sport Industry}}, 
author = {Sawan, Nedal and Eltweri, Ahmed and Lucia, Caterina De and Cavaliere, Luigi Pio Leonardo and Faccia, Alessio and Moşteanu, Narcisa Roxana}, 
journal = {EBEE 2020 2nd International Conference on E-Business and E-commerce Engineering}, 
doi = {10.1145/3446922.3446932}, 
abstract = {{Augmented reality (AR) is already part of the lives of thousands of people, in many different sectors. In addition to a change in current business models, the introduction of this technology in sports can greatly implement and improve fan engagement strategies and the fan experience in the world of e-sports. This research, starting from a concise but systematic literature review, analyses how mixed and augmented reality are providing a growing number of applications in the world of sport. Augmented reality is a technology that allows having a better perception of reality. This can help drive a vehicle, see obstacles that would otherwise not be noticed. Given that the nature of augmented reality makes it perfect for a dynamic sector such as sports, many applications can be identified in the sports field, however, many benefits can be identified: a) training for professionals and amateurs; b) marketing strategies and revenue diversifications for sports clubs; c) supporters’ experience; d) supporters’ engagement; e) valid and feasible alternative during pandemic outbreaks; f) measurement of sports results and sports assessment. Augmented reality has been introduced in the sports sector for a while. Many sports are exploiting the features of this new technology, by introducing apps for augmented reality that allow fans to get even closer to their beloved sport heroes. Cycling, football, fitness, cricket, winter sports many others, Apps to increase reality are developed in many different contexts, to experience a race, a match or simply to train with greater awareness, thus obtaining better results.}}, 
pages = {55--59}, 
keywords = {}
}

@article{fitts1967HPe, 
year = {1967}, 
title = {{Human Performance}}, 
author = {Fitts, P.M. and Posner, M.I.}, 
journal = {Brooks/Cole}, 
url = {https://psycnet.apa.org/record/1967-35040-000}, 
abstract = {{Begun by Fitts, finished by Posner, this paperback provides an introduction to the topic of human performance. Harvard Book List (edited) 1971 \#658 (PsycINFO Database Record (c) 2016 APA, all rights reserved)}}, 
keywords = {}
}
@article{huber2013AEP, 
year = {2013}, 
title = {{Applying Educational Psychology in Coaching Athletes}}, 
author = {Huber, Jeffrey}, 
journal = {Human Kinetics}, 
url = {https://us.humankinetics.com/products/applying-educational-psychology-in-coaching-athletes}, 
keywords = {}
}
@book{stevenson2010oxford,
  title={Oxford Dictionary of English},
  author={Stevenson, A.},
  isbn={9780199571123},
  lccn={2010935310},
  series={Oxford Dictionary of English},
  url={https://books.google.de/books?id=anecAQAAQBAJ},
  year={2010},
  publisher={OUP Oxford}
}
@article{manuri2016SAA, 
	author = {Andrea Sanna and Federico Manuri},
	title = {A Survey on Applications of Augmented Reality},
	journal = {Advances in Computer Science : an International Journal},
	volume = {5},
	number = {1},
	year = {2016},
	keywords = {Augmented reality; Computer augmented environment; User interfaces; Head-mounted display; Mobile and ubiquitous computing.},
	abstract = {The term Augmented Reality (AR) refers to a set of technologies and devices able to enhance and improve human perception, thus bridging the gap between real and virtual space. Physical and artificial objects are mixed together in a hybrid space where the user can move without constraints. This mediated reality is spread in our everyday life: work, study, training, relaxation, time spent traveling are just some of the moments in which you can use AR applications.This paper aims to provide an overview of current technologies and future trends of augmented reality as well as to describe the main application domains, outlining benefits and open issues.},
	issn = {2322-5157},
	url = {http://www.acsij.org/acsij/article/view/400},
	pages = {18--27}
}
@article{viglialoro2019rar, 
year = {2019}, 
title = {{Review of the Augmented Reality Systems for Shoulder Rehabilitation}}, 
author = {Viglialoro, Rosanna Maria and Condino, Sara and Turini, Giuseppe and Carbone, Marina and Ferrari, Vincenzo and Gesi, Marco}, 
journal = {Information}, 
doi = {10.3390/info10050154}, 
abstract = {{Literature shows an increasing interest for the development of augmented reality (AR) applications in several fields, including rehabilitation. Current studies show the need for new rehabilitation tools for upper extremity, since traditional interventions are less effective than in other body regions. This review aims at: Studying to what extent AR applications are used in shoulder rehabilitation, examining wearable/non-wearable technologies employed, and investigating the evidence supporting AR effectiveness. Nine AR systems were identified and analyzed in terms of: Tracking methods, visualization technologies, integrated feedback, rehabilitation setting, and clinical evaluation. Our findings show that all these systems utilize vision-based registration, mainly with wearable marker-based tracking, and spatial displays. No system uses head-mounted displays, and only one system (11\%) integrates a wearable interface (for tactile feedback). Three systems (33\%) provide only visual feedback; 66\% present visual-audio feedback, and only 33\% of these provide visual-audio feedback, 22\% visual-audio with biofeedback, and 11\% visual-audio with haptic feedback. Moreover, several systems (44\%) are designed primarily for home settings. Three systems (33\%) have been successfully evaluated in clinical trials with more than 10 patients, showing advantages over traditional rehabilitation methods. Further clinical studies are needed to generalize the obtained findings, supporting the effectiveness of the AR applications.}}, 
pages = {154}, 
number = {5}, 
volume = {10}, 
keywords = {}
}
@article{brennan2019fdt, 
year = {2019}, 
title = {{Feedback Design in Targeted Exercise Digital Biofeedback Systems for Home Rehabilitation: A Scoping Review}}, 
author = {Brennan, Louise and Zubiete, Enrique Dorronzoro and Caulfield, Brian}, 
journal = {Sensors}, 
doi = {10.3390/s20010181}, 
pmid = {31905653}, 
abstract = {{Digital biofeedback systems (DBSs) are used in physical rehabilitation to improve outcomes by engaging and educating patients and have the potential to support patients while doing targeted exercises during home rehabilitation. The components of feedback (mode, content, frequency and timing) can influence motor learning and engagement in various ways. The feedback design used in DBSs for targeted exercise home rehabilitation, as well as the evidence underpinning the feedback and how it is evaluated, is not clearly known. To explore these concepts, we conducted a scoping review where an electronic search of PUBMED, PEDro and ACM digital libraries was conducted from January 2000 to July 2019. The main inclusion criteria included DBSs for targeted exercises, in a home rehabilitation setting, which have been tested on a clinical population. Nineteen papers were reviewed, detailing thirteen different DBSs. Feedback was mainly visual, concurrent and descriptive, frequently providing knowledge of results. Three systems provided clear rationale for the use of feedback. Four studies conducted specific evaluations of the feedback, and seven studies evaluated feedback in a less detailed or indirect manner. Future studies should describe in detail the feedback design in DBSs and consider a robust evaluation of the feedback element of the intervention to determine its efficacy.}}, 
pages = {181}, 
number = {1}, 
volume = {20}, 
keywords = {}
}
@article{neumann2018sra, 
year = {2018}, 
title = {{A systematic review of the application of interactive virtual reality to sport}}, 
author = {Neumann, David L. and Moffitt, Robyn L. and Thomas, Patrick R. and Loveday, Kylie and Watling, David P. and Lombard, Chantal L. and Antonova, Simona and Tremeer, Michael A.}, 
journal = {Virtual Reality}, 
issn = {1359-4338}, 
doi = {10.1007/s10055-017-0320-5}, 
abstract = {{Virtual reality (VR) technology is being increasingly used by athletes, coaches, and other sport-related professionals. The present systematic review aimed to document research on the application of VR to sport to better understand the outcomes that have emerged in this work. Research literature databases were searched, and the results screened to identify articles reporting applications of interactive VR to sport with healthy human participants. Twenty articles were identified and coded to document the study aims, research designs, participant characteristics, sport types, VR technology, measures, and key findings. From the review, it was shown that interactive VR applications have enhanced a range of performance, physiological, and psychological outcomes. The specific effects have been influenced by factors related to the athlete and the VR system, which comprise athlete factors, VR environment factors, task factors, and the non-VR environment factors. Important variables include the presence of others in the virtual environment, competitiveness, task autonomy, immersion, attentional focus, and feedback. The majority of research has been conducted on endurance sports, such as running, cycling, and rowing, and more research is required to examine the use of interactive VR in skill-based sports. Additional directions for future research and reporting standards for researchers are suggested.}}, 
pages = {183--198}, 
number = {3}, 
volume = {22}, 
keywords = {}
}
@book{schmidt2004motor,
  title={Motor Learning and Performance},
  author={Schmidt, R.A. and Wrisberg, C.A.},
  isbn={9780736045667},
  lccn={03025025},
  url={https://books.google.de/books?id=GUVqAAAAMAAJ},
  year={2004},
  publisher={Human Kinetics}, 
  pages = {11 pp.}
}
@article{SWINNEN1997749,
title = {Interlimb coordination: Learning and transfer under different feedback conditions},
journal = {Human Movement Science},
volume = {16},
number = {6},
pages = {749-785},
year = {1997},
issn = {0167-9457},
doi = {10.1016/S0167-9457(97)00020-1},
author = {Stephan P. Swinnen and Timothy D. Lee and Sabine Verschueren and Deborah J. Serrien and Hedwig Bogaerds},
keywords = {Motor learning, Interlimb coordination, Augmented feedback, Transfer, Specificity of learning},
abstract = {The role of intrinsic and extrinsic information feedback in learning a new bimanual coordination pattern was investigated. The pattern required continuous flexion-extension movements of the upper limbs with a 90 ° phase offset. Separate groups practiced the task under one of the following visual feedback conditions: (a) blindfolded (reduced FB group), (b) with normal vision (normal FB group), or (c) with concurrent relative motion information (enhanced FB group). All groups were subjected to three different transfer test conditions at regular intervals during practice. These tests included reduced, normal vision, and enhanced vision conditions. Experiment 1 showed that the group receiving augmented information feedback about its relative motions in real-time produced the required coordination pattern more successfully than the remaining two groups, irrespective of the transfer conditions under which performance was evaluated. Experiment 2 replicated and extended the superiority of the enhanced feedback group during acquisition and retention. Experiment 3 demonstrated that successful transfer to various transfer test conditions was not a result of test-trial effects. Overall, the data suggest that the conditions that optimized performance of the coordination pattern during acquisition also optimized transfer performance.}
}
@incollection{SINGER197879,
title = {Motor Skills and Learning Strategies},
editor = {HAROLD F. O'NEIL},
booktitle = {Learning Strategies},
publisher = {Academic Press},
pages = {79-106},
year = {1978},
isbn = {978-0-12-526650-5},
doi = {10.1016/B978-0-12-526650-5.50009-5},
author = {Robert N. Singer},
abstract = {Publisher Summary
This chapter discusses cognitive processes and learner strategies, and their involvement in the learning and performance of motor skills. The term motor skills have usually been with the physical, and in an athletic or recreational context. Yet, motor behaviors—also referred to as psychomotor or movement-oriented behaviors—permeate a wide variety of occupational and daily-living activities. At present, cognitive processes operate sequentially and serially to help produce skilled movement-performance. Some of them change in relative importance as skill is acquired. As the role of cognitive processes in the learning of various categories of tasks becomes revealed, the alternative and best strategies to enhance the operation of these processes can also be investigated and determined. Cognitive strategies represent, according to Gagné, one of five principal categories of learning outcomes; he further, distinguished motor skills from cognitive strategies. Subsequently, many strategies related to the learning of cognitive materials are similar to those involved in the mastery of motor skills. In addition, cognitions and strategies unique to psychomotor behaviors can be identified. It is noteworthy that current directions in cognitive psychology contrast traditional behavioristic thinking as to the active role learners play in expectations, perceptions, decision-making, interpreting feedback, making attributions to performance, arousal, memory and retrieval, and other processes. Taken together, the next step would seem to be a thorough analysis of the cognitive aspects of motor skill learning, with implications for learner strategies and training programs.}
}
@article{taylor2012rsm, 
year = {2012}, 
title = {{The role of strategies in motor learning}}, 
author = {Taylor, Jordan A. and Ivry, Richard B.}, 
journal = {Annals of the New York Academy of Sciences}, 
issn = {1749-6632}, 
doi = {10.1111/j.1749-6632.2011.06430.x}, 
pmid = {22329960}, 
pmcid = {PMC4330992}, 
abstract = {{There has been renewed interest in the role of strategies in sensorimotor learning. The combination of new behavioral methods and computational methods has begun to unravel the interaction between processes related to strategic control and processes related to motor adaptation. These processes may operate on very different error signals. Strategy learning is sensitive to goal-based performance error. In contrast, adaptation is sensitive to prediction errors between the desired and actual consequences of a planned movement. The former guides what the desired movement should be, whereas the latter guides how to implement the desired movement. Whereas traditional approaches have favored serial models in which an initial strategy-based phase gives way to more automatized forms of control, it now seems that strategic and adaptive processes operate with considerable independence throughout learning, although the relative weight given the two processes will shift with changes in performance. As such, skill acquisition involves the synergistic engagement of strategic and adaptive processes.}}, 
pages = {1--12}, 
number = {1}, 
volume = {1251}, 
keywords = {}
}
@book { ADictionaryofComputerScience,
      author = {Andrew Butterfield and Gerard Ekembe Ngondi and Anne Kerr},
      title = {A Dictionary of Computer Science},
      year = {2016},
      publisher = {Oxford University Press},
      isbn = {9780191768125},
      doi = {10.1093/acref/9780199688975.001.0001},
      url = {https://www.oxfordreference.com/view/10.1093/acref/9780199688975.001.0001/acref-9780199688975}
}
@article{whatIsMR,
author = {Speicher, Maximilian and Hall, Brian D. and Nebeling, Michael},
title = {What is Mixed Reality?},
year = {2019},
isbn = {9781450359702},
doi = {10.1145/3290605},
publisher = {Association for Computing Machinery},
journal = {Proceedings of the 2019 CHI Conference on Human Factors in Computing Systems},
address = {New York, NY, USA},
abstract = {What is Mixed Reality (MR)? To revisit this question given the many recent developments,
we conducted interviews with ten AR/VR experts from academia and industry, as well
as a literature survey of 68 papers. We find that, while there are prominent examples,
there is no universally agreed on, one-size-fits-all definition of MR. Rather, we
identified six partially competing notions from the literature and experts' responses.
We then started to isolate the different aspects of reality relevant for MR experiences,
going beyond the primarily visual notions and extending to audio, motion, haptics,
taste, and smell. We distill our findings into a conceptual framework with seven dimensions
to characterize MR applications in terms of the number of environments, number of
users, level of immersion, level of virtuality, degree of interaction, input, and
output. Our goal with this paper is to support classification and discussion of MR
applications' design and provide a better means to researchers to contextualize their
work within the increasingly fragmented MR landscape.},
pages = {1–15},
numpages = {15}
}

@article{oh2010defining,
  title={Defining exergames \& exergaming},
  author={Oh, Yoonsin and Yang, Stephen},
  journal={Proceedings of meaningful play},
  volume={2010},
  pages={21--23},
  year={2010}
}
@article{horst2019eun, 
year = {2019}, 
title = {{Explaining the unique nature of individual gait patterns with deep learning}}, 
author = {Horst, Fabian and Lapuschkin, Sebastian and Samek, Wojciech and Müller, Klaus-Robert and Schöllhorn, Wolfgang I.}, 
journal = {Scientific Reports}, 
doi = {10.1038/s41598-019-38748-8}, 
pmid = {30787319}, 
eprint = {1808.04308}, 
abstract = {{Machine learning (ML) techniques such as (deep) artificial neural networks (DNN) are solving very successfully a plethora of tasks and provide new predictive models for complex physical, chemical, biological and social systems. However, in most cases this comes with the disadvantage of acting as a black box, rarely providing information about what made them arrive at a particular prediction. This black box aspect of ML techniques can be problematic especially in medical diagnoses, so far hampering a clinical acceptance. The present paper studies the uniqueness of individual gait patterns in clinical biomechanics using DNNs. By attributing portions of the model predictions back to the input variables (ground reaction forces and full-body joint angles), the Layer-Wise Relevance Propagation (LRP) technique reliably demonstrates which variables at what time windows of the gait cycle are most relevant for the characterisation of gait patterns from a certain individual. By measuring the time-resolved contribution of each input variable to the prediction of ML techniques such as DNNs, our method describes the first general framework that enables to understand and interpret non-linear ML methods in (biomechanical) gait analysis and thereby supplies a powerful tool for analysis, diagnosis and treatment of human gait.}}, 
pages = {2391}, 
number = {1}, 
volume = {9}, 
keywords = {}
}


@article{morone2021dab,
author = {Giovanni Morone and Sheida Ghanbari Ghooshchy and Angela Palomba and Alessio Baricich and Andrea Santamato and Chiara Ciritella and Irene Ciancarelli and Franco Molteni and Francesca Gimigliano and Giovanni Iolascon and Pierluigi Zoccolotti and Stefano Paolucci and Marco Iosa},
title = {Differentiation among bio- and augmented- feedback in technologically assisted rehabilitation},
journal = {Expert Review of Medical Devices},
volume = {18},
number = {6},
pages = {513-522},
year  = {2021},
publisher = {Taylor \& Francis},
doi = {10.1080/17434440.2021.1927704},
note ={PMID: 33960257},
}

@article{hattie:2007:Feedback,
author = {John Hattie and Helen Timperley},
title ={The Power of Feedback},
journal = {Review of Educational Research},
volume = {77},
number = {1},
pages = {81-112},
year = {2007},
doi = {10.3102/003465430298487}
}


@article{Lysakowski:1982:Feedback,
author = {Richard S Lysakowski and Herbert J Walberg},
title ={Instructional Effects of Cues, Participation, and Corrective Feedback: A Quantitative Synthesis},
journal = {American Educational Research Journal},
volume = {19},
number = {4},
pages = {559-572},
year = {1982},
doi = {10.3102/00028312019004559},
}
@article{gupta2019stt, 
year = {2019}, 
title = {{A Survey on Tracking Techniques in Augmented Reality based Application}}, 
author = {Gupta, Sidharth and Chaudhary, Reshab and Gupta, Suryansh and Kaur, Amanpreet and Mantri, Archana}, 
journal = {2019 Fifth International Conference on Image Information Processing (ICIIP)}, 
doi = {10.1109/iciip47207.2019.8985779}, 
abstract = {{Augmented Reality (AR) is a process where the computerized information is â€œaugmentâ€ into the real or the physical world. This helps us in better understanding of the process and has numerous applications. The scope of AR is practically unlimited in today's world and if implemented, would help in solving many complex problems in an easy manner. This paper explains the applications of AR in multiple areas. The paper lays stress on six such major areas where the field of AR is flourished. The important milestones in the history of AR are discussed in this paper. Tracking is one of the thrust areas in the field of AR. A thorough survey is conducted on different types of tracking techniques that are used for development of AR applications. The paper is concluded in the form of comparative analysis between different types of sensor based tracking techniques and vision based tracking techniques. Hybridization of different types of tracking techniques is one of the best solutions for an accurate and robust tracking to meet the stringent requirements of AR applications.}}, 
pages = {215--220}, 
volume = {00}, 
keywords = {}
}
@article{liebermann2002aai, 
year = {2002}, 
title = {{Advances in the application of information technology to sport performance}}, 
author = {Liebermann, Dario G. and Katz, Larry and Hughes, Mike D. and Bartlett, Roger M. and McClements, Jim and Franks, Ian M.}, 
journal = {Journal of Sports Sciences}, 
issn = {0264-0414}, 
doi = {10.1080/026404102320675611}, 
pmid = {12363293}, 
abstract = {{This paper overviews the diverse information technologies that are used to provide athletes with relevant feedback. Examples taken from various sports are used to illustrate selected applications of technology-based feedback. Several feedback systems are discussed, including vision, audition and proprioception. Each technology described here is based on the assumption that feedback would eventually enhance skill acquisition and sport performance and, as such, its usefulness to athletes and coaches in training is critically evaluated.}}, 
pages = {755--769}, 
number = {10}, 
volume = {20}, 
keywords = {}
}
@article{elsayed2021cra, 
year = {2021}, 
title = {{CameraReady: Assessing the Influence of Display Types and Visualizations on Posture Guidance}}, 
author = {Elsayed, Hesham and Hoffmann, Philipp and GÃ¼nther, Sebastian and Schmitz, Martin and Weigel, Martin and MÃ¼hlhÃ¤user, Max and MÃ¼ller, Florian}, 
journal = {DIS '21: Designing Interactive Systems Conference 2021}, 
doi = {10.1145/3461778.3462026}, 
abstract = {{Computer-supported posture guidance is used in sports, dance training, expression of art with movements, and learning gestures for interaction. At present, the influence of display types and visualizations have not been investigated in the literature. These factors are important as they directly impact perception and cognitive load, and hence influence the performance of participants. In this paper, we conducted a controlled experiment with 20 participants to compare the use of five display types with different screen sizes: smartphones, tablets, desktop monitors, TVs, and large displays. On each device, we compared three common visualizations for posture guidance: skeletons, silhouettes, and 3d body models. To conduct our assessment, we developed a mobile and cross-platform system that only requires a single camera. Our results show that compared to a smartphone display, larger displays show a lower error (12\%). Regarding the choice of visualization, participants rated 3D body models as significantly more usable in comparison to a skeleton visualization.}}, 
keywords = {}
}
@article{mubin2020esg, 
year = {2020}, 
title = {{Exploring serious games for stroke rehabilitation: a scoping review}}, 
author = {Mubin, Omar and Alnajjar, Fady and Mahmud, Abdullah Al and Jishtu, Nalini and Alsinglawi, Belal}, 
journal = {Disability and Rehabilitation: Assistive Technology}, 
issn = {1748-3107}, 
doi = {10.1080/17483107.2020.1768309}, 
pmid = {32508187}, 
abstract = {{Aims and Objectives: Stroke is the main cause of long-term disabilit and happens mostly in the older population. Stroke affected patients experience either of the cognitive, visual or motor losses and recovery requires time and patience as they have to do physical exercises every day and at times repetitively. There are various types of stroke rehabilitation exercises focussing on technological solutions that include therapies performed using games. Motion-based games are popular in encouraging participants to perform repetitive tasks without being getting bored. Therefore, in this study, we have explored studies that included the use of games for stroke rehabilitation to understand the design principles and characteristics of the games used for these purposes. Method: A number of medical respositories were searched for relevant articles in a window of 2008-2018. 18 studies were chosen for the scoping review depending on the inclusion criteria, and design principles used in these studies are analysed and evaluated. Results and Conclusion: We present main findings from our review concerning the attributes of existing games for stroke rehabilitation such as meaningful play, handling of failures, emphasising challenge, and the value of feedback. We conclude with a list of design recommendations that future serious game developers can consider while designing interfaces for stroke patients.}}, 
pages = {1--7}, 
keywords = {}
}
@article{perin2018sas, 
year = {2018}, 
title = {{State of the Art of Sports Data Visualization}}, 
author = {Perin, C. and Vuillemot, R. and Stolper, C. D. and Stasko, J. T. and Wood, J. and Carpendale, S.}, 
journal = {Computer Graphics Forum}, 
issn = {0167-7055}, 
doi = {10.1111/cgf.13447}, 
abstract = {{In this report, we organize and reflect on recent advances and challenges in the field of sports data visualization. The exponentiallyâ€growing body of visualization research based on sports data is a prime indication of the importance and timeliness of this report. Sports data visualization research encompasses the breadth of visualization tasks and goals: exploring the design of new visualization techniques; adapting existing visualizations to a novel domain; and conducting design studies and evaluations in close collaboration with experts, including practitioners, enthusiasts, and journalists. Frequently this research has impact beyond sports in both academia and in industry because it is i) grounded in realistic, highly heterogeneous data, ii) applied to realâ€world problems, and iii) designed in close collaboration with domain experts. In this report, we analyze current research contributions through the lens of three categories of sports data: box score data (data containing statistical summaries of a sport event such as a game), tracking data (data about inâ€game actions and trajectories), and metaâ€data (data about the sport and its participants but not necessarily a given game). We conclude this report with a highâ€level discussion of sports visualization research informed by our analysisâ€”identifying critical research gaps and valuable opportunities for the visualization community. More information is available at the STAR's website: https://sportsdataviz.github.io/.}}, 
pages = {663--686}, 
number = {3}, 
volume = {37}, 
keywords = {}
}
@article{rutkowski2020uvr, 
year = {2020}, 
title = {{Use of virtual reality-based training in different fields of rehabilitation: A systematic review and meta-analysis}}, 
author = {Rutkowski, S and Kiper, P and Cacciante, L and Cieślik, B and Mazurek, J and Turolla, A and Szczepańska-Gieracha, J}, 
journal = {Journal of Rehabilitation Medicine}, 
doi = {10.2340/16501977-2755}, 
pmid = {33073855}, 
abstract = {{To analyse the effectiveness of virtual reality-based interventions within several fields of rehabilitation, and to investigate whether the outcomes of virtual reality-based interventions, in terms of upper or lower limb function, gait and balance, differ with respect to the virtual reality system used.}}, 
pages = {jrm00121}, 
number = {11}, 
volume = {52}, 
keywords = {}
}
@article{ma2011vrp, 
year = {2011}, 
title = {{Virtual Reality and Serious Games in Healthcare
}}, 
author = {Ma, Minhua and Zheng, Huiru}, 
journal = {Advanced Computational Intelligence Paradigms in Healthcare 6. Virtual Reality in Psychotherapy, Rehabilitation, and Assessment}, 
issn = {1860-949X}, 
doi = {10.1007/978-3-642-17824-5_9}, 
abstract = {{This chapter discusses the applications and solutions of emerging Virtual Reality (VR) and video games technologies in the healthcare sector, e.g. physical therapy for motor rehabilitation, exposure therapy for psychological phobias, and pain relief. Section 2 reviews state-of-the-art interactive devices used in current VR systems and high-end games such as sensor-based and camera-based tracking devices, data gloves, and haptic force feedback devices. Section 3 investigates recent advances and key concepts in games technology, including dynamic simulation, flow theory, adaptive games, and their possible implementation in serious games for healthcare. Various serious games are described in this section: some were designed and developed for specific healthcare purposes, e.g. BreakAway (2009)â€™s Free Dive, HopeLab (2006)â€™s Re-Mission, and Ma et al. (2007)â€™s VR game series, others were utilising off-the-shelf games such as Nintendo Wii sports for physiotherapy. A couple of experiments of using VR systems and games for stroke rehabilitation are highlighted in section 4 as examples to showcase the benefits and impacts of these technologies to conventional clinic practice. Finally, section 5 points some future directions of applying emerging games technologies in healthcare, such as augmented reality, Wii-mote motion control system, and even full body motion capture and controller free games technology demonstrated recently on E3 2009 which have great potentials to treat motor disorders, combat obesity, and other healthcare applications.}}, 
pages = {169--192}, 
keywords = {}
}
@article{tuah2021sgh, 
year = {2021}, 
title = {{A Survey on Gamification for Health Rehabilitation Care: Applications, Opportunities, and Open Challenges}}, 
author = {Tuah, Nooralisa Mohd and Ahmedy, Fatimah and Gani, Abdullah and Yong, Lionelson Norbert}, 
journal = {Information}, 
doi = {10.3390/info12020091}, 
abstract = {{Research trends in gamification have shown a significant diversity in various areas of e-health, particularly in addressing the issues of rehabilitation and physical activity. Rehabilitation requires better engaging tools that help to increase the patientâ€™s motivation and engagement in particular forms of rehabilitation training. Adopting gamification in rehabilitation offers different treatment and care environments when implementing rehabilitation training. As gamification is increasingly being explored in rehabilitation, one might not realize that using various techniques in gamified applications yields a different effect on gameplay. To date, varied gamification techniques have been utilized to provide useful experiences from the perspective of health applications. However, a limited number of surveys have investigated the gamification of rehabilitation and the use of suitable game techniques for rehabilitation in the literature. The objective of this paper is to examine and analyze the existing gamification techniques for rehabilitation applications. A classification of rehabilitation gamification is developed based on the rehabilitation gamifying requirements and the gamification characteristics that are commonly applied in rehabilitation applications. This classification is the main contribution of this paper. It provides insight for researchers and practitioners into suitable techniques to design and apply gamification with increased motivation and sustainable engagement for rehabilitation treatment and care. In addition, different game elements, selection blocks, and gamification techniques are identified for application in rehabilitation. In conclusion, several challenges and research opportunities are discussed to improve gamification deployment in rehabilitation in the future.}}, 
pages = {91}, 
number = {2}, 
volume = {12},
keywords = {}
}
@article{kim2019srv, 
year = {2019}, 
title = {{A Systematic Review of a Virtual Reality System from the Perspective of User Experience}}, 
author = {Kim, Yong Min and Rhiu, Ilsun and Yun, Myung Hwan}, 
journal = {International Journal of Humanâ€“Computer Interaction}, 
issn = {1044-7318}, 
doi = {10.1080/10447318.2019.1699746}, 
abstract = {{Virtual reality (VR) is receiving attention enough to be considered as its revival age in both industrial and academic field. Since VR systems have various types of interaction with users and new types of interaction are constantly being developed, various studies investigating user experience (UX) of VR systems are continuously needed. However, there is still a lack of research on the taxonomy that can recognize the main characteristics of VR system at a glance by reflecting the influencing factors of UX. Therefore, we collected and reviewed the research related to the UX evaluation of the VR system in order to identify the current research status and to suggest future research direction. To achieve this, a systematic review was conducted on UX studies for VR, and taxonomies of VR system including influencing factors of UX were proposed. A total of 393 unique articles were collected, and 65 articles were selected to be reviewed via Systematic Reviews and Meta-Analyses methodology. The selected articles were analyzed according to predefined taxonomies. As a result, current status of research can be identified base on the proposed taxonomies. Besides, issues related to VR devices and technology, and research method for future research directions can be suggested.}}, 
pages = {1--18}, 
number = {10}, 
volume = {36}, 
keywords = {}
}
@article{schiza2019vra, 
year = {2019}, 
title = {{Virtual Reality Applications for Neurological Disease: A Review}}, 
author = {Schiza, Eirini and Matsangidou, Maria and Neokleous, Kleanthis and Pattichis, Constantinos S.}, 
journal = {Frontiers in Robotics and AI}, 
doi = {10.3389/frobt.2019.00100}, 
pmid = {33501115}, 
pmcid = {PMC7806052}, 
abstract = {{Recent advancements in Virtual Reality (VR) immersive technologies provide new tools for the development of novel and promising applications for neurological rehabilitation. The purpose of this paper is to review the emerging VR applications developed for the evaluation and treatment of patients with neurological diseases. We start by discussing the impact of novel VR tasks that encourage and facilitate the patient's empowerment and involvement in the rehabilitation process. Then, a systematic review was carried out on six well-known electronic libraries using the terms: â€œVirtual Reality AND Neurorehabilitation,â€ or â€œHead Mounted Display AND Neurorehabilitation.â€ This review focused on fully-immersive VR systems for which 12 relevant studies published in the time span of the last five years (from 2014 to 2019) were identified. Overall, this review paper examined the use of VR in certain neurological conditions such as dementia, stroke, spinal cord injury, Parkinson's, and multiple sclerosis. Most of the studies reveal positive results suggesting that VR is a feasible and effective tool in the treatment of neurological disorders. In addition, the finding of this systematic literature review suggested that low-cost, immersive VR technologies can prove to be effective for clinical rehabilitation in healthcare, and home-based setting with practical implications and uses. The development of VR technologies in recent years has resulted in more accessible and affordable solutions that can still provide promising results. Concluding, VR and interactive devices resulted in the development of holistic, portable, accessible, and usable systems for certain neurological disease interventions. It is expected that emerging VR technologies and tools will further facilitate the development of state of the art applications in the future, exerting a significant impact on the wellbeing of the patient.}}, 
pages = {100}, 
volume = {6}, 
keywords = {}
}
@article{milgram1994arc,
author = {Milgram, Paul and Takemura, Haruo and Utsumi, Akira and Kishino, Fumio},
year = {1994},
month = {01},
pages = {},
title = {Augmented reality: A class of displays on the reality-virtuality continuum},
volume = {2351},
journal = {Telemanipulator and Telepresence Technologies},
doi = {10.1117/12.197321}
}
@article{gandhi2020mts, 
year = {2020}, 
title = {{Mirror Therapy in Stroke Rehabilitation: Current Perspectives}}, 
author = {Gandhi, Dorcas BC and Sterba, Albert and Khatter, Himani and Pandian, Jeyaraj D}, 
journal = {Therapeutics and Clinical Risk Management}, 
issn = {1176-6336}, 
doi = {10.2147/tcrm.s206883}, 
pmid = {32103968}, 
pmcid = {PMC7012218}, 
abstract = {{In contrast to varied therapy approaches, mirror therapy (MT) can be used even in completely plegic stroke survivors, as it uses visual stimuli for producing a desired response in the affected limb. MT has been studied to have effects not just on motor impairments but also on sensations, visuospatial neglect, and pain after stroke. This paper attempts to systematically review and present the current perspectives on mirror therapy and its application in stroke rehabilitation, and dosage, feasibility and acceptability in stroke rehabilitation. An electronic database search across Google, PubMed, Web of Science, etc., generated 3871 results. After screening them based on the inclusion and exclusion criteria, we included 28 studies in this review. The data collected were divided on the basis of application in stroke rehabilitation, modes of intervention delivery, and types of control and outcome assessment. We found that most studies intervened for upper limb motor impairments post stroke. Studies were equally distributed between intervention in chronic and acute phases post stroke with therapy durations lasting between 1 and 8 weeks. MT showed definitive motor and sensory improvements although the extent of improvements in sensory impairments and hemineglect is limited. MT proves to be an effective and feasible approach to rehabilitate post-stroke survivors in the acute, sub-acute, and chronic phases of stroke, although its long-term effects and impact on activities of daily living need to be analysed extensively.}}, 
pages = {75--85}, 
volume = {16}, 
note = {Added after review / Solely on Mirror Therapy, no visual feedback, very medical}, 
keywords = {}
}

@article{hilton2011dem, 
year = {2011}, 
title = {{Development and Evaluation of a Mixed Reality System for Stroke Rehabilitation}}, 
author = {Hilton, Dave and Cobb, Sue and Pridmore, Tony and Gladman, John and Edmans, Judi}, 
journal = {Studies in Computational Intelligence}, 
issn = {1860-949X}, 
doi = {10.1007/978-3-642-17824-5_10}, 
abstract = {{Computer simulations are gaining interest from researchers and therapists involved in stroke rehabilitation because they offer a means to monitor user activity and replicate tasks within safe and controlled environments. We developed a virtual environment (VE) to simulate the potentially hazardous task of making a hot drink. A three dimensional representation of a kitchen, including objects and utensils, was displayed on a computer screen and controlled through a touch screen interface. We also developed a user interface that employed real, physical kitchen objects, adapted in order to provide the computer with spatial and orientation data through a combination of motion sensors and a computer vision system. This tactile interface technology is known as a tangible user interface (TUI) and together with a VE comprises a mixed reality (MR) system. The MR system described here enabled users to perform naturalistic upper limb movements in order to interact with the task simulation. In this chapter we explain how the VE and MR systems were developed through a user-centred design process that involved the participation of consultants, clinicians and stroke survivors. Case examples of feasibility and evaluation studies using both the VE and MR systems are presented and discussed. Recommendations for the design and development of MR systems specifically for stroke rehabilitation are included.}}, 
pages = {193--228}, 
keywords = {}
}
@article{davies2003vrf, 
year = {2003}, 
title = {{Virtual Reality and Full Scale Modelling – a large Mixed Reality system for Participatory Design}}, 
author = {Davies, Roy C. and Dalholm, Elisabeth and Mitchell, Birgitta and Tate, Paul}, 
journal = {Space Requirements for Wheeled Mobility: An International Workshop}, 
keywords = {}
}
@article{greenhalgh2005ees, 
year = {2005}, 
title = {{Effectiveness and efficiency of search methods in systematic reviews of complex evidence: audit of primary sources}}, 
author = {Greenhalgh, Trisha and Peacock, Richard}, 
journal = {BMJ}, 
issn = {0959-8138}, 
doi = {10.1136/bmj.38636.593461.68}, 
pmid = {16230312}, 
abstract = {{Objective To describe where papers come from in a systematic review of complex evidence. Method Audit of how the 495 primary sources for the review were originally identified. Results Only 30\% of sources were obtained from the protocol defined at the outset of the study (that is, from the database and hand searches). Fifty one per cent were identified by “snowballing” (such as pursuing references of references), and 24\% by personal knowledge or personal contacts. Conclusion Systematic reviews of complex evidence cannot rely solely on protocol-driven search strategies.}}, 
pages = {1064}, 
number = {7524}, 
volume = {331}, 
keywords = {}
}
@article{badampudi2015eus, 
year = {2015}, 
title = {{Experiences from using snowballing and database searches in systematic literature studies}}, 
author = {Badampudi, Deepika and Wohlin, Claes and Petersen, Kai}, 
journal = {Proceedings of the 19th International Conference on Evaluation and Assessment in Software Engineering}, 
doi = {10.1145/2745802.2745818}, 
abstract = {{Background: Systematic literature studies are commonly used in software engineering. There are two main ways of conducting the searches for these type of studies; they are snowballing and database searches. In snowballing, the reference list (backward snowballing - BSB) and citations (forward snowballing - FSB) of relevant papers are reviewed to identify new papers whereas in a database search, different databases are searched using predefined search strings to identify new papers. Objective: Snowballing has not been in use as extensively as database search. Hence it is important to evaluate its efficiency and reliability when being used as a search strategy in literature studies. Moreover, it is important to compare it to database searches. Method: In this paper, we applied snowballing in a literature study, and reflected on the outcome. We also compared database search with backward and forward snowballing. Database search and snowballing were conducted independently by different researchers. The searches of our literature study were compared with respect to the efficiency and reliability of the findings. Results: Out of the total number of papers found, snowballing identified 83\% of the papers in comparison to 46\% of the papers for the database search. Snowballing failed to identify a few relevant papers, which potentially could have been addressed by identifying a more comprehensive start set. Conclusion: The efficiency of snowballing is comparable to database search. It can potentially be more reliable than a database search however, the reliability is highly dependent on the creation of a suitable start set.}}, 
pages = {1--10}, 
keywords = {}
}
@article{wohlin2014gss, 
year = {2014}, 
title = {{Guidelines for snowballing in systematic literature studies and a replication in software engineering}}, 
author = {Wohlin, Claes}, 
journal = {Proc. of the 18th International Conference on Evaluation and Assessment in Software Engineering - EASE '14}, 
doi = {10.1145/2601248.2601268}, 
abstract = {{Background: Systematic literature studies have become common in software engineering, and hence it is important to understand how to conduct them efficiently and reliably. Objective: This paper presents guidelines for conducting literature reviews using a snowballing approach, and they are illustrated and evaluated by replicating a published systematic literature review. Method: The guidelines are based on the experience from conducting several systematic literature reviews and experimenting with different approaches. Results: The guidelines for using snowballing as a way to search for relevant literature was successfully applied to a systematic literature review. Conclusions: It is concluded that using snowballing, as a first search strategy, may very well be a good alternative to the use of database searches.}}, 
pages = {38}, 
keywords = {}
}
@article{liberati2009prisma, 
year = {2009}, 
title = {{The PRISMA statement for reporting systematic reviews and meta-analyses of studies that evaluate health care interventions: explanation and elaboration}}, 
author = {Liberati, Alessandro and Altman, Douglas G. and Tetzlaff, Jennifer and Mulrow, Cynthia and Gøtzsche, Peter C. and Ioannidis, John P.A. and Clarke, Mike and Devereaux, P.J. and Kleijnen, Jos and Moher, David}, 
journal = {Journal of Clinical Epidemiology}, 
issn = {0895-4356}, 
doi = {10.1016/j.jclinepi.2009.06.006}, 
pmid = {19631507}, 
abstract = {{ Systematic reviews and meta-analyses are essential to summarize evidence relating to efficacy and safety of health care interventions accurately and reliably. The clarity and transparency of these reports, however, is not optimal. Poor reporting of systematic reviews diminishes their value to clinicians, policy makers, and other users. Since the development of the QUOROM (QUality Of Reporting Of Meta-analysis) Statement—a reporting guideline published in 1999—there have been several conceptual, methodological, and practical advances regarding the conduct and reporting of systematic reviews and meta-analyses. Also, reviews of published systematic reviews have found that key information about these studies is often poorly reported. Realizing these issues, an international group that included experienced authors and methodologists developed PRISMA (Preferred Reporting Items for Systematic reviews and Meta-Analyses) as an evolution of the original QUOROM guideline for systematic reviews and meta-analyses of evaluations of health care interventions. The PRISMA Statement consists of a 27-item checklist and a four-phase flow diagram. The checklist includes items deemed essential for transparent reporting of a systematic review. In this Explanation and Elaboration document, we explain the meaning and rationale for each checklist item. For each item, we include an example of good reporting and, where possible, references to relevant empirical studies and methodological literature. The PRISMA Statement, this document, and the associated Web site (http://www.prisma-statement.org/) should be helpful resources to improve reporting of systematic reviews and meta-analyses.}}, 
pages = {e1--e34}, 
number = {10}, 
volume = {62}, 
keywords = {}
}
@article{wolpert2001ppm, 
year = {2001}, 
title = {{Perspectives and problems in motor learning}}, 
author = {Wolpert, Daniel M. and Ghahramani, Zoubin and Flanagan, J. Randall}, 
journal = {TRENDS in Cognitive Sciences}, 
doi = {10.1016/s1364-6613(00)01773-3}, 
keywords = {}
}
@article{booth2019msr, 
year = {2019}, 
title = {{Muscle Synergies in Response to Biofeedback-Driven Gait Adaptations in Children With Cerebral Palsy}}, 
author = {Booth, Adam T. C. and Krogt, Marjolein M. van der and Harlaar, Jaap and Dominici, Nadia and Buizer, Annemieke I.}, 
journal = {Frontiers in Physiology}, 
issn = {1664-042X}, 
doi = {10.3389/fphys.2019.01208}, 
pmid = {31611807}, 
pmcid = {PMC6776587}, 
abstract = {{Children with cerebral palsy (CP) often show impaired selective motor control (SMC) that induces limitations in motor function. Children with CP can improve aspects of pathological gait in an immediate response to visual biofeedback. It is not known, however, how these gait adaptations are achieved at the neural level, nor do we know the extent of SMC plasticity in CP. Investigate the underlying SMC and changes that may occur when gait is adapted with biofeedback. Twenty-three ambulatory children with CP and related (hereditary) forms of spastic paresis (Aged: 10.4 ± 3.1, 6–16 years, M: 16/F: 9) were challenged with real-time biofeedback to improve step length, knee extension, and ankle power while walking on an instrumented treadmill in a virtual reality environment. The electromyograms of eight superficial muscles of the leg were analyzed and synergies were further decomposed using non-negative matrix factorization (NNMF) using 1 to 5 synergies, to quantify SMC. Total variance accounted for (tVAF) was used as a measure of synergy complexity. An imposed four synergy solution was investigated further to compare similarity in weightings and timing patterns of matched paired synergies between baseline and biofeedback trials. Despite changes in walking pattern, changes in synergies were limited. The number of synergies required to explain at least 90\% of muscle activation increased significantly, however, the change in measures of tVAF1 from baseline (0.75 ± 0.08) were less than ±2\% between trials. In addition, within-subject similarity of synergies to baseline walking was high (>0.8) across all biofeedback trials. These results suggest that while gait may be adapted in an immediate response, SMC as quantified by synergy analysis is perhaps more rigidly impaired in CP. Subtle changes in synergies were identified; however, it is questionable if these are clinically meaningful at the level of an individual. Adaptations may be limited in the short term, and further investigation is essential to establish if long term training using biofeedback leads to adapted SMC.}}, 
pages = {1208}, 
volume = {10}, 
keywords = {}
}

@article{Park2021,
  doi = {10.3390/app11167259},
  year = {2021},
  month = aug,
  publisher = {{MDPI} {AG}},
  volume = {11},
  number = {16},
  pages = {7259},
  author = {Sebeom Park and Shokhrukh Bokijonov and Yosoon Choi},
  title = {Review of Microsoft {HoloLens} Applications over the Past Five Years},
  journal = {Applied Sciences}
}
@article{mills2005bem, 
year = {2005}, 
title = {{The basics of electromyography}}, 
author = {Mills, K R}, 
journal = {Journal of Neurology, Neurosurgery \& Psychiatry}, 
issn = {0022-3050}, 
doi = {10.1136/jnnp.2005.069211}, 
pmid = {15961866}, 
pmcid = {PMC1765694}, 
pages = {ii32}, 
number = {suppl 2}, 
volume = {76}, 
keywords = {}
}
@article{ijsselsteijn2004fas, 
year = {2004}, 
title = {{Enhancing the Home Fitness Experience}}, 
author = {IJsselsteijn, Wijnand and Kort, Yvonne de and Westerink, Joyce and Jager, Marko de and Bonants, Ronald}, 
journal = {Entertainment Computing – ICEC 2004, Third International Conference, Eindhoven, The Netherlands, September 1-3, 2004. Proceedings}, 
issn = {0302-9743}, 
doi = {10.1007/978-3-540-28643-1_8}, 
abstract = {{The current paper describes research that is aimed to elucidate our understanding of technology factors that may help users of home exercise equipment to stay motivated for doing regular work-outs. In particular, we investigated the effects of immersion and coaching by a virtual agent on intrinsic motivation and the sense of presence of participants cycling on a stationary home exercise bike. A basic two-by-two within-subjects experimental design was employed whereby participants were presented with a virtual racetrack with two levels of immersion (high vs. low) and two levels of a virtual coach (with vs. without). Results indicate a clear positive effect of immersion on both motivation and presence. The virtual coach significantly lowered the perceived control and pressure/tension dimensions of intrinsic motivation, but did not affect the enjoyment dimension. The presence of the virtual coach also reduced negative effects associated with VEs.}}, 
pages = {46--56}, 
keywords = {}
}
@article{Nilsson2016irr, 
year = {2016}, 
title = {{Immersion revisited: A review of existing definitions of immersion and their relation to different theories of presence}}, 
author = {Nilsson, Niels Christian and Nordahl, Rolf and Serafin, Stefania}, 
journal = {Human Technology: An Interdisciplinary Journal on Humans in ICT Environments}, 
issn = {1795-6889}, 
doi = {10.17011/ht/urn.201611174652}, 
abstract = {{By Niels Christian Nilsson, Rolf Nordahl and Stefania Serafin}}, 
pages = {108--134}, 
number = {2}, 
volume = {12}, 
keywords = {}
}
@incollection{pucihar2015dcm, 
year = {2015}, 
title = {{Dual Camera Magic Lens for Handheld AR Sketching}}, 
author = {Pucihar, Klen \v{C}opi\v{c} and Grubert, Jens and Kljun, Matja{\v{z}}}, 
booktitle = {Human-Computer Interaction – INTERACT 2015, 15th IFIP TC 13 International Conference, Bamberg, Germany, September 14-18, 2015, Proceedings, Part IV}, 
isbn = {9783319227221}, 
abstract = {{One challenge of supporting in-situ sketching tasks with Magic Lenses on handheld Augmented Reality systems is to provide accurate and robust pose tracking without disrupting the sketching experience. Typical tracking approaches rely on the back-facing camera both for tracking and providing the view of the physical scene. This typically requires a fiducial to be in the scene which can disrupt the sketching experience on a blank sheet of paper. We address this challenge by proposing a Dual Camera Magic Lens approach. Specifically, we use the front facing camera for tracking while the back camera concurrently provides the view of the scene. Preliminary evaluation on a virtual tracing task with an off-the-shelf handheld device suggests that the Dual Camera Magic Lens approach has the potential to be both faster and lead to a higher perceived satisfaction compared to Magic Lens and Static Peephole interfaces.}}, 
pages = {523--527}, 
series = {Lecture Notes in Computer Science}, 
publisher = {Springer, Cham}, 
keywords = {}, 
doi = {10.1007/978-3-319-22723-8_53}
}
@book{schmalstieg2016augmented,
  title={Augmented reality: principles and practice},
  author={Schmalstieg, Dieter and H\"ollerer, Tobias},
  year={2016},
  publisher={Addison-Wesley Professional}
}

@article{mohr2017rvt, 
year = {2017}, 
title = {{Retargeting Video Tutorials Showing Tools With Surface Contact to Augmented Reality}}, 
author = {Mohr, Peter and Mark, Gloria and Fussell, Susan and Lampe, Cliff and Hourcade, Juan Pablo and Appert, Caroline and Wigdor, Daniel and Mandl, David and Tatzgern, Markus and Veas, Eduardo and Schmalstieg, Dieter and Kalkofen, Denis}, 
journal = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems}, 
doi = {10.1145/3025453.3025688}, 
url = {https://dl.acm.org/doi/abs/10.1145/3025453.3025688}, 
abstract = {{A video tutorial effectively conveys complex motions, but may be hard to follow precisely because of its restriction to a predetermined viewpoint. Augmented reality (AR) tutorials have been demonstrated to be more effective. We bring the advantages of both together by interactively retargeting conventional, two-dimensional videos into three-dimensional AR tutorials. Unlike previous work, we do not simply overlay video, but synthesize 3D-registered motion from the video. Since the information in the resulting AR tutorial is registered to 3D objects, the user can freely change the viewpoint without degrading the experience. This approach applies to many styles of video tutorials. In this work, we concentrate on a class of tutorials which alter the surface of an object.}}, 
pages = {6547--6558}, 
keywords = {}
}
@article{gatullo2020whw, 
year = {2020}, 
title = {{What, How, and Why are Visual Assets Used in Industrial Augmented Reality? A Systematic Review and Classification in Maintenance, Assembly, and Training (From 1997 to 2019)}}, 
author = {Gattullo, Michele and Evangelista, Alessandro and Uva, Antonio E. and Fiorentino, Michele and Gabbard, Joseph L.}, 
journal = {IEEE Transactions on Visualization and Computer Graphics}, 
issn = {1077-2626}, 
doi = {10.1109/tvcg.2020.3014614}, 
pmid = {32759085}, 
url = {https://ieeexplore.ieee.org/abstract/document/9161249}, 
abstract = {{Industrial Augmented Reality (iAR) has demonstrated its advantages to communicate technical information in the fields of maintenance, assembly, and training. However, literature is scattered among different visual assets (i.e., AR visual user interface elements associated with a real scene). In this work, we present a systematic literature review of visual assets used in these industrial fields. We searched five databases, initially finding 1757 papers. Then, we selected 122 iAR papers from 1997 to 2019 and extracted 348 visual assets. We propose a classification for visual assets according to (i) what is displayed, (ii) how it conveys information (frame of reference, color coding, animation), and, (iii) why it is used. Our review shows that product models, text and auxiliary models are, in order, the most common, with each most often used to support operating, checking and locating tasks respectively. Other visual assets are scarcely used. Product and auxiliary models are commonly rendered world-fixed, color coding is not used as often as expected, while animations are limited to product and auxiliary model. This survey provides a snapshot of over 20 years of literature in iAR, useful to understand established practices to orientate in iAR interface design and to present future research directions.}}, 
pages = {1443--1456}, 
number = {2}, 
volume = {28}, 
keywords = {}
}
@article{tang2015pah, 
year = {2015}, 
title = {{Physio@Home: Exploring Visual Guidance and Feedback Techniques for Physiotherapy Exercises}}, 
author = {Tang, Richard and Begole, Bo and Kim, Jinwoo and Inkpen, Kori and Woo, Woontack and Yang, Xing-Dong and Bateman, Scott and Jorge, Joaquim and Tang, Anthony}, 
journal = {Proc. of the 33rd Annual ACM Conf. on Human Factors in Computing Systems}, 
doi = {10.1145/2702123.2702401}, 
url = {https://dl.acm.org/doi/abs/10.1145/2702123.2702401}, 
abstract = {{Physiotherapy patients exercising at home alone are at risk of re-injury since they do not have corrective guidance from a therapist. To explore solutions to this problem, we designed Physio@Home, a prototype that guides people through prerecorded physiotherapy exercises using real-time visual guides and multi-camera views. Our design addresses several aspects of corrective guidance, including: plane and range of movement, joint positions and angles, and extent of movement. We evaluated our design, com-paring how closely people could follow exercise movements under various feedback conditions. Participants were most accurate when using our visual guide and multi-views. We provide suggestions for exercise guidance systems drawn from qualitative findings on visual feedback complexity.}}, 
pages = {4123--4132}, 
keywords = {}
}
@article{wang2019asw, 
	year = {2019}, 
	title = {{Action snapshot with single pose and viewpoint}}, 
	author = {Wang, Meili and Guo, Shihui and Liao, Minghong and He, Dongjian and Chang, Jian and Zhang, Jianjun}, 
	journal = {The Visual Computer}, 
	issn = {0178-2789}, 
	doi = {10.1007/s00371-018-1479-9}, 
	abstract = {{Many art forms present visual content as a single image captured from a particular viewpoint. How to select a meaningful representative moment from an action performance is difficult, even for an experienced artist. Often, a well-picked image can tell a story properly. This is important for a range of narrative scenarios, such as journalists reporting breaking news, scholars presenting their research, or artists crafting artworks. We address the underlying structures and mechanisms of a pictorial narrative with a new concept, called the action snapshot, which automates the process of generating a meaningful snapshot (a single still image) from an input of scene sequences. The input of dynamic scenes could include several interactive characters who are fully animated. We propose a novel method based on information theory to quantitatively evaluate the information contained in a pose. Taking the selected top postures as input, a convolutional neural network is constructed and trained with the method of deep reinforcement learning to select a single viewpoint, which maximally conveys the information of the sequence. User studies are conducted to experimentally compare the computer-selected poses and viewpoints with those selected by human participants. The results show that the proposed method can assist the selection of the most informative snapshot effectively from animation-intensive scenarios.}}, 
	pages = {507--520}, 
	number = {4}, 
	volume = {35}, 
	keywords = {}
}

@article{choi2012rav, 
	year = {2012}, 
	title = {{Retrieval and Visualization of Human Motion Data via Stick Figures}}, 
	author = {Choi, M. G. and Yang, K. and Igarashi, T. and Mitani, J. and Lee, J.}, 
	journal = {Computer Graphics Forum}, 
	issn = {0167-7055}, 
	doi = {10.1111/j.1467-8659.2012.03198.x}, 
	abstract = {{We propose 2D stick figures as a unified medium for visualizing and searching for human motion data. The stick figures can express a wide range or human motion, and they are easy to be drawn by people without any professional training. In our interface, the user can browse overall motion by viewing the stick figure images generated from the database and retrieve them directly by using sketched stick figures as an input query. We started with a preliminary survey to observe how people draw stick figures. Based on the rules observed from the user study, we developed an algorithm converting motion data to a sequence of stick figures. The feature‐based comparison method between the stick figures provides an interactive and progressive search for the users. They assist the user's sketching by showing the current retrieval result at each stroke. We demonstrate the utility of the system with a user study, in which the participants retrieved example motion segments from the database with 102 motion files by using our interface.}}, 
	pages = {2057--2065}, 
	number = {7}, 
	volume = {31}, 
	note = {Valuable Database}, 
	keywords = {}
}

@article{yeh2011ecp, 
	year = {2011}, 
	title = {{Efficient camera path planning algorithm for human motion overview}}, 
	author = {Yeh, I‐Cheng and Lin, Chao‐Hung and Chien, Hung‐Jen and Lee, Tong‐Yee}, 
	journal = {Computer Animation and Virtual Worlds}, 
	issn = {1546-4261}, 
	doi = {10.1002/cav.398}, 
	abstract = {{Camera path planning for character motions is a fundamental and important research topic, benefiting many animation applications. Existing optimal‐based approaches are generally computationally expensive and infeasible for interactive applications. In this paper, we propose an efficient approach that can take many constraints of finding the camera path into account and can potentially enable interactive camera control. Instead of solving a highly complicated camera optimization problem in a spatiotemporal four‐dimensional space, we heuristically determine the camera path based on an efficient greedy‐based tree traversal approach. The experimental results show that the proposed approach can efficiently generate a smooth, informative, and aesthetic camera path that can reveal the significant features of character motions. Moreover, the conducted user study also shows that the generated camera paths are comparable to those of a state‐of‐the‐art approach and those made by professional animators. Copyright © 2011 John Wiley \& Sons, Ltd. This paper proposes an efficient approach of finding the camera path for human motion and can potentially enable interactive camera control. Instead of solving a complicated camera optimization problem, we heuristically determine the camera path‐based on an efficient greedy‐based tree traversal approach. The experimental results show that the proposed approach generate a smooth, informative, and aesthetic motion over view efficiently.}}, 
	pages = {239--250}, 
	number = {2‐3}, 
	volume = {22}, 
	keywords = {}
}

@article{assa2005asp, 
	year = {2005}, 
	title = {{Action synopsis: pose selection and illustration}}, 
	author = {Assa, Jackie and Caspi, Yaron and Cohen-Or, Daniel}, 
	journal = {ACM Transactions on Graphics (TOG)}, 
	issn = {0730-0301}, 
	doi = {10.1145/1073204.1073246}, 
	abstract = {{Illustrating motion in still imagery for the purpose of summary, abstraction and motion description is important for a diverse spectrum of fields, ranging from arts to sciences. In this paper, we introduce a method that produces an action synopsis for presenting motion in still images. The method carefully selects key poses based on an analysis of a skeletal animation sequence, to facilitate expressing complex motions in a single image or a small number of concise views. Our approach is to embed the high-dimensional motion curve in a low-dimensional Euclidean space, where the main characteristics of the skeletal action are kept. The lower complexity of the embedded motion curve allows a simple iterative method which analyzes the curve and locates significant points, associated with the key poses of the original motion. We present methods for illustrating the selected poses in an image as a means to convey the action. We applied our methods to a variety of motions of human actions given either as 3D animation sequences or as video clips, and generated images that depict their synopsis.}}, 
	pages = {667--676}, 
	number = {3}, 
	volume = {24}, 
	keywords = {}
}
@article{assa2008moh, 
	year = {2008}, 
	title = {{Motion overview of human actions}}, 
	author = {Assa, Jackie and Cohen-Or, Daniel and Yeh, I-Cheng and Lee, Tong-Yee}, 
	journal = {ACM Transactions on Graphics}, 
	issn = {0730-0301}, 
	doi = {10.1145/1409060.1409068}, 
	abstract = {{During the last decade, motion capture data has emerged and gained a leading role in animations, games and 3D environments. Many of these applications require the creation of expressive overview video clips capturing the human motion, however sufficient attention has not been given to this problem. In this paper, we present a technique that generates an overview video based on the analysis of motion capture data. Our method is targeted for applications of 3D character based animations, automating, for example, the action summary and gameplay overview in simulations and computer games. We base our method on quantum annealing optimization with an objective function that respects the analysis of the character motion and the camera movement constraints. It automatically generates a smooth camera control path, splitting it to several shots if required. To evaluate our method, we introduce a novel camera placement metric which is evaluated against previous work and conduct a user study comparing our results with the various systems.}}, 
	pages = {1--10}, 
	number = {5}, 
	volume = {27}, 
	keywords = {}
}
@article{blanz1996woa, 
	year = {1996}, 
	title = {{What Object Attributes Determine Canonical Views?}}, 
	author = {Blanz, Volker and Tarr, Michael J and Bülthoff, Heinrich H}, 
	journal = {Perception}, 
	issn = {0301-0066}, 
	doi = {10.1068/p2897}, 
	pmid = {10664755}, 
	abstract = {{We investigated preferred or canonical views for familiar and three-dimensional nonsense objects using computer-graphics psychophysics. We assessed the canonical views for objects by allowing participants to actively rotate realistically shaded three-dimensional models in realtime. Objects were viewed on a Silicon Graphics workstation and manipulated in virtual space with a three-degree-of-freedom input device. In the first experiment, participants adjusted each object to the viewpoint from which they would take a photograph if they planned to use the object to illustrate a brochure. In the second experiment, participants mentally imaged each object on the basis of the name and then adjusted the object to the viewpoint from which they imagined it. In both experiments, there was a large degree of consistency across participants in terms of the preferred view for a given object. Our results provide new insights on the geometrical, experiential, and functional attributes that determine canonical views under ecological conditions.}}, 
	pages = {575--599}, 
	number = {5}, 
	volume = {28}, 
	keywords = {}
}
@article{takahashi2005fdv, 
	year = {2005}, 
	title = {{A Feature-Driven Approach to Locating Optimal Viewpoints for Volume Visualization}}, 
	author = {Takahashi, Shigeo and Fujishiro, Issei and Takeshima, Yuriko and Nishita, Tomoyuki}, 
	journal = {VIS 05. IEEE Visualization, 2005}, 
	doi = {10.1109/visual.2005.1532834}, 
	abstract = {{Optimal viewpoint selection is an important task because it considerably influences the amount of information contained in the 2D projected images of 3D objects, and thus dominates their first impressions from a psychological point of view. Although several methods have been proposed that calculate the optimal positions of viewpoints especially for 3D surface meshes, none has been done for solid objects such as volumes. This paper presents a new method of locating such optimal viewpoints when visualizing volumes using direct volume rendering. The major idea behind our method is to decompose an entire volume into a set of feature components, and then find a globally optimal viewpoint by finding a compromise between locally optimal viewpoints for the components. As the feature components, the method employs interval volumes and their combinations that characterize the topological transitions of isosurfaces according to the scalar field. Furthermore, opacity transfer functions are also utilized to assign different weights to the decomposed components so that users can emphasize features of specific interest in the volumes. Several examples of volume datasets together with their optimal positions of viewpoints are exhibited in order to demonstrate that the method can effectively guide naive users to find optimal projections of volumes.}}, 
	pages = {495--502}, 
	keywords = {}
}
@article{ishara2015mra, 
	year = {2015}, 
	title = {{Mobile Robotic Active View Planning for Physiotherapy and Physical Exercise Guidance}}, 
	author = {Ishara, Kalana and Lee, Ivan and Brinkworth, Russell}, 
	journal = {2015 IEEE 7th International Conference on Cybernetics and Intelligent Systems (CIS) and IEEE Conference on Robotics, Automation and Mechatronics (RAM)}, 
	doi = {10.1109/iccis.2015.7274609}, 
	abstract = {{Consulting a physiotherapist or physical trainer for long term regular exercises is not financially affordable for all. As a solution, our long term research goal is to develop a robotic physiotherapist/physical trainer which could instructively and physically guide a performer. Towards that direction, in this paper we present an autonomously repositioning mobile robot to observe a person throughout a sequence of physical exercises by selecting less self-occluded viewpoints. A viewpoint specific joint mutual occlusion (JMO) measurement is formulated at candidate viewpoints. Then a utility function, which accounts for joint occlusion, skeleton coverage, sensing range and moving cost, is averaged over the sub-activity periodic duration to find the optimal viewpoint. Proposed methods have been evaluated with multi-view dataset and an online mobile robot while a person performed eight different physical activities with two trials each. Results indicate proposed active view planner can autonomously drive the mobile robot to a less self-occluded viewpoint over manually setup fixed viewpoint observation, leading to more accurate human movement analysis.}}, 
	pages = {130--136}, 
	keywords = {}
}
@article{viridis,
	doi = {10.1371/journal.pone.0199239},
	author = {Nuñez, Jamie R. AND Anderton, Christopher R. AND Renslow, Ryan S.},
	journal = {PLOS ONE},
	publisher = {Public Library of Science},
	title = {Optimizing colormaps with consideration for color vision deficiency to enable accurate interpretation of scientific data},
	year = {2018},
	month = {08},
	volume = {13},
	doi = {10.1371/journal.pone.0199239},
	pages = {1-14},
	number = {7},
}

@book{zusne1970vpf, 
	year = {1970}, 
	title = {{Visual Perception of Form}}, 
	author = {Zusne, Leonard}, 
	isbn = {0127830502}, 
	publisher = {Academic Press}, 
	keywords = {}
}
@incollection{wiebel:2013:EuroVis, 
	year = {2013}, 
	title = {{3D Strokes on Visible Structures in Direct Volume Rendering}}, 
	author = {Wiebel, Alexander and Preis, Philipp and Vos, Frans M. and Hege, Hans-Christian}, 
	editor = {Hlawitschka, Mario and Weinkauf, Tino}, 
	booktitle = {EuroVis - Shortpapers}, 
	abstract = {{In this paper we describe VisiTrace, a novel technique to draw 3D lines in direct volume rendered images. It allows to draw strokes in the 2D space of the screen to produce 3D lines that run on top or in the center of structures
	visible in the rendering. It is able to ignore structures that shortly occlude the structure that has been visible at
	the start of the stroke. For this purpose a shortest path algorithm finding the optimal curve in a specially designed
	graph is employed. We demonstrate the usefulness of the technique by applying it to image data from medicine
	and engineering, and show how it can be used to mark structures in the example data, and to automatically obtain
	good views toward these structures enabling faster navigation in the rendering.}}, 
	pages = {91--95}, 
	keywords = {}, 
	publisher = {The Eurographics Association},
	doi = {10.2312/pe.eurovisshort.eurovisshort2013.091-095},
}
@article{su2013pre, 
	year = {2013}, 
	title = {{Personal Rehabilitation Exercise Assistant with Kinect and Dynamic Time Warping}}, 
	author = {Su, Chuan-Jun}, 
	journal = {International Journal of Information and Education Technology}, 
	issn = {2010-3689}, 
	doi = {10.7763/ijiet.2013.v3.316}, 
	abstract = {{Constant rehabilitation exercises at home are usually required for complimenting prescribed exercises executed in a hospital setting and for expediting a patient’s physical recovery. One of the main issues is to provide technological support for making home-based rehabilitation offering similar outcomes to hospital-based rehabilitation with an occupational physician presented. This paper presents our development of a Kinect-based system for ensuring home-based rehabilitation (KHRD) using Dynamic Time Warping (DTW) algorithm and fuzzy logic. The ultimate goal is to offer assistance for patients to conduct home-based rehabilitation without the presence of a physician and to avoid adverse events.}}, 
	pages = {448--454}, 
	keywords = {}
}

@article{anton2015pre, 
	year = {2015}, 
	title = {{Exercise Recognition for Kinect-based Telerehabilitation*}}, 
	author = {Antón, D and Goñi, A and Illarramendi, A}, 
	journal = {Methods of Information in Medicine}, 
	issn = {0026-1270}, 
	doi = {10.3414/me13-01-0109}, 
	pmid = {25301322}, 
	abstract = {{Background: An aging population and people’s higher survival to diseases and traumas that leave physical consequences are challenging aspects in the context of an efficient health management. This is why telerehabilitation systems are being developed, to allow monitoring and support of physiotherapy sessions at home, which could reduce healthcare costs while also improving the quality of life of the users. Objectives: Our goal is the development of a Kinect-based algorithm that provides a very accurate real-time monitoring of physical rehabilitation exercises and that also provides a friendly interface oriented both to users and physiotherapists. Methods: The two main constituents of our algorithm are the posture classification method and the exercises recognition method. The exercises consist of series of movements. Each movement is composed of an initial posture, a final posture and the angular trajectories of the limbs involved in the movement. The algorithm was designed and tested with datasets of real movements performed by volunteers. We also explain in the paper how we obtained the optimal values for the trade-off values for posture and trajectory recognition. Results: Two relevant aspects of the algorithm were evaluated in our tests, classification accuracy and real-time data processing. We achieved 91.9\% accuracy in posture classification and 93.75\% accuracy in trajectory recognition. We also checked whether the algorithm was able to process the data in real-time. We found that our algorithm could process more than 20,000 postures per second and all the required trajectory data-series in real-time, which in practice guarantees no perceptible delays. Later on, we carried out two clinical trials with real patients that suffered shoulder disorders. We obtained an exercise monitoring accuracy of 95.16\%. Conclusions: We present an exercise recognition algorithm that handles the data provided by Kinect efficiently. The algorithm has been validated in a real scenario where we have verified its suitability. Moreover, we have received a positive feedback from both users and the physiotherapists who took part in the tests.}}, 
	pages = {145--155}, 
	number = {02}, 
	volume = {54}, 
	keywords = {}
}

@article{saenz2016kbv, 
	year = {2016}, 
	title = {{Kinect-Based Virtual Game for the Elderly that Detects Incorrect Body Postures in Real Time}}, 
	author = {Saenz-de-Urturi, Zelai and Soto, Begonya Garcia-Zapirain}, 
	journal = {Sensors}, 
	doi = {10.3390/s16050704}, 
	pmid = {27196903}, 
	pmcid = {PMC4883395}, 
	abstract = {{Poor posture can result in loss of physical function, which is necessary to preserving independence in later life. Its decline is often the determining factor for loss of independence in the elderly. To avoid this, a system to correct poor posture in the elderly, designed for Kinect-based indoor applications, is proposed in this paper. Due to the importance of maintaining a healthy life style in senior citizens, the system has been integrated into a game which focuses on their physical stimulation. The game encourages users to perform physical activities while the posture correction system helps them to adopt proper posture. The system captures limb node data received from the Kinect sensor in order to detect posture variations in real time. The DTW algorithm compares the original posture with the current one to detect any deviation from the original correct position. The system was tested and achieved a successful detection percentage of 95.20\%. Experimental tests performed in a nursing home with different users show the effectiveness of the proposed solution.}}, 
	pages = {704}, 
	number = {5}, 
	volume = {16}, 
	keywords = {}
}
@inbook{borisenko,
	address = {New York},
	alteditor = {Richard A. Silverman},
	author = {Borisenko, A. I. and Tarapov, I. E.},
	publisher = {Dover Publications Inc.},
	timestamp = {2011.05.10},
	pages={109},
	title = {Vector and Tensor Analysis with Applications},
	year = {1979}
}
@article{munzner2009anm, 
	year = {2009}, 
	title = {{A Nested Model for Visualization Design and Validation}}, 
	author = {Munzner, Tamara}, 
	journal = {IEEE TVCG}, 
	issn = {1077-2626}, 
	doi = {10.1109/tvcg.2009.111}, 
	pmid = {19834155}, 
	abstract = {{We present a nested model for the visualization design and validation with four layers: characterize the task and data in the vocabulary of the problem domain, abstract into operations and data types, design visual encoding and interaction techniques, and create algorithms to execute techniques efficiently. The output from a level above is input to the level below, bringing attention to the design challenge that an upstream error inevitably cascades to all downstream levels. This model provides prescriptive guidance for determining appropriate evaluation approaches by identifying threats to validity unique to each level. We also provide three recommendations motivated by this model: authors should distinguish between these levels when claiming contributions at more than one of them, authors should explicitly state upstream assumptions at levels above the focus of a paper, and visualization venues should accept more papers on domain characterization.}}, 
	pages = {921--928}, 
	number = {6}, 
	volume = {15}, 
	keywords = {}
}
@ARTICLE{diller2022vcb,
	author={Diller, Florian and Scheuermann, Gerik and Wiebel, Alexander},
	journal={IEEE Transactions on Visualization and Computer Graphics}, 
	title={Visual Cue Based Corrective Feedback for Motor Skill Training in Mixed Reality: A Survey}, 
	year={2022},
	volume={},
	number={},
	pages={1-14},
	doi={10.1109/TVCG.2022.3227999}
}
@article{sorzano2014sdr, 
	title = {{A survey of dimensionality reduction techniques}}, 
	author = {Sorzano, C.O.S. and Vargas, J. and Pascual‐Montano, A.}, 
	journal = {ArXiv14032877 Cs Q-Bio Stat}, 
	year={2014},
	doi = {10.48550/arXiv.1403.2877}, 
	abstract = {{Experimental life sciences like biology or chemistry have seen in the recent decades an explosion of the data available from experiments. Laboratory instruments become more and more complex and report hundreds or thousands measurements for a single experiment and therefore the statistical methods face challenging tasks when dealing with such high‐dimensional data. However, much of the data is highly redundant and can be efficiently brought down to a much smaller number of variables without a significant loss of information. The mathematical procedures making possible this reduction are called dimensionality reduction techniques; they have widely been developed by fields like Statistics or Machine Learning, and are currently a hot research topic. In this review we categorize the plethora of dimension reduction techniques available and give the mathematical insight behind them.}}, 
	keywords = {}
}
@inbook{charalambides2002enumerative,
	title={Enumerative Combinatorics},
	author={Charalambides, C.A.},
	isbn={9781584882909},
	lccn={2002019775},
	series={Discrete Mathematics and Its Applications},
	url={https://books.google.de/books?id=PDMGA-v5G54C},
	year={2002},
	publisher={Taylor \& Francis},
	pages={62}
}
@misc{kinect:documentation, 
	title = {{Azure Kinect DK documentation}}, 
	author = {{Microsoft Development Team}}, 
	url = {\url{https://learn.microsoft.com/en-us/azure/kinect-dk/}},
	note = {\url{https://learn.microsoft.com/en-us/azure/kinect-dk/}, Accessed: 2023-3-30},
	urldate = {2023-3-30}, 
	journal = {Microsoft Azure}, 
	keywords = {},
	year = {2018}
}
@ARTICLE{bouwmans2018arpca,
	author={Bouwmans, Thierry and Javed, Sajid and Zhang, Hongyang and Lin, Zhouchen and Otazo, Ricardo},
	journal={Proceedings of the IEEE}, 
	title={On the Applications of Robust PCA in Image and Video Processing}, 
	year={2018},
	volume={106},
	number={8},
	pages={1427-1457},
	doi={10.1109/JPROC.2018.2853589}
}
@article{skaro2021knac,
	author = {Skaro, Jordan and Hazelwood, Scott J. and Klisch, Stephen M.},
	title = {Knee Angles After Crosstalk Correction With Principal Component Analysis in Gait and Cycling},
	journal = {Journal of Biomechanical Engineering},
	volume = {143},
	number = {5},
	pages = {054501},
	year = {2021},
	month = {02},
	abstract = {Principal component analysis (PCA) has been used as a post-hoc method for reducing knee crosstalk errors during gait analysis. PCA minimizes correlations between flexion–extension (FE), abduction–adduction (AA), and internal–external rotation (IE) angles. However, previous studies have not considered PCA for exercises involving knee flexion angles that are greater than those typically experienced during gait. Thus, the goal of this study was to investigate using PCA to correct for crosstalk during one exercise (i.e., cycling) that involves relatively high flexion angles. Fifteen participants were tested in gait and cycling using a motion analysis system. Uncorrected FE, AA and IE angles were compared to those calculated with PCA performed on (1) all angles (FE-AA-IE PCA correction) and (2) only FE-AA angles (FE-AA PCA correction). Significant differences existed between uncorrected and FE-AA-IE PCA corrected AA and IE angles for both exercises, between uncorrected and FE-AA PCA corrected AA angles for both exercises, and between FE-AA-IE and FE-AA PCA corrected IE angles for cycling. Correlations existed before PCA correction and were eliminated following PCA correction with the exception that FE-IE correlations remained following FE-AA PCA correction. Since the two PCA analyses differed only in their IE angle predictions for the high flexion exercise (cycling), IE angle results were compared to previous studies. Using FE-AA PCA correction may be the preferred protocol for cycling as it appeared to retain physiological IE angle correlations at high flexion angles. However, there exists a critical need for studies aimed at obtaining more accurate IE angles in such exercises.},
	issn = {0148-0731},
	doi = {10.1115/1.4049809}
	}
@article{swamy2018ins, 
	year = {2018}, 
	title = {{Investigating the Nature of Students' Reasoning in Connecting Molecular Structures of Stereoisomers with their Physical Properties using an AR App}}, 
	author = {Swamy, Narasimha and Dasgupta, Chandan}, 
	journal = {2018 IEEE Tenth International Conference on Technology for Education (T4E)}, 
	doi = {10.1109/t4e.2018.00018}, 
	abstract = {{Stereoisomers are chemicals with identical molecular composition differing only in the spatial arrangement of their atoms. This difference causes differences in their physical, chemical or biological properties. Fundamental to the learning of stereochemistry is to understand how this spatial differences in stereoisomers causes differences in their properties. It is a complex learning problem requiring learners to imagine dynamic processes occurring at the molecular level. It is also a learning problem that has not been adequately addressed in the context of stereochemistry. We conducted an exploratory study to investigate how chemistry students of different grade levels reason to connect structure and properties of stereoisomers. In parallel, we were also working on the development of an augmented reality based molecular visualization app called ‘StereoChem’; to aid the specific difficulties observed in the students while they were performing stereochemical tasks. From our observation and analysis we report the critical bottlenecks identified in students' reasoning, probable sources of those bottlenecks and the refinement of our ‘StereoChem’ app. In conclusion, we suggest key design guidelines drawn from our study for curriculum design, pedagogical practices and technological support to help students overcome those bottlenecks.}}, 
	pages = {53--60}, 
	keywords = {}
}

@article{oconner2019imd, 
	year = {2019}, 
	title = {{Interactive molecular dynamics in virtual reality from quantum chemistry to drug binding: An open-source multi-person framework}}, 
	author = {O’Connor, Michael B. and Bennie, Simon J. and Deeks, Helen M. and Jamieson-Binnie, Alexander and Jones, Alex J. and Shannon, Robin J. and Walters, Rebecca and Mitchell, Thomas J. and Mulholland, Adrian J. and Glowacki, David R.}, 
	journal = {The Journal of Chemical Physics}, 
	issn = {0021-9606}, 
	doi = {10.1063/1.5092590}, 
	pmid = {31202243}, 
	eprint = {1902.01827}, 
	abstract = {{As molecular scientists have made progress in their ability to engineer nanoscale molecular structure, we face new challenges in our ability to engineer molecular dynamics (MD) and flexibility. Dynamics at the molecular scale differs from the familiar mechanics of everyday objects because it involves a complicated, highly correlated, and three-dimensional many-body dynamical choreography which is often nonintuitive even for highly trained researchers. We recently described how interactive molecular dynamics in virtual reality (iMD-VR) can help to meet this challenge, enabling researchers to manipulate real-time MD simulations of flexible structures in 3D. In this article, we outline various efforts to extend immersive technologies to the molecular sciences, and we introduce “Narupa,” a flexible, open-source, multiperson iMD-VR software framework which enables groups of researchers to simultaneously cohabit real-time simulation environments to interactively visualize and manipulate the dynamics of molecular structures with atomic-level precision. We outline several application domains where iMD-VR is facilitating research, communication, and creative approaches within the molecular sciences, including training machines to learn potential energy functions, biomolecular conformational sampling, protein-ligand binding, reaction discovery using “on-the-fly” quantum chemistry, and transport dynamics in materials. We touch on iMD-VR’s various cognitive and perceptual affordances and outline how these provide research insight for molecular systems. By synergistically combining human spatial reasoning and design insight with computational automation, technologies such as iMD-VR have the potential to improve our ability to understand, engineer, and communicate microscopic dynamical behavior, offering the potential to usher in a new paradigm for engineering molecules and nano-architectures.}}, 
	pages = {220901}, 
	number = {22}, 
	volume = {150}, 
	keywords = {}
}

@article{oconner2018smc, 
	year = {2018}, 
	title = {{Sampling molecular conformations and dynamics in a multiuser virtual reality framework}}, 
	author = {O’Connor, Michael and Deeks, Helen M. and Dawn, Edward and Metatla, Oussama and Roudaut, Anne and Sutton, Matthew and Thomas, Lisa May and Glowacki, Becca Rose and Sage, Rebecca and Tew, Philip and Wonnacott, Mark and Bates, Phil and Mulholland, Adrian J. and Glowacki, David R.}, 
	journal = {Science Advances}, 
	doi = {10.1126/sciadv.aat2731}, 
	pmid = {29963636}, 
	pmcid = {PMC6025904}, 
	eprint = {1801.02884}, 
	abstract = {{We describe a framework for interactive molecular dynamics in a multiuser virtual reality (VR) environment, combining rigorous cloud-mounted atomistic physics simulations with commodity VR hardware, which we have made accessible to readers (see isci.itch.io/nsb-imd). It allows users to visualize and sample, with atomic-level precision, the structures and dynamics of complex molecular structures “on the fly” and to interact with other users in the same virtual environment. A series of controlled studies, in which participants were tasked with a range of molecular manipulation goals (threading methane through a nanotube, changing helical screw sense, and tying a protein knot), quantitatively demonstrate that users within the interactive VR environment can complete sophisticated molecular modeling tasks more quickly than they can using conventional interfaces, especially for molecular pathways and structural transitions whose conformational choreographies are intrinsically three-dimensional. This framework should accelerate progress in nanoscale molecular engineering areas including conformational mapping, drug development, synthetic biology, and catalyst design. More broadly, our findings highlight the potential of VR in scientific domains where three-dimensional dynamics matter, spanning research and education.}}, 
	pages = {eaat2731}, 
	number = {6}, 
	volume = {4}, 
	keywords = {}
}

@article{lam2012esi, 
	year = {2012}, 
	title = {{Empirical Studies in Information Visualization: Seven Scenarios}}, 
	author = {Lam, H. and Bertini, E. and Isenberg, P. and Plaisant, C. and Carpendale, S.}, 
	journal = {IEEE Transactions on Visualization and Computer Graphics}, 
	issn = {1077-2626}, 
	doi = {10.1109/tvcg.2011.279}, 
	pmid = {22144529}, 
	abstract = {{We take a new, scenario-based look at evaluation in information visualization. Our seven scenarios, evaluating visual data analysis and reasoning, evaluating user performance, evaluating user experience, evaluating environments and work practices, evaluating communication through visualization, evaluating visualization algorithms, and evaluating collaborative data analysis were derived through an extensive literature review of over 800 visualization publications. These scenarios distinguish different study goals and types of research questions and are illustrated through example studies. Through this broad survey and the distillation of these scenarios, we make two contributions. One, we encapsulate the current practices in the information visualization research community and, two, we provide a different approach to reaching decisions about what might be the most effective evaluation of a given information visualization. Scenarios can be used to choose appropriate research questions and goals and the provided examples can be consulted for guidance on how to design one's own study.}}, 
	pages = {1520--1536}, 
	number = {9}, 
	volume = {18}, 
	keywords = {}
}

@article{kutak2023sam, 
	year = {2023}, 
	title = {{State of the Art of Molecular Visualization in Immersive Virtual Environments}}, 
	author = {Kuťák, David and Vázquez, Pere‐Pau and Isenberg, Tobias and Krone, Michael and Baaden, Marc and Byška, Jan and Kozlíková, Barbora and Miao, Haichao}, 
	journal = {Computer Graphics Forum}, 
	issn = {0167-7055}, 
	doi = {10.1111/cgf.14738}, 
	abstract = {{Visualization plays a crucial role in molecular and structural biology. It has been successfully applied to a variety of tasks, including structural analysis and interactive drug design. While some of the challenges in this area can be overcome with more advanced visualization and interaction techniques, others are challenging primarily due to the limitations of the hardware devices used to interact with the visualized content. Consequently, visualization researchers are increasingly trying to take advantage of new technologies to facilitate the work of domain scientists. Some typical problems associated with classic 2D interfaces, such as regular desktop computers, are a lack of natural spatial understanding and interaction, and a limited field of view. These problems could be solved by immersive virtual environments and corresponding hardware, such as virtual reality head‐mounted displays. Thus, researchers are investigating the potential of immersive virtual environments in the field of molecular visualization. There is already a body of work ranging from educational approaches to protein visualization to applications for collaborative drug design. This review focuses on molecular visualization in immersive virtual environments as a whole, aiming to cover this area comprehensively. We divide the existing papers into different groups based on their application areas, and types of tasks performed. Furthermore, we also include a list of available software tools. We conclude the report with a discussion of potential future research on molecular visualization in immersive environments. In this review, we survey the literature focusing on molecular visualization in immersive environments. We report on various enabling technologies, such as head‐mounted displays and augmented and mixed reality. Furthermore, we identify key domains, use cases, and visualization and interaction techniques employed by the current research.}}, 
	keywords = {}
}

@article{isenberg2013srp, 
	year = {2013}, 
	title = {{A Systematic Review on the Practice of Evaluating Visualization}}, 
	author = {Isenberg, Tobias and Isenberg, Petra and Chen, Jian and Sedlmair, Michael and Möller, Torsten}, 
	journal = {IEEE Transactions on Visualization and Computer Graphics}, 
	issn = {1077-2626}, 
	doi = {10.1109/tvcg.2013.126}, 
	pmid = {24051849}, 
	abstract = {{We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80–90\% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.}}, 
	pages = {2818--2827}, 
	number = {12}, 
	volume = {19}, 
	keywords = {}
}
@article{chua2003tpt, 
	year = {2003}, 
	title = {{Training for Physical Tasks in Virtual Environments: Tai Chi}}, 
	author = {Chua, Philo Tan and Crivella, Rebecca and Daly, Bo and Hu, Ning and Schaaf, Russ and Ventura, David and Camill, Todd and Hodgins, Jessica and Pausch, Randy}, 
	journal = {IEEE Virtual Reality, 2003. Proceedings}, 
	doi = {10.1109/vr.2003.1191125}, 
	abstract = {{We present a wireless virtual reality system and a prototype full body Tai Chi training application. Our primary contribution is the creation of a virtual reality system that tracks the full body in a working volume of 4 meters by 5 meters by 2.3 meters high to produce an animated representation of the user with 42 degrees of freedom. This – combined with a lightweight (< 3 pounds) belt-worn video receiver and head-mounted display –provides a wide area, untethered virtual environment that allows exploration of new application areas. Our secondary contribution is our attempt to show that user interface techniques made possible by such a system can improve training for a full body motor task. We tested several immersive techniques, such as providing multiple copies of a teacher's body positioned around the student and allowing the student to superimpose his body directly over the virtual teacher. None of these techniques proved significantly better than mimicking traditional Tai Chi instruction, where we provided one virtual teacher directly in front of the student. We consider the implications of these findings for future motion training tasks.}}, 
	pages = {87--94}, 
	keywords = {}
}
@article{Yan2015oma, 
	year = {2015}, 
	title = {{OutsideMe: Augmenting Dancer's External Self-Image by Using A Mixed Reality System}}, 
	author = {Yan, Shuo and Ding, Gangyi and Guan, Zheng and Sun, Ningxiao and Li, Hongsong and Zhang, Longfei}, 
	journal = {Proceedings of the 33rd Annual ACM Conference Extended Abstracts on Human Factors in Computing Systems}, 
	doi = {10.1145/2702613.2732759}, 
	abstract = {{External self-image is often used as an effective tool to enhance dancing technique, choreography, creativity, and expression. The traditional tools of presenting external image, such as mirrors or videos, are limited in their mobility, perspective, and immediacy. To address the issue, we present OutsideMe, a vision-sync mixed reality system that enables dancers see their body movements as external observers through a head-mounted display (HMD) device. This system captures dancer's posture and blends it into scenes from the dancer's original field of view in an interactive frame rate. The dancers can observe themselves without distracting their presence identities. In this research, we develop four work modes for supporting dancer's training, and carry out a feasibility study and a user study. The feedbacks from the participants performing various dancing styles are analyzed and discussed. The preliminary experimental results support our design.}}, 
	pages = {965--970}, 
	keywords = {}
}
@article{kasahara2016pe, 
	year = {2016}, 
	title = {{Parallel Eyes: Exploring Human Capability and Behaviors with Paralleled First Person View Sharing}}, 
	author = {Kasahara, Shunichi and Ando, Mitsuhito and Suganuma, Kiyoshi and Rekimoto, Jun}, 
	journal = {Proceedings of the 2016 CHI Conference on Human Factors in Computing Systems}, 
	doi = {10.1145/2858036.2858495}, 
	abstract = {{Our research explores how humans can understand and develop viewing behaviors with mutual paralleled first person view sharing in which a person can see others' first person video perspectives as well as their own perspective in realtime. We developed a paralleled first person view sharing system which consists of multiple video see-through head mounted displays and an embedded eye tracking system. With this system, four persons can see four shared first person videos of each other. We then conducted workshop based research with two activities, drawing pictures and playing a simple chasing game with our view sharing system. Our results show that 1) people can complement each other's memory and decisions and 2) people can develop their viewing behaviors to understand their own physical embodiment and spatial relationship with others in complex situations. Our findings about patterns of viewing behavior and design implications will contribute to building design experience in paralleled view sharing applications.}}, 
	pages = {1561--1572}, 
	keywords = {}
}
@article{kawasaki2010cst, 
	year = {2010}, 
	title = {{Collaboration and Skill Transmission by First-person Perspective View Sharing System}}, 
	author = {Kawasaki, Hiroki and Iizuka, Hiroyuki and Okamoto, Shin and Ando, Hideyuki and Maeda, Taro}, 
	journal = {19th International Symposium in Robot and Human Interactive Communication}, 
	doi = {10.1109/roman.2010.5598668}, 
	abstract = {{When two distant persons establish cooperative interaction, how to share their motions and sensations and how to adjust or revise their motions are important for cooperation. In this paper, we propose an approach for sharing first-person perspectives to establish collaboration and to transmit a skill from one to another. We developed a view-sharing system to realize such interaction. To investigate the fundamental behavioral property of humans with our system, we examined a simple collaborated behavior and found that a situation where subjects only see their partner's view improves velocity following. By exploiting this property, we transmitted the basic skill required for the Diabolo trick to non-skilled persons. Through our system, the performances of non-skilled persons with the assistance of a skilled person surpassed individual performances}}, 
	pages = {125--131}, 
	keywords = {}
}
@article{Hamanishi2019avu, 
	year = {2019}, 
	title = {{Assisting viewpoint to understand own posture as an avatar in-situation}}, 
	author = {Hamanishi, Natsuki and Miyaki, Takashi and Rekimoto, Jun}, 
	journal = {Proceedings of the 5th International ACM In-Cooperation HCI and UX Conference on - CHIuXiD'19}, 
	doi = {10.1145/3328243.3328244}, 
	abstract = {{Understanding the correct self-posture is known to improve the performance of motor skills in sports, dance, ballet, walking, and running. However, it is difficult to understand the accurate self-posture and move one's body as intended for imitation or learning, especially in-situation. Based on previous physiological research, we herein propose the addition of a new assisting viewpoint to the human body interface for understanding the correct self-posture without interrupting the training process. This new viewpoint enables the users to see their current posture as a three-dimensional skeletal image that is an avatar which synchronizes with the owner's movements. The Optical See-Through Head Mounted Display (OST-HMD) and Full-Body Motion Capture (MoCap) are used for creating the proposed viewpoint. The position and the angle of view of an avatar is determined by the rotation of the user's head interactively. Moreover, visualizing the avatar's trail helps users to understand how to moved their own body correctly. We conducted several experiments to confirm the avatar system's validity and the availability for an expert athlete. Our results showed that the proposed viewpoint was successful in enabling the user to understand the accurate self-posture in-situation without occurring interruption.}}, 
	pages = {1--8}, 
	keywords = {}
}
@article{rymal2009dsm, 
	year = {2009}, 
	title = {{Does Self-Modeling Affect Imagery Ability or Vividness?}}, 
	author = {Rymal, Amanda M and Ste-Marie, Diane M}, 
	journal = {Journal of Imagery Research in Sport and Physical Activity}, 
	doi = {10.2202/1932-0191.1035}, 
	abstract = {{Research has shown imagery interventions to be important tools for learning new skills, as well as enhancing competitive performance. Moreover, imagery vividness and ability are two factors shown to contribute to their effectiveness. Therefore, learning ways to increase one's imagery vividness and ability is important. Hence, the present research examined the effects of an external stimulus (i.e., a self-modeling video) on one's imagery vividness and ability. A self-modeling video is an edited video showing the desired target behaviors; in this case it was a competitive dive. Two imagery measures (VMIQ and MIQ-R) were used to capture whether the self-modeling video would influence competitive divers' imagery vividness and ability. Seven competitive divers were administered both imagery measures at pre-test and post-test. After pre-test scores were taken, the participants' individual self-modeling videos were shown on three occasions before each competition and once at each competition. The results for the VMIQ indicated that imagery vividness when imaging the self was significantly better than when imaging others, F(1,6) = 7.44, p < 0.05, ?2 = .54. Of more importance is that the participants' imagery vividness increased after the self-modeling video had been administered for imaging one self but not for imaging others, although this only approached significance, F(1,6) = 3.70, p = .107, ?2 = .38. No significant results, however, were found for imagery ability. These findings suggest that there is potential for a self-modeling video to positively influence an athletes' imagery vividness.}}, 
	number = {1}, 
	volume = {4}, 
	keywords = {}
}
@article{white1998ida, 
	year = {1998}, 
	title = {{An In-Depth Analysis of the Uses of Imagery by High-Level Slalom Canoeists and Artistic Gymnasts}}, 
	author = {White, Alison and Hardy, Lew}, 
	journal = {The Sport Psychologist}, 
	issn = {0888-4781}, 
	doi = {10.1123/tsp.12.4.387}, 
	abstract = {{This study employed a qualitative methodology to examine the ways in which imagery is used by high-level slalom canoeists ( n = 3) and artistic gymnasts ( n = 3). Participants were interviewed about their imagery use and experiences in different environments. Athletes’ responses were analyzed using inductive and deductive procedures. A total of 43 raw data themes formed 10 first order and 3 second order dimensions, characterizing the athletes’ uses of imagery. Participants reported using imagery in a variety of different environments for cognitive and motivational purposes. Data showed several differences between the canoeists’ and gymnasts’ uses of imagery, reflecting the differing task demands of each sport. The experience of imagery was unique to each individual, and athletes were able to emphasize certain aspects or manipulate the content of their images for specific cognitive or motivational functions.}}, 
	pages = {387--403}, 
	number = {4}, 
	volume = {12}, 
	keywords = {}
}
@article{kim2020rtm, 
	year = {2020}, 
	title = {{Real-Time Motion Feedback System based on Smart Mirror Vision}}, 
	author = {Kim, Seoungtak and Seo, Dasol and Lee, Sangyong and Kim, Yeonjun and Kang, Hyun Wook and Choi, Yong-Sik and Jung, Jin-Woo}, 
	journal = {2020 Joint 11th International Conference on Soft Computing and Intelligent Systems and 21st International Symposium on Advanced Intelligent Systems (SCIS-ISIS)}, 
	doi = {10.1109/scisisis50064.2020.9322752}, 
	abstract = {{Modern people do not have much time to take care of their health due to heavy workloads. Therefore, we propose a smart mirror system, through which people can take exercises at home and get corrections for their movements. The users' motions are sent to the server using Raspberry Pi. Once the server receives the video, it sends the correct movements back to the user. Upon receiving the correct movements, the feedback, which is provided from the Guide video, the user can compare their movements to it. The users can correct their motions by following the correct motions provided from the Guide video. The incorrect motion is determined by the gap of the angle of the user's joints from the Guide video. This proposed Smart mirror system is assumed to contribute to people's health due to its ease of use and greater accessibility.}}, 
	pages = {1--4}, 
	volume = {00}, 
	keywords = {}
}
@article{gonzalez2010crt, 
	year = {2010}, 
	title = {{The Contribution of Real-Time Mirror Reflections of Motor Actions on Virtual Body Ownership in an Immersive Virtual Environment}}, 
	author = {González-Franco, Mar and Pérez-Marcos, Daniel and Spanlang, Bernhard and Slater, Mel}, 
	journal = {2010 IEEE Virtual Reality Conference (VR)}, 
	doi = {10.1109/vr.2010.5444805}, 
	abstract = {{This paper reports an experiment that investigated people's body ownership of an avatar that was observed in a virtual mirror. Twenty subjects were recruited in a within-groups study where 10 first experienced a virtual character that synchronously reflected their upper-body movements as seen in a virtual mirror, and then an asynchronous condition where the mirror avatar displayed prerecorded actions, unrelated to those of the participant. The other 10 subjects experienced the conditions in the opposite order. In both conditions the participant could carry out actions that led to elevation above ground level, as seen from their first person perspective and correspondingly in the mirror. A rotating virtual fan eventually descended to 2m above the ground. The hypothesis was that synchronous mirror reflection would result in higher subjective sense of ownership. A questionnaire analysis showed that the body ownership illusion was significantly greater for the synchronous than asynchronous condition. Additionally participants in the synchronous condition avoided collision with the descending fan significantly more often than those in the asynchronous condition. The results of this experiment are put into context within similar experiments on multisensory correlation and body ownership within cognitive neuroscience.}}, 
	pages = {111--114}, 
	keywords = {}
}
@book{desmond1997mim, 
	year = {1997}, 
	title = {{Meaning in Motion: New Cultural Studies of Dance}}, 
	author = {Desmond, Jane C.}, 
	editor = {Desmond, Jane C.}, 
	isbn = {978-0822319429}, 
	publisher = {Duke University Press}, 
	address = {Durham}, 
	keywords = {}, 
	doi = {10.2307/j.ctv11sn2b4.18}
}
@article{park2021ued, 
	year = {2021}, 
	title = {{User experience design for a smart-mirror-based personalized training system}}, 
	author = {Park, Hye Sun and Lee, Gun A. and Seo, Byung-Kuk and Billinghurst, Mark}, 
	journal = {Multimedia Tools and Applications}, 
	issn = {1380-7501}, 
	doi = {10.1007/s11042-020-10148-5}, 
	abstract = {{This paper describes the user experience (UX) design for a smart-mirror-based personalized training system which aims to help people live a healthy life. A number of researchers and companies have developed fitness systems that use a virtual coach which shows the user with actions they should perform. However such systems can be difficult to accurately follow the virtual guide’s motions and there are also limitations in the feedback provided to inform users of their correct body posture. This is because most systems are designed for users to simply watch and follow a character’s motions (poses) from a third person perspective. In our smart mirror-based system, users are able to follow the exercise-postures of a virtual professional trainer shown in a first person viewpoint and receive coaching through a real-time motion correction. This is based on a predefined database of the trainer’s postures gained from motion-capture technology, and it is personalized to the user’s body 3D model acquired through an instant one-time scanning process. In this paper, we report on the UX design of our system, mainly focusing on understandable visualization, intuitive interaction, attractive information representation and easily acceptable user scenarios. Through a series of user studies, we analyze and discuss user friendliness, information comprehension, and user satisfaction as they relate to our design. In addition, we also assess the similarity and effectiveness of the proposed system compared to traditional personalized training (PT) at a gym. Based on the implications, we discuss future research directions for improving the user experience of the smart-mirror-based PT system.}}, 
	pages = {31159--31181}, 
	number = {20}, 
	volume = {80}, 
	keywords = {}
}
@article{brepohl2023virtual,
	title={Virtual reality applied to physiotherapy: a review of current knowledge},
	author={Brepohl, Polyana Cristina Alves and Leite, Higor},
	journal={Virtual Reality},
	volume={27},
	number={1},
	pages={71--95},
	year={2023},
	publisher={Springer},
	doi={10.1007/s10055-022-00654-2}
}
@article{campo2021immersive,
	title={Immersive virtual reality as physical therapy in older adults: present or future (systematic review)},
	author={Campo-Prieto, Pablo and Cancela, Jos{\'e} Mar{\'\i}a and Rodr{\'\i}guez-Fuentes, Gustavo},
	journal={Virtual Reality},
	volume={25},
	number={3},
	pages={801--817},
	year={2021},
	publisher={Springer}, 
	doi = {10.1007/s10055-020-00495-x},
}
@inproceedings{hoang2016onebody,
	author = {Hoang, Thuong N. and Reinoso, Martin and Vetere, Frank and Tanin, Egemen},
	title = {Onebody: Remote Posture Guidance System using First Person View in Virtual Environment},
	year = {2016},
	isbn = {9781450347631},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	doi = {10.1145/2971485.2971521},
	abstract = {We present Onebody, a virtual reality system for remote posture guidance during sports or physical activity training, such as martial arts, yoga or dance, using first person perspective. The system uses skeletal tracking of the instructor and the students, rendered as virtual avatars. Using a virtual reality headset, the student can visualise the movement of the instructor's avatar, rendered in place of their own body. Onebody provides a first person perspective of the movement instruction, allowing the student to step into the instructor's body. We conducted a study to compare the performance of Onebody in terms of posture matching accuracy and user's preference, with existing techniques of delivering movement instructions, including pre-recorded video, video conferencing and third person view virtual reality. The result indicated that Onebody offers better posture accuracy in delivering movement instructions.},
	booktitle = {Proceedings of the 9th Nordic Conference on Human-Computer Interaction},
	articleno = {25},
	numpages = {10},
	keywords = {Virtual reality, first person view, posture guidance},
	location = {Gothenburg, Sweden},
	series = {NordiCHI '16}
}
@ARTICLE{naour2019superimpose,
	AUTHOR={Le Naour, Thibaut and Hamon, Ludovic and Bresciani, Jean-Pierre},   
	TITLE={Superimposing 3D Virtual Self + Expert Modeling for Motor Learning: Application to the Throw in American Football},      
	JOURNAL={Frontiers in ICT},      
	VOLUME={6},           
	YEAR={2019},      
	URL={https://www.frontiersin.org/articles/10.3389/fict.2019.00016},       
	DOI={10.3389/fict.2019.00016},      
	ISSN={2297-198X},   
	ABSTRACT={We learn and/or relearn motor skills at all ages. Feedback plays a crucial role in this learning process, and Virtual Reality (VR) constitutes a unique tool to provide feedback and improve motor learning. In particular, VR grants the possibility to edit 3D movements and display augmented feedback in real time. Here we combined VR and motion capture to provide learners with a 3D feedback superimposing in real time the reference movements of an expert (expert feedback) to the movements of the learner (self feedback). We assessed the effectiveness of this feedback for the learning of a throwing movement in American football. This feedback was used during (concurrent feedback) and/or after movement execution (delayed feedback), and it was compared with a feedback displaying only the reference movements of the expert. In contrast with more traditional studies relying on video feedback, we used the Dynamic Time Warping algorithm coupled to motion capture to measure the spatial characteristics of the movements. We also assessed the regularity with which the learner reproduced the reference movement along its path. For that, we used a new metric computing the dispersion of distance around the mean distance over time. Our results show that when the movements of the expert were superimposed on the movements of the learner during learning (i.e., self + expert), the reproduction of the reference movement improved significantly. Furthermore, providing feedback about the movements of the expert only did not give rise to any significant improvement regarding movement reproduction.}
}
@inproceedings{anderson2013youmove,
	author = {Anderson, Fraser and Grossman, Tovi and Matejka, Justin and Fitzmaurice, George},
	title = {YouMove: enhancing movement training with an augmented reality mirror},
	year = {2013},
	isbn = {9781450322683},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	doi = {10.1145/2501988.2502045},
	abstract = {YouMove is a novel system that allows users to record and learn physical movement sequences. The recording system is designed to be simple, allowing anyone to create and share training content. The training system uses recorded data to train the user using a large-scale augmented reality mirror. The system trains the user through a series of stages that gradually reduce the user's reliance on guidance and feedback. This paper discusses the design and implementation of YouMove and its interactive mirror. We also present a user study in which YouMove was shown to improve learning and short-term retention by a factor of 2 compared to a traditional video demonstration.},
	booktitle = {Proceedings of the 26th Annual ACM Symposium on User Interface Software and Technology},
	pages = {311–320},
	numpages = {10},
	keywords = {training, movement, motor learning, learning, guidance., full body, augmented reality, 3d},
	location = {St. Andrews, Scotland, United Kingdom},
	series = {UIST '13}
}
@INPROCEEDINGS{raffe2018combining,
	author={Raffe, William L. and Garcia, Jaime A.},
	booktitle={2018 IEEE 6th International Conference on Serious Games and Applications for Health (SeGAH)}, 
	title={Combining skeletal tracking and virtual reality for game-based fall prevention training for the elderly}, 
	year={2018},
	volume={},
	number={},
	pages={1-7},
	keywords={Games;Avatars;Visualization;Tracking;Training;Senior citizens},
	doi={10.1109/SeGAH.2018.8401371}}

@Article{treede2015classification,
	Author={Treede, R. D.  and Rief, W.  and Barke, A.  and Aziz, Q.  and Bennett, M. I.  and Benoliel, R.  and Cohen, M.  and Evers, S.  and Finnerup, N. B.  and First, M. B.  and Giamberardino, M. A.  and Kaasa, S.  and Kosek, E.  and Lavand'homme, P.  and Nicholas, M.  and Perrot, S.  and Scholz, J.  and Schug, S.  and Smith, B. H.  and Svensson, P.  and Vlaeyen, J. W. S.  and Wang, S. J.} ,
	Title = {{A} classification of chronic pain for {I}{C}{D}-11},
	Journal={Pain},
	Year={2015},
	Volume={156},
	Number={6},
	Pages={1003--1007},
	Month={Jun},
	doi={10.1097/j.pain.0000000000000160}
}
@misc{worldphysiotherapy2023global,
	title = {Annual Membership Census - Global Report},
	author = {{World Physiotherapy}},
	Year={2023},
	url={https://world.physio/sites/default/files/2024-01/AMC2023-Global.pdf}
}
@ARTICLE{lyi2021comparative,
	author={L'Yi, Sehi and Jo, Jaemin and Seo, Jinwook},
	journal={IEEE Transactions on Visualization and Computer Graphics}, 
	title={Comparative Layouts Revisited: Design Space, Guidelines, and Future Directions}, 
	year={2021},
	volume={27},
	number={2},
	pages={1525-1535},
	keywords={Layout;Visualization;Task analysis;Bars;Heating systems;Data visualization;Guidelines;Comparative layout;visual comparison;literature review;juxtaposition;superposition;explicit-encoding},
	doi={10.1109/TVCG.2020.3030419}}
@article{inoue2021virtual,
	title={Virtual mirror and beyond: The psychological basis for avatar embodiment via a mirror},
	author={Inoue, Yasuyuki and Kitazaki, Michiteru},
	journal={Journal of Robotics and Mechatronics},
	volume={33},
	number={5},
	pages={1004--1012},
	year={2021},
	publisher={Fuji Technology Press Ltd.},
	doi={10.20965/jrm.2021.p1004}
}
@INPROCEEDINGS{gonzalesfranco2010contribution,
	author={González-Franco, Mar and Pérez-Marcos, Daniel and Spanlang, Bernhard and Slater, Mel},
	booktitle={2010 IEEE Virtual Reality Conference (VR)}, 
	title={The contribution of real-time mirror reflections of motor actions on virtual body ownership in an immersive virtual environment}, 
	year={2010},
	volume={},
	number={},
	pages={111-114},
	keywords={Mirrors;Reflection;Virtual environment;Rubber;Virtual reality;Computer graphics;Avatars;Synchronous motors;Large scale integration;Computer science;rubber hand illusion;body ownership;agency;virtual reality},
	doi={10.1109/VR.2010.5444805}}
@misc{united2022world,
	title={World Population Prospects 2022, Online Edition},
	author={{United Nations, Department of Economic and Social Affairs, Population Division}},
	year={2022}
}
@article{demsar2013pca, 
	year = {2013}, 
	title = {{Principal Component Analysis on Spatial Data: An Overview}}, 
	author = {Demšar, Urška and Harris, Paul and Brunsdon, Chris and Fotheringham, A. Stewart and McLoone, Sean}, 
	journal = {Annals of the Association of American Geographers}, 
	issn = {0004-5608}, 
	doi = {10.1080/00045608.2012.689236}, 
	abstract = {{This article considers critically how one of the oldest and most widely applied statistical methods, principal components analysis (PCA), is employed with spatial data. We first provide a brief guide to how PCA works: This includes robust and compositional PCA variants, links to factor analysis, latent variable modeling, and multilevel PCA. We then present two different approaches to using PCA with spatial data. First we look at the nonspatial approach, which avoids challenges posed by spatial data by using a standard PCA on attribute space only. Within this approach we identify four main methodologies, which we define as (1) PCA applied to spatial objects, (2) PCA applied to raster data, (3) atmospheric science PCA, and (4) PCA on flows. In the second approach, we look at PCA adapted for effects in geographical space by looking at PCA methods adapted for first-order nonstationary effects (spatial heterogeneity) and second-order stationary effects (spatial autocorrelation). We also describe how PCA can be used to investigate multiple scales of spatial autocorrelation. Furthermore, we attempt to disambiguate a terminology confusion by clarifying which methods are specifically termed “spatial PCA” in the literature and how this term has different meanings in different areas. Finally, we look at a further three variations of PCA that have not been used in a spatial context but show considerable potential in this respect: simple PCA, sparse PCA, and multilinear PCA.}}, 
	pages = {106--128}, 
	number = {1}, 
	volume = {103}, 
	keywords = {}
}
@article{ahmadi2014aac, 
	year = {2014}, 
	title = {{Automatic Activity Classification and Movement Assessment During a Sports Training Session Using Wearable Inertial Sensors}}, 
	author = {Ahmadi, Amin and Mitchell, Edmond and Destelle, Francois and Gowing, Marc and O'Connor, Noel E. and Richter, Chris and Moran, Kieran}, 
	journal = {2014 11th International Conference on Wearable and Implantable Body Sensor Networks}, 
	issn = {2376-8886}, 
	doi = {10.1109/bsn.2014.29}, 
	abstract = {{Motion analysis technologies have been widely used to monitor the potential for injury and enhance athlete performance. However, most of these technologies are expensive, can only be used in laboratory environments and examine only a few trials of each movement action. In this paper, we present a novel ambulatory motion analysis framework using wearable inertial sensors to accurately assess all of an athlete's activities in an outdoor training environment. We firstly present a system that automatically classifies a large range of training activities using the Discrete Wavelet Transform (DWT) in conjunction with a Random forest classifier. The classifier is capable of successfully classifying various activities with up to 98\% accuracy. Secondly, a computationally efficient gradient descent algorithm is used to estimate the relative orientations of the wearable inertial sensors mounted on the thigh and shank of a subject, from which the flexion-extension knee angle is calculated. Finally, a curve shift registration technique is applied to both generate normative data and determine if a subject's movement technique differed to the normative data in order to identify potential injury related factors. It is envisaged that the proposed framework could be utilized for accurate and automatic sports activity classification and reliable movement technique evaluation in various unconstrained environments.}}, 
	pages = {98--103}, 
	keywords = {}
}
@article{mueller2021peq, 
	year = {2021}, 
	title = {{Physical Exercise Quality Assessment Using Wearable Sensors}}, 
	author = {Müller, Philipp Niklas and Rauterberg, Felix and Achenbach, Philipp and Tregel, Thomas and Göbel, Stefan}, 
	journal = {Lecture Notes in Computer Science}, 
	issn = {0302-9743}, 
	doi = {10.1007/978-3-030-88272-3\textunderscore17}, 
	abstract = {{To ensure health benefits and prevent injuries, the correct execution of fitness exercises is essential, particularly when vulnerable individuals are involved, such as during rehabilitation. As it is difficult for a person to assess the execution quality for themselves and most people cannot afford a personal trainer at all times, an automated assessment of execution quality is desirable. Whereas human activity recognition with modern sensor technologies has become a fundamental topic in scientific research and industry over the past decade, the execution quality of exercises is rarely addressed. In this paper, we assess the applicability of machine learning-based classification to differentiate not just between different fitness exercises, but also their execution quality. For this purpose, we propose three different system variants to recognize three different fitness exercises and at least three typical execution errors each based on acceleration and gyroscope data from up to four body-worn sensors. In our evaluation, we utilize data we recorded from 16 different participants to determine our systems’ recognition performance for different application and implementation scenarios.}}, 
	pages = {229--243}, 
	keywords = {}
}
@article{oreilly2015esp, 
	year = {2015}, 
	title = {{Evaluating Squat Performance with a Single Inertial Measurement Unit}}, 
	author = {O'Reilly, Martin and Whelan, Darragh and Chanialidis, Charalampos and Friel, Nial and Delahunt, Eamonn and Ward, Tomàs and Caulfield, Brian}, 
	journal = {2015 IEEE 12th International Conference on Wearable and Implantable Body Sensor Networks (BSN)}, 
	doi = {10.1109/bsn.2015.7299380}, 
	abstract = {{Inertial measurement units (IMUs) may be used during exercise performance to assess form and technique. To maximise practicality and minimise cost a single-sensor system is most desirable. This study sought to investigate whether a single lumbar-worn IMU is capable of identifying seven commonly observed squatting deviations. Twenty-two volunteers (18 males, 4 females, age: 26.09±3.98 years, height: 1.75±0.14m, body mass: 75.2±14.2 kg) performed the squat exercise correctly and with 7 induced deviations. IMU signal features were extracted for each condition. Statistical analysis and leave one subject out classifier evaluation were used to assess the ability of a single sensor to evaluate performance. Binary level classification was able to distinguish between correct and incorrect squatting performance with a sensitivity of 64.41\%, specificity of 88.01\% and accuracy of 80.45\%. Multi-label classification was able to distinguish between specific squat deviations with a sensitivity of 59.65\%, specificity of 94.84\% and accuracy of 56.55\%. These results indicate that a single IMU can successfully discriminate between squatting deviations. A larger data set must be collected and more complex classification techniques developed in order to create a more robust exercise analysis IMU-based system.}}, 
	pages = {1--6}, 
	keywords = {}
}
@article{schmidt2013qar, 
	year = {2013}, 
	title = {{Qualitative activity recognition of weight lifting exercises}}, 
	author = {Schmidt, Albrecht and Bulling, Andreas and Holz, Christian and Velloso, Eduardo and Bulling, Andreas and Gellersen, Hans and Ugulino, Wallace and Fuks, Hugo}, 
	journal = {Proceedings of the 4th Augmented Human International Conference}, 
	doi = {10.1145/2459236.2459256}, 
	abstract = {{Research on activity recognition has traditionally focused on discriminating between different activities, i.e. to predict which activity was performed at a specific point in time. The quality of executing an activity, the how (well), has only received little attention so far, even though it potentially provides useful information for a large variety of applications. In this work we define quality of execution and investigate three aspects that pertain to qualitative activity recognition: specifying correct execution, detecting execution mistakes, providing feedback on the to the user. We illustrate our approach on the example problem of qualitatively assessing and providing feedback on weight lifting exercises. In two user studies we try out a sensor- and a model-based approach to qualitative activity recognition. Our results underline the potential of model-based assessment and the positive impact of real-time user feedback on the quality of execution.}}, 
	pages = {116--123}, 
	keywords = {}
}

@article{kwon2020ocp, 
	year = {2020}, 
	title = {{Optimal Camera Point Selection Toward the Most Preferable View of 3-D Human Pose}}, 
	author = {Kwon, Beom and Huh, Jungwoo and Lee, Kyoungoh and Lee, Sanghoon}, 
	journal = {IEEE Transactions on Systems, Man, and Cybernetics: Systems}, 
	issn = {2168-2216}, 
	doi = {10.1109/tsmc.2020.3004338}, 
	abstract = {{Answering the question “what is the most preferable view of a three-dimensional (3-D) human model?” is a challenge in computer vision, computer graphics, and cinematography applications because the appearance of a human, for a given pose, relies on the viewpoint of the user. Currently, to the best of the authors’ knowledge, solid research on the most preferable viewing angle for obtaining numerical subjective evaluation scores has not been conducted. In this study, we investigate a metric that can be used to quantify the view of a 3-D human model, whose value is maximized at the most favorable camera angle in accordance with subjective assessments done by users. For an objective assessment in a numerical form, in this study, we define three view selection metrics: the 1) normalized limb length sum; 2) normalized area of a two-dimensional bounding box; and 3) normalized visible area of a 3-D bounding box. Finally, we formulate a viewpoint optimization problem whose objective function is the sum of the metrics. However, the objective function is nonconcave, and the solution set of the constraint is nonconvex. To overcome this difficulty, we employ decomposition and penalty methods. From the simulation results, it is verified that the average of the viewpoint selection error between the ground truth viewpoint and the optimal viewpoint obtained by the proposed algorithm is very close to the lower bound of the viewpoint selection error.}}, 
	pages = {533--553}, 
	number = {1}, 
	volume = {52}, 
	keywords = {}
}

@article{nundy2000wam, 
	year = {2000}, 
	title = {{Why are angles misperceived?}}, 
	author = {Nundy, Surajit and Lotto, Beau and Coppola, David and Shimpi, Amita and Purves, Dale}, 
	journal = {Proceedings of the National Academy of Sciences of the United States of America}, 
	doi = {10.1073/pnas.97.10.5592}, 
	abstract = {{Although it has long been apparent that observers tend to overestimate the magnitude of acute angles and underestimate obtuse ones, there is no consensus about why such distortions are seen. Geometrical modeling combined with psychophysical testing of human subjects indicates that these misperceptions are the result of an empirical strategy that resolves the inherent ambiguity of angular stimuli by generating percepts of the past significance of the stimulus rather than the geometry of its retinal projection.}}, 
	keywords = {}
}

@article{polonsky2005wii, 
	year = {2005}, 
	title = {{What’s in an Image?}}, 
	author = {Polonsky, Oleg and Patané, Giuseppe and Biasotti, Silvia and Gotsman, Craig and Spagnuolo, Michela}, 
	journal = {The Visual Computer}, 
	abstract = {{There are many possible 2D views of a given 3D object and most people would agree that some views
	are more aesthetic and/or more “informative” than others. Thus, it would be very useful, in many applications,
	to be able to automatically compute these “best” views.
	Although all measures of the quality of a view will ultimately be subjective, hence difficult to quantify, we
	propose some general principles which may be used to
	address this challenge. In particular, we describe a number of different ways to measure the goodness of a view,
	and show how to optimize these measures by reducing
	the size of the search space.}}, 
	keywords = {},
	doi={10.1007/s00371-005-0326-y}
}

@article{dutagaci2010bbv, 
	year = {2010}, 
	title = {{A benchmark for best view selection of 3D objects}}, 
	author = {Dutagaci, Helin and Cheung, Chun Pan and Godil, Afzal}, 
	journal = {Proceedings of the ACM workshop on 3D object retrieval - 3DOR '10}, 
	doi = {10.1145/1877808.1877819}, 
	abstract = {{The best view selection corresponds to the task of automatically selecting the most representative view of a 3D model. In this paper, we describe a benchmark for evaluation of best view selection algorithms. The benchmark consists of the preferred views of 68 3D models provided by 26 human subjects. The data was collected using a web-based subjective experiment where the users were asked to select the most informative view of a 3D model. We provided a quantitative evaluation measure based on this ground truth data, and compared the performances of seven best view selection algorithms.}}, 
	pages = {45--50}, 
	keywords = {}
}

@article{bonaventura2018svs, 
	year = {2018}, 
	title = {{A Survey of Viewpoint Selection Methods for Polygonal Models}}, 
	author = {Bonaventura, Xavier and Feixas, Miquel and Sbert, Mateu and Chuang, Lewis and Wallraven, Christian}, 
	journal = {Entropy}, 
	doi = {10.3390/e20050370}, 
	pmid = {33265460}, 
	pmcid = {PMC7512891}, 
	abstract = {{Viewpoint selection has been an emerging area in computer graphics for some years, and it is now getting maturity with applications in fields such as scene navigation, scientific visualization, object recognition, mesh simplification, and camera placement. In this survey, we review and compare twenty-two measures to select good views of a polygonal 3D model, classify them using an extension of the categories defined by Secord et al., and evaluate them against the Dutagaci et al. benchmark. Eleven of these measures have not been reviewed in previous surveys. Three out of the five short-listed best viewpoint measures are directly related to information. We also present in which fields the different viewpoint measures have been applied. Finally, we provide a publicly available framework where all the viewpoint selection measures are implemented and can be compared against each other.}}, 
	pages = {370}, 
	number = {5}, 
	volume = {20}, 
	keywords = {}
}

@article{zhang2019vsb, 
	year = {2019}, 
	title = {{3D scene viewpoint selection based on chaos-particle swarm optimization}}, 
	author = {Zhang, Feiyu and Li, Mingxue and Wang, Xinran and Wang, Meili and Tang, Qing}, 
	journal = {Proceedings of the Seventh International Symposium of Chinese CHI on - Chinese CHI '19}, 
	doi = {10.1145/3332169.3332173}, 
	abstract = {{The efficiency in perception of 3D scenes is a significant  problem. This paper presents a novel viewpoint 
	evaluation method combining geometric and visual 
	perception information. Firstly, we generalize the 
	criteria of the best viewpoint selection from the 
	references. Then, we introduce a dynamic inertia 
	weight and Multi-start PSO algorithm into original 
	particle swarm algorithm to prevent the problem of 
	local optimum. Finally, we develop a system with 
	friendly interfaces to demonstrate the practicality of our 
	method. The experimental results verify that this 
	approach can achieve viewpoint selection automatically
	and adapt to multi-model scene.}}, 
	pages = {97--100}, 
	keywords = {}
}

@article{ofli2012smi, 
	year = {2012}, 
	title = {{Sequence of the Most Informative Joints (SMIJ): A New Representation for Human Skeletal Action Recognition}}, 
	author = {Ofli, Ferda and Chaudhry, Rizwan and Kurillo, Gregorij and Vidal, René and Bajcsy, Ruzena}, 
	journal = {2012 IEEE Computer Society Conference on Computer Vision and Pattern Recognition Workshops}, 
	doi = {10.1109/cvprw.2012.6239231}, 
	abstract = {{Much of the existing work on action recognition combines simple features (e.g., joint angle trajectories, optical flow, spatio-temporal video features) with somewhat complex classifiers or dynamical models (e.g., kernel SVMs, HMMs, LDSs, deep belief networks). Although successful, these approaches represent an action with a set of parameters that usually do not have any physical meaning. As a consequence, such approaches do not provide any qualitative insight that relates an action to the actual motion of the body or its parts. For example, it is not necessarily the case that clapping can be correlated to hand motion or that walking can be correlated to a specific combination of motions from the feet, arms and body. In this paper, we propose a new representation of human actions called Sequence of the Most Informative Joints (SMIJ), which is extremely easy to interpret. At each time instant, we automatically select a few skeletal joints that are deemed to be the most informative for performing the current action. The selection of joints is based on highly interpretable measures such as the mean or variance of joint angles, maximum angular velocity of joints, etc. We then represent an action as a sequence of these most informative joints. Our experiments on multiple databases show that the proposed representation is very discriminative for the task of human action recognition and performs better than several state-of-the-art algorithms.}}, 
	pages = {8--13}, 
	volume = {1}, 
	keywords = {}
}
@article{kiciroglu2020amc, 
	year = {2020}, 
	title = {{ActiveMoCap: Optimized Viewpoint Selection for Active Human Motion Capture}}, 
	author = {Kiciroglu, Sena and Rhodin, Helge and Sinha, Sudipta N. and Salzmann, Mathieu and Fua, Pascal}, 
	journal = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition 2020}, 
	abstract = {{The accuracy of monocular 3D human pose estimation depends on the viewpoint from which the image is captured. While freely moving cameras, such as on drones, provide control over this viewpoint, automatically positioning them at the location which will yield the highest accuracy remains an open problem. This is the problem that we address in this paper. Specifically, given a short video sequence, we introduce an algorithm that predicts which viewpoints should be chosen to capture future frames so as to maximize 3D human pose estimation accuracy. The key idea underlying our approach is a method to estimate the uncertainty of the 3D body pose estimates. We integrate several sources of uncertainty, originating from deep learning based regressors and temporal smoothness. Our motion planner yields improved 3D body pose estimates and outperforms or matches existing ones that are based on person following and orbiting.}}, 
	keywords = {},
	doi={10.1109/CVPR42600.2020.00018}
}

@article{shi2012ksb, 
	year = {2012}, 
	title = {{A Kinematics Significance Based Skeleton Map for Rapid Viewpoint Selection}}, 
	author = {Shi, Zhenfeng and Yu, Liyang and El-Latif, Ahmed and Le, Dan and Niu, Xiamu}, 
	journal = {International Journal of Digital Content Technology and its Applications}, 
	issn = {1975-9339},
	pages = {31--40}, 
	number = {1}, 
	volume = {6},
	doi={10.6342/NTU201603740},
	keywords = {}
}

@article{rudoy2011vsh, 
	year = {2011}, 
	title = {{Viewpoint Selection for Human Actions}}, 
	author = {Rudoy, Dmitry and Zelnik-Manor, Lihi}, 
	journal = {International Journal of Computer Vision}, 
	issn = {0920-5691}, 
	doi = {10.1007/s11263-011-0484-5}, 
	abstract = {{In many scenarios a dynamic scene is filmed by multiple video cameras located at different viewing positions. Visualizing such multi-view data on a single display raises an immediate question—which cameras capture better views of the scene? Typically, (e.g. in TV broadcasts) a human producer manually selects the best view. In this paper we wish to automate this process by evaluating the quality of a view, captured by every single camera. We regard human actions as three-dimensional shapes induced by their silhouettes in the space-time volume. The quality of a view is then evaluated based on features of the space-time shape, which correspond with limb visibility. Resting on these features, two view quality approaches are proposed. One is generic while the other can be trained to fit any preferred action recognition method. Our experiments show that the proposed view selection provide intuitive results which match common conventions. We further show that it improves action recognition results.}}, 
	pages = {243--254}, 
	number = {3}, 
	volume = {97}, 
	keywords = {}
}

@article{garth2008lvf, 
	year = {2008}, 
	title = {{Lagrangian Visualization of Flow-Embedded Surface Structures}}, 
	author = {Garth, Christoph and Wiebel, Alexander and Tricoche, Xavier and Joy, Ken and Scheuermann, Gerik}, 
	journal = {IDAV Publications}, 
	doi = {https://escholarship.org/uc/item/6gh7n28g}, 
	url = {https://escholarship.org/uc/item/6gh7n28g}, 
	abstract = {{The notions of Finite-Time Lyapunov Exponent (FTLE) and Lagrangian Coherent Structures provide a strong framework for the analysis and visualization of complex technical flows. Their definition is simple and intuitive, and they are built on a deep theoretical foundation. We apply these concepts to enable the analysis of flows in the immediate vicinity of the boundaries of flow-embedded objects by limiting the Lagrangian analysis to surfaces closely neighboring these boundaries. To this purpose, we present an approach to approximate FTLE fields over such surfaces. Furthermore, we achieve an effective depiction of boundary-related flow structures such as separation and attachment over object boundaries and specific insight into the surrounding flow using several specifically chosen visualization techniques. We document the applicability of our methods by presenting a number of application examples.}}, 
	keywords = {}
}

@incollection{wiebel_2013_EuroVis, 
	year = {2013}, 
	title = {{3D Strokes on Visible Structures in Direct Volume Rendering}}, 
	author = {Wiebel, Alexander and Preis, Philipp and Vos, Frans M. and Hege, Hans-Christian}, 
	editor = {Hlawitschka, Mario and Weinkauf, Tino}, 
	booktitle = {EuroVis - Short Papers}, 
	pages = {91--95}, 
	keywords = {}, 
	doi = {10.2312/pe.eurovisshort.eurovisshort2013.091-095}
}

@article{kim2012idc, 
	year = {2012}, 
	title = {{Interactive data-centric viewpoint selection}}, 
	author = {Kim, Han Suk and Unat, Didem and Baden, Scott B. and Schulze, Jürgen P.}, 
	journal = {Visualization and Data Analysis 2012}, 
	issn = {0277-786X}, 
	doi = {10.1117/12.907480}, 
	abstract = {{We propose a new algorithm for automatic viewpoint selection for volume data sets. While most previous algorithms depend on information theoretic frameworks, our algorithm solely focuses on the data itself without off-line rendering steps, and finds a view direction which shows the data set’s features well. The algorithm consists of two main steps: feature selection and viewpoint selection. The feature selection step is an extension of the 2D Harris interest point detection algorithm. This step selects corner and/or high-intensity points as features, which captures the overall structures and local details. The second step, viewpoint selection, takes this set and finds a direction that lays out those points in a way that the variance of projected points is maximized, which can be formulated as a Principal Component Analysis (PCA) problem. The PCA solution guarantees that surfaces with detected corner points are less likely to be degenerative, and it minimizes occlusion between them. Our entire algorithm takes less than a second, which allows it to be integrated into real-time volume rendering applications where users can modify the volume with transfer functions, because the optimized viewpoint depends on the transfer function.}}, 
	pages = {829405--829405-12}, 
	note = {Use PCA to select a viewpoint}, 
	keywords = {}
}

@article{zheng2011ivf, 
	year = {2011}, 
	title = {{iView: A Feature Clustering Framework for Suggesting Informative Views in Volume Visualization}}, 
	author = {Zheng, Ziyi and Ahmed, Nafees and Mueller, Klaus}, 
	journal = {IEEE Transactions on Visualization and Computer Graphics}, 
	issn = {1077-2626}, 
	doi = {10.1109/tvcg.2011.218}, 
	pmid = {22034313}, 
	abstract = {{The unguided visual exploration of volumetric data can be both a challenging and a time-consuming undertaking. Identifying a set of favorable vantage points at which to start exploratory expeditions can greatly reduce this effort and can also ensure that no important structures are being missed. Recent research efforts have focused on entropy–based viewpoint selection criteria that depend on scalar values describing the structures of interest. In contrast, we propose a viewpoint suggestion pipeline that is based on feature-clustering in high-dimensional space. We use gradient/normal variation as a metric to identify interesting local events and then cluster these via k-means to detect important salient composite features. Next, we compute the maximum possible exposure of these composite feature for different viewpoints and calculate a 2D entropy map parameterized in longitude and latitude to point out promising view orientations. Superimposed onto an interactive track-ball interface, users can then directly use this entropy map to quickly navigate to potentially interesting viewpoints where visibility-based transfer functions can be employed to generate volume renderings that minimize occlusions. To give full exploration freedom to the user, the entropy map is updated on the fly whenever a view has been selected, pointing to new and promising but so far unseen view directions. Alternatively, our system can also use a set-cover optimization algorithm to provide a minimal set of views needed to observe all features. The views so generated could then be saved into a list for further inspection or into a gallery for a summary presentation.}}, 
	pages = {1959--1968}, 
	number = {12}, 
	volume = {17}, 
	keywords = {}
}

@article{vasquez2008rvp, 
	year = {2008}, 
	title = {{Representative Views and Paths for Volume Models}}, 
	author = {Vázquez, Pere-Pau and Monclús, Eva and Navazo, Isabel}, 
	journal = {Lecture Notes in Computer Science}, 
	issn = {0302-9743}, 
	doi = {10.1007/978-3-540-85412-8\textunderscore10}, 
	abstract = {{Volume data models are becoming larger and larger as the capture technology improves. Thus, their visualization requires high computational power. The automatic presentation of volume models through representative images and/or exploration paths becomes more and more useful. Representative views are also useful for document illustration, fast data quality evaluation, or model libraries documentation. Exploration paths are also useful for video demonstrations and previsualization of captured data. In this paper we present a fast, adaptive method for the selection of representative views and the automatic generation of exploration paths for volume models. Our algorithm is based on multi-scale entropy and algorithmic complexity. These views and paths reveal informative parts of a model given a certain transfer function. We show that our method is simple and easy to incorporate in medical visualization tools.}}, 
	pages = {106--117}, 
	keywords = {}
}

@article{bordoloi2005vsv, 
	year = {2005}, 
	title = {{View Selection for Volume Rendering}}, 
	author = {Bordoloi, U D and Shen, Han-Wei}, 
	journal = {IEEE Visualization 2005 - (VIS'05)}, 
	doi = {10.1109/vis.2005.110}, 
	pages = {62--62}, 
	keywords = {}
}

@article{kohlmann2007lsd, 
	year = {2007}, 
	title = {{LiveSync: Deformed Viewing Spheres for Knowledge-Based Navigation}}, 
	author = {Kohlmann, P. and Bruckner, S. and Groller, M. Eduard and Kanitsar, A.}, 
	journal = {IEEE TVCG}, 
	issn = {1077-2626}, 
	doi = {10.1109/tvcg.2007.70576}, 
	pmid = {17968108}, 
	abstract = {{Although real-time interactive volume rendering is available even for very large data sets, this visualization method is used quite rarely in the clinical practice. We suspect this is because it is very complicated and time consuming to adjust the parameters to achieve meaningful results. The clinician has to take care of the appropriate viewpoint, zooming, transfer function setup, clipping planes and other parameters. Because of this, most often only 2D slices of the data set are examined. Our work introduces LiveSync, a new concept to synchronize 2D slice views and volumetric views of medical data sets. Through intuitive picking actions on the slice, the users define the anatomical structures they are interested in. The 3D volumetric view is updated automatically with the goal that the users are provided with expressive result images. To achieve this live synchronization we use a minimal set of derived information without the need for segmented data sets or data-specific pre-computations. The components we consider are the picked point, slice view zoom, patient orientation, viewpoint history, local object shape and visibility. We introduce deformed viewing spheres which encode the viewpoint quality for the components. A combination of these deformed viewing spheres is used to estimate a good viewpoint. Our system provides the physician with synchronized views which help to gain deeper insight into the medical data with minimal user interaction.}}, 
	pages = {1544--1551}, 
	number = {6}, 
	volume = {13}, 
	keywords = {}
}

@article{kwon2008dcp, 
	year = {2008}, 
	title = {{Determination of camera parameters for character motions using motion area}}, 
	author = {Kwon, Ji-Yong and Lee, In-Kwon}, 
	journal = {The Visual Computer}, 
	issn = {0178-2789}, 
	doi = {10.1007/s00371-008-0228-x}, 
	abstract = {{We propose a method to determine camera parameters for character motion, which considers the motion by itself. The basic idea is to approximately compute the area swept by the motion of the character’s links that are orthogonally projected onto the image plane, which we call “motion area”. Using the motion area, we can determine good fixed camera parameters and camera paths for a given character motion in the off-line or real-time camera control. In our experimental results, we demonstrate that our camera path generation algorithms can compute a smooth moving camera path while the camera effectively displays the dynamic features of character motion. Our methods can be easily used in combination with the method for generating occlusion-free camera paths. We expect that our methods can also be utilized by the general camera planning method as one of heuristics for measuring the visual quality of the scenes that include dynamically moving characters.}}, 
	pages = {475--483}, 
	number = {7-9}, 
	volume = {24}, 
	keywords = {}
}
@article{10.1109/tvcg.2012.143, 
	year = {2013}, 
	title = {{A Unified Approach to Streamline Selection and Viewpoint Selection for 3D Flow Visualization}}, 
	author = {Tao, Jun and Ma, Jun and Wang, Chaoli and Shene, Ching-Kuang}, 
	journal = {IEEE Transactions on Visualization and Computer Graphics}, 
	issn = {1077-2626}, 
	doi = {10.1109/tvcg.2012.143}, 
	pmid = {22732682}, 
	abstract = {{We treat streamline selection and viewpoint selection as symmetric problems which are formulated into a unified information-theoretic framework. This is achieved by building two interrelated information channels between a pool of candidate streamlines and a set of sample viewpoints. We define the streamline information to select best streamlines and in a similar manner, define the viewpoint information to select best viewpoints. Furthermore, we propose solutions to streamline clustering and viewpoint partitioning based on the representativeness of streamlines and viewpoints, respectively. Finally, we define a camera path that passes through all selected viewpoints for automatic flow field exploration. We demonstrate the robustness of our approach by showing experimental results with different flow data sets, and conducting rigorous comparisons between our algorithm and other seed placement or streamline selection algorithms based on information theory.}}, 
	pages = {393--406}, 
	number = {3}, 
	volume = {19}, 
	note = {Von Alex}, 
	keywords = {}
}

@article{10.1109/pacificvis.2011.5742376, 
	year = {2011}, 
	title = {{View Point Evaluation and Streamline Filtering for Flow Visualization}}, 
	author = {Lee, Teng-Yok and Mishchenko, Oleg and Shen, Han-Wei and Crawfis, Roger}, 
	journal = {2011 IEEE Pacific Visualization Symposium}, 
	doi = {10.1109/pacificvis.2011.5742376}, 
	abstract = {{Visualization of flow fields with geometric primitives is often challenging due to occlusion that is inevitably introduced by 3D stream-lines. In this paper, we present a novel view-dependent algorithm that can minimize occlusion and reveal important flow features for three dimensional flow fields. To analyze regions of higher importance, we utilize Shannon's entropy as a measure of vector complexity. An entropy field in the form of a three dimensional volume is extracted from the input vector field. To utilize this view-independent complexity measure for view-dependent calculations, we introduce the notion of a maximal entropy projection (MEP) framebuffer, which stores maximal entropy values as well as the corresponding depth values for a given viewpoint. With this in-formation, we develop a view-dependent streamline selection algorithm that can evaluate and choose streamlines that will cause minimum occlusion to regions of higher importance. Based on a similar concept, we also propose a viewpoint selection algorithm that works hand-in-hand with our streamline selection algorithm to maximize the visibility of high complexity regions in the flow field.}}, 
	pages = {83--90}, 
	note = {Von Alex}, 
	keywords = {}
}

@article{manitsaris2016taa, 
	year = {2016}, 
	title = {{Techniques and Approaches in Static Visualization of Motion Capture Data}}, 
	author = {Manitsaris, Sotiris and Li, William and Bartram, Lyn and Pasquier, Philippe}, 
	journal = {Proceedings of the 3rd International Symposium on Movement and Computing}, 
	doi = {10.1145/2948910.2948935}, 
	abstract = {{In this paper we present a state of the art of the current approaches to visualization of motion capture data. We discuss the data representation, pre-processing techniques, and the design of existing tools and systems. Next we outline the advantages and disadvantages of the systems, some of which are explicitly noted by the original authors. Lastly we conclude with an overall summary and future directions.}}, 
	pages = {1--8}, 
	keywords = {}
}

@article{mao2017psa, 
	year = {2017}, 
	title = {{Pose selection for animated scenes and a case study of bas-relief generation}}, 
	author = {Mao, Xiaoyang and Thalmann, Daniel and Gavrilova, Marina and Wang, Meili and Guo, Shihui and Liao, Minghong and He, Dongjian and Chang, Jian and Zhang, Jian and Zhang, Zhiyi}, 
	journal = {Proceedings of the Computer Graphics International Conference}, 
	doi = {10.1145/3095140.3095171}, 
	abstract = {{This paper aims to automate the process of generating a meaningful single still image from a temporal input of scene sequences. The success of our extraction relies on evaluating the optimal pose of characters selection, which should maximize the information conveyed. We define the information entropy of the still image candidates as the evaluation criteria. To validate our method and to demonstrate its effectiveness, we generated a relief (as a unique form of art creation) to narrate given temporal action scenes. A user study was conducted to experimentally compare the computer-selected poses with those selected by human participants. The results show that the proposed method can assist the selection of informative pose of character effectively.}}, 
	pages = {1--6}, 
	keywords = {}
}
@inproceedings{diller2024automatic,
	author={Florian Diller and Alexander Wiebel and Gerik Scheuermann},
	title={Automatic Viewpoint Selection for Interactive Motor Feedback Using Principal Component Analysis},
	booktitle={Proceedings of the 19th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications - HUCAPP},
	year={2024},
	pages={350-361},
	publisher={SciTePress},
	organization={INSTICC},
	doi={10.5220/0012308700003660},
	isbn={978-989-758-679-8},
	issn={2184-4321}
}
@article{tam2012registration,
	title={Registration of 3D point clouds and meshes: A survey from rigid to nonrigid},
	author={Tam, Gary KL and Cheng, Zhi-Quan and Lai, Yu-Kun and Langbein, Frank C and Liu, Yonghuai and Marshall, David and Martin, Ralph R and Sun, Xian-Fang and Rosin, Paul L},
	journal={IEEE transactions on visualization and computer graphics},
	volume={19},
	number={7},
	pages={1199--1217},
	year={2012},
	publisher={IEEE},
	doi={10.1109/TVCG.2012.310}
}
@inproceedings{bellekens2014survey,
	title={A Survey of Rigid 3D Pointcloud Registration Algorithms},
	author={Bellekens, Ben and Spruyt, Vincent and Berkvens, Rafael and Weyn, Maarten},
	booktitle={AMBIENT 2014: the Fourth International Conference on Ambient Computing, Applications, Services and Technologies, August 24-28, 2014, Rome, Italy},
	pages={8--13},
	year={2014}
}
@article{yaniv2008rigid,
	title={Rigid Registration},
	author={Yaniv, Ziv},
	journal={Image-Guided Interventions: Technology Review and Clinical Applications},
	pages={159--192},
	year={2008},
	publisher={Springer},
	doi={10.1146/annurev-bioeng-070909-105249}
}
%----------------------Intro literature----------------------%

@article{cope2023history,
	author = {Bill Cope and Mary Kalantzis},
	title = {A little history of e-learning: finding new ways to learn in the PLATO computer education system, 1959–1976},
	journal = {History of Education},
	volume = {52},
	number = {6},
	pages = {905--936},
	year = {2023},
	publisher = {Routledge},
	doi = {10.1080/0046760X.2022.2141353}
}

@inproceedings{diller2024holistic,
booktitle = {Eurographics 2024 - Education Papers},
title = {Holistic Approach to Modular Open Educational Resources for Computer Graphics},
author = {Diller, Florian and Püschel, Fabian and Stockemer, Julian and Böhm, Klaus and Wiebel, Alexander},
year = {2024},
publisher = {The Eurographics Association},
ISSN = {1017-4656},
ISBN = {978-3-03868-238-7},
DOI = {10.2312/eged.20241002}
}
        

@article{diller2025skillar,
  title={SkillAR: omnipresent in-situ feedback for motor skill training using AR},
  author={Diller, Florian and Henkel, Nico and Scheuermann, Gerik and Wiebel, Alexander},
  journal={Virtual Reality},
  volume={29},
  number={1},
  pages={1--11},
  year={2025},
  doi={10.1007/s10055-025-01108-1},
  publisher={Springer}
}
@article{vavra2011visualization,
	title={Visualization in science education},
	author={Vavra, Karen L and Janjic-Watrich, Vera and Loerke, Karen and Phillips, Linda M and Norris, Stephen P and Macnab, John},
	journal={Alberta Science Education Journal},
	volume={41},
	number={1},
	pages={22--30},
	year={2011}
}
@article{firat2018towards,
	title={Towards a survey of interactive visualization for education},
	author={F{\i}rat, Elif E and Laramee, Robert S},
	journal={Computer Graphics and Visual Computing, CGVC 2018},
	pages={91--101},
	year={2018},
	doi={10.2312/cgvc.20181211}
}
@article{alansi2023analyzing,
	title = {Analyzing augmented reality (AR) and virtual reality (VR) recent development in education},
	journal = {Social Sciences \& Humanities Open},
	volume = {8},
	number = {1},
	pages = {100532},
	year = {2023},
	issn = {2590-2911},
	doi = {10.1016/j.ssaho.2023.100532},
	url = {https://www.sciencedirect.com/science/article/pii/S2590291123001377},
	author = {Abdullah M. Al-Ansi and Mohammed Jaboob and Askar Garad and Ahmed Al-Ansi},
	keywords = {Augmented reality (AR), Virtual reality (VR), Literature review, Education},
	abstract = {Augmented Reality (AR) and Virtual Reality (VR) technologies have revolutionized learning approaches through immersive digital experience, interactive environment, simulation and engagement. Yet, these technologies are in developing stage and require massive investment and mass customization to meet the high demand in education. This comprehensive review aims to frame AR and VR development in education during the last twelve years. By adopting text mining and topic analysis approaches, a total of 1536 articles were selected for further analysis. These articles were selected from Scopus database based on specific criteria where titles, keywords and abstracts were extracted for analysis by WordStat. Hypotheses were formulated based on the prior works of AR and VR in education and being processed and evaluated to unvield state of art of AR and VR literature development, applications, advantages and future directions. Results reveal that adoption of AR and VR in education have exponential growth during recent years where wearable device have gain the large portion of this development. Based on secondary data, results also reveal the gap in implementing and customizing these technologies quickly in educational institutions. As AR and VR technologies rapidly develop and become mature, more educational applications emerge in learning process. Researchers are recommended to keep in pace to discover gaps of AR and VR transition to education and create effective adaptability approaches to gain more benefits of these technologies development.}
}
@article{asad2021virtual,
  title={Virtual reality as pedagogical tool to enhance experiential learning: a systematic literature review},
  author={Asad, Muhammad Mujtaba and Naz, Aisha and Churi, Prathamesh and Tahanzadeh, Mohammad Mehdi},
  journal={Education Research International},
  volume={2021},
  number={1},
  year={2021},
  publisher={Wiley Online Library},
  doi={10.1155/2021/7061623}
}
@inproceedings{majgaard2020virtual,
  title={Virtual experiential learning, learning design and interaction in extended reality simulations},
  author={Majgaard, Gunver and Weitze, Charlotte},
  booktitle={Proceedings of the 14th European Conference on Game Based Learning, ECGBL},
  pages={372--379},
  year={2020}
}
@inproceedings{wang2007experiential,
  title={Experiential mixed reality learning environments for design education},
  author={Wang, Xiangyu},
  booktitle={Proceedings of the 41st Australia and New Zealand Annual Conference of the Architectural Science Association (ANZAScA). Deadkin University, Geelong, Australia},
  pages={272--277},
  year={2007}
}
@book{lave:wenger:1991,
  place={Cambridge},
  series={Learning in Doing: Social, Cognitive and Computational Perspectives},
  title={Situated Learning: Legitimate Peripheral Participation},
  publisher={Cambridge University Press},
  author={Lave, Jean and Wenger, Etienne},
  year={1991},
  doi={10.1017/CBO9780511815355},
  collection={Learning in Doing: Social, Cognitive and Computational Perspectives}
}
@article{mat2025virtual,
  title={Virtual virtuoso: a systematic literature review of immersive learning environments for psychomotor skill development},
  author={Mat Sanusi, Khaleel Asyraaf and Iren, Deniz and Fanchamps, Nardie and Geisen, Mai and Klemke, Roland and others},
  journal={Educational technology research and development},
  pages={1--41},
  year={2025},
  doi={10.1007/s11423-025-10449-2},
  publisher={Springer}
}
@article{godden1975context,
author = {Godden, D. R. and Baddeley, A. D.},
title = {Context-Dependent Memory in Two Natural Environments: On Land and Underwater},
journal = {British Journal of Psychology},
volume = {66},
number = {3},
pages = {325-331},
doi = {10.1111/j.2044-8295.1975.tb01468.x},
abstract = {In a free recall experiment, divers learnt lists of words in two natural environments: on dry land and underwater, and recalled the words in either the environment of original learning, or in the alternative environment. Lists learnt underwater were best recalled underwater, and vice versa. A subsequent experiment shows that the disruption of moving from one environment to the other was unlikely to be responsible for context-dependent memory.},
year = {1975}
}
@article{ruitenberg2012context,
  title={Context-dependent motor skill and the role of practice},
  author={Ruitenberg, Marit FL and De Kleine, Elian and Van der Lubbe, Rob HJ and Verwey, Willem B and Abrahamse, Elger L},
  journal={Psychological research},
  volume={76},
  pages={812--820},
  year={2012},
  doi={10.1007/s00426-011-0388-6},
  publisher={Springer}
}
@article{smith2001environmental,
  title={Environmental context-dependent memory: A review and meta-analysis},
  author={Smith, Steven M and Vela, Edward},
  journal={Psychonomic bulletin \& review},
  volume={8},
  pages={203--220},
  year={2001},
  doi={10.3758/BF03196157},
  publisher={Springer}
}
@article{anderson1998contextual,
  title={Contextual dependencies during perceptual-motor skill performance: Influence of task difficulty},
  author={Anderson, Ted and Wright, David L and Immink, Maarten A},
  journal={Memory},
  volume={6},
  number={2},
  pages={207--221},
  year={1998},
  doi={10.1080/741942069},
  publisher={Taylor \& Francis}
}
@article{wright1991contextual,
  title={Contextual dependencies in motor skills},
  author={Wright, David L and Shea, Charles H},
  journal={Memory \& Cognition},
  volume={19},
  pages={361--370},
  year={1991},
  doi={10.3758/BF03197140},
  publisher={Springer}
}
﻿@Article{diller2025towards,
author={Diller, Florian
and Frey, Thorben
and Scheuermann, Gerik
and Wiebel, Alexander},
title={Towards an Optimal Display of Superimposed Avatars for Motor Feedback},
journal={SN Computer Science},
year={2025},
month={Apr},
day={15},
volume={6},
number={4},
pages={388},
issn={2661-8907},
doi={10.1007/s42979-025-03904-7}
}


@article{lapsley2017review,
  author = {Lapsley, Phil},
  title = {Review: Plato’s ‘Friendly Orange Glow’},
  journal = {The Wall Street Journal},
  date = {2017-12-08},
  url = {https://www.wsj.com/articles/review-platos-friendly-orange-glow-1512771287}
}